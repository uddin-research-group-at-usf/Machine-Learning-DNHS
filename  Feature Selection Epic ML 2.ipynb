{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook have code for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings imported from other notebook Settings.ipynb\n",
    "%run Settings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = joblib.load(\"E:/Machine Learning/Output Data/Response Variable (PTSS Epic).pkl\")\n",
    "full_data = joblib.load(\"E:/Machine Learning/Output Data/GRRN_phenodata (cross_long Epic).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_df_cross':      cg11188799  cg19586199  cg03354771  cg16246200  cg12700033  cg15500320  \\\n",
       " 0        0.0125      0.9566      0.0198      0.9633      0.0407      0.0166   \n",
       " 2        0.0154      0.9574      0.0228      0.9728      0.0330      0.0139   \n",
       " 5        0.0128      0.9573      0.0279      0.9758      0.0445      0.0161   \n",
       " 6        0.0150      0.9566      0.0291      0.9692      0.0315      0.0154   \n",
       " 11       0.0110      0.9678      0.0221      0.9686      0.0450      0.0157   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0104      0.9616      0.0206      0.9790      0.0428      0.0151   \n",
       " 441      0.0132      0.9632      0.0312      0.9769      0.0368      0.0125   \n",
       " 442      0.0143      0.9532      0.0225      0.9737      0.0355      0.0154   \n",
       " 444      0.0112      0.9658      0.0231      0.9785      0.0440      0.0171   \n",
       " 447      0.0128      0.9575      0.0238      0.9786      0.0359      0.0141   \n",
       " \n",
       "      cg13374701  cg11090676  cg00935119  cg26116980  cg01529076  cg01362515  \\\n",
       " 0        0.9532      0.0231      0.0268      0.9865      0.5381      0.7642   \n",
       " 2        0.9294      0.0279      0.0226      0.9867      0.4091      0.7783   \n",
       " 5        0.9554      0.0283      0.0274      0.9857      0.4791      0.8271   \n",
       " 6        0.9464      0.0292      0.0299      0.9837      0.4153      0.7256   \n",
       " 11       0.9496      0.0278      0.0223      0.9872      0.5150      0.7906   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.9503      0.0246      0.0219      0.9879      0.4202      0.7836   \n",
       " 441      0.9544      0.0274      0.0250      0.9835      0.3843      0.7686   \n",
       " 442      0.9518      0.0289      0.0252      0.9843      0.4428      0.7963   \n",
       " 444      0.9498      0.0274      0.0297      0.9886      0.4676      0.7925   \n",
       " 447      0.9421      0.0280      0.0255      0.9855      0.4571      0.7071   \n",
       " \n",
       "      cg01320969  cg27005894  cg22402853  cg15096815  cg16101035  cg18071894  \\\n",
       " 0        0.0239      0.0304      0.0228      0.0252      0.0434      0.5119   \n",
       " 2        0.0246      0.0261      0.0194      0.0535      0.0342      0.4285   \n",
       " 5        0.0261      0.0310      0.0262      0.0455      0.0401      0.4430   \n",
       " 6        0.0234      0.0351      0.0221      0.0274      0.0373      0.4288   \n",
       " 11       0.0228      0.0313      0.0212      0.0339      0.0403      0.4604   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0297      0.0320      0.0257      0.0286      0.0454      0.3537   \n",
       " 441      0.0248      0.0272      0.0240      0.0285      0.0410      0.4309   \n",
       " 442      0.0213      0.0327      0.0236      0.0291      0.0428      0.4075   \n",
       " 444      0.0225      0.0290      0.0236      0.0443      0.0382      0.5006   \n",
       " 447      0.0250      0.0294      0.0228      0.0317      0.0372      0.4218   \n",
       " \n",
       "      cg06846259  cg10105971  cg03384545  cg05859578  cg05898629  cg25053252  \\\n",
       " 0        0.7744      0.1079      0.0257      0.8785      0.9651      0.0328   \n",
       " 2        0.6217      0.0896      0.0187      0.9007      0.9538      0.0288   \n",
       " 5        0.7145      0.0948      0.0215      0.9113      0.9552      0.0299   \n",
       " 6        0.6268      0.1085      0.0196      0.8874      0.9644      0.0307   \n",
       " 11       0.5853      0.1159      0.0208      0.9142      0.9546      0.0263   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.5679      0.0736      0.0196      0.9035      0.9746      0.0262   \n",
       " 441      0.5911      0.0942      0.0200      0.8712      0.9588      0.0312   \n",
       " 442      0.6808      0.1058      0.0244      0.8920      0.9493      0.0329   \n",
       " 444      0.5859      0.0821      0.0213      0.9100      0.9730      0.0256   \n",
       " 447      0.7885      0.0988      0.0194      0.8845      0.9583      0.0285   \n",
       " \n",
       "      cg22322863  cg00039463  cg06633814  cg12271199  cg15900987  cg06959103  \\\n",
       " 0        0.0279      0.6601      0.0363      0.0254      0.9235      0.0360   \n",
       " 2        0.0207      0.5935      0.0246      0.0207      0.9039      0.0388   \n",
       " 5        0.0225      0.6294      0.0350      0.0257      0.9270      0.0457   \n",
       " 6        0.0259      0.6136      0.0285      0.0269      0.9198      0.0423   \n",
       " 11       0.0278      0.6893      0.0259      0.0243      0.8983      0.0412   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0220      0.5250      0.0243      0.0249      0.9386      0.0441   \n",
       " 441      0.0226      0.6529      0.0373      0.0238      0.9076      0.0429   \n",
       " 442      0.0261      0.6109      0.0249      0.0256      0.9193      0.0512   \n",
       " 444      0.0226      0.6460      0.0301      0.0264      0.9258      0.0343   \n",
       " 447      0.0225      0.5567      0.0245      0.0255      0.9020      0.0371   \n",
       " \n",
       "      cg11872076  cg25034766  cg24718866  cg23014605  cg05970790  cg15001636  \\\n",
       " 0        0.0218      0.9477      0.0393      0.0368      0.0266      0.6747   \n",
       " 2        0.0131      0.9598      0.0262      0.0399      0.0381      0.6900   \n",
       " 5        0.0196      0.9589      0.0319      0.0404      0.0390      0.6868   \n",
       " 6        0.0169      0.9574      0.0268      0.0352      0.0296      0.7224   \n",
       " 11       0.0158      0.9697      0.0272      0.0347      0.0282      0.6496   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0114      0.9612      0.0254      0.0350      0.0248      0.6885   \n",
       " 441      0.0149      0.9636      0.0252      0.0366      0.0284      0.6735   \n",
       " 442      0.0147      0.9679      0.0295      0.0395      0.0367      0.6477   \n",
       " 444      0.0168      0.9765      0.0339      0.0343      0.0305      0.7072   \n",
       " 447      0.0150      0.9660      0.0247      0.0432      0.0289      0.7148   \n",
       " \n",
       "      cg06432200  cg16606005  cg12100463  cg10913456  cg11065262  cg15684811  \\\n",
       " 0        0.5866      0.9653      0.8401      0.0156      0.0395      0.0563   \n",
       " 2        0.6390      0.9740      0.8593      0.0129      0.0298      0.0662   \n",
       " 5        0.5946      0.9752      0.8612      0.0167      0.0355      0.0568   \n",
       " 6        0.6140      0.9620      0.8450      0.0174      0.0345      0.0648   \n",
       " 11       0.6280      0.9703      0.8432      0.0139      0.0293      0.0581   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.6296      0.9722      0.8591      0.0146      0.0279      0.0512   \n",
       " 441      0.5749      0.9561      0.8469      0.0184      0.0299      0.0638   \n",
       " 442      0.6076      0.9637      0.8416      0.0140      0.0350      0.0556   \n",
       " 444      0.5917      0.9704      0.8718      0.0157      0.0303      0.0527   \n",
       " 447      0.6620      0.9627      0.8477      0.0148      0.0298      0.0599   \n",
       " \n",
       "      cg09781971  cg02072813  cg14274357  cg21209684  cg18014042  cg25579739  \\\n",
       " 0        0.0515      0.8982      0.9253      0.0221      0.9622      0.0291   \n",
       " 2        0.0509      0.8635      0.9368      0.0235      0.9588      0.0232   \n",
       " 5        0.0419      0.8818      0.9372      0.0257      0.9657      0.0243   \n",
       " 6        0.0549      0.8754      0.9337      0.0240      0.9593      0.0247   \n",
       " 11       0.0425      0.9102      0.9272      0.0231      0.9633      0.0270   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0412      0.8435      0.9250      0.0247      0.9673      0.0242   \n",
       " 441      0.0486      0.8886      0.8892      0.0242      0.9641      0.0261   \n",
       " 442      0.0407      0.8608      0.9313      0.0247      0.9604      0.0278   \n",
       " 444      0.0361      0.9042      0.9399      0.0269      0.9693      0.0241   \n",
       " 447      0.0532      0.8376      0.7974      0.0250      0.9604      0.0239   \n",
       " \n",
       "      cg11844358  cg23564290  cg05513979  cg06462174  cg20787340  cg01921845  \\\n",
       " 0        0.9871      0.0247      0.0347      0.2687      0.0146      0.9827   \n",
       " 2        0.9869      0.0259      0.0353      0.2583      0.0156      0.9747   \n",
       " 5        0.9849      0.0309      0.0345      0.2827      0.0150      0.9784   \n",
       " 6        0.9831      0.0323      0.0383      0.2456      0.0156      0.9770   \n",
       " 11       0.9864      0.0309      0.0337      0.2951      0.0146      0.9801   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.9870      0.0254      0.0302      0.2593      0.0173      0.9781   \n",
       " 441      0.9861      0.0272      0.0337      0.2415      0.0143      0.9781   \n",
       " 442      0.9839      0.0295      0.0369      0.2372      0.0159      0.9748   \n",
       " 444      0.9845      0.0321      0.0316      0.2949      0.0147      0.9796   \n",
       " 447      0.9858      0.0273      0.0326      0.2456      0.0148      0.9759   \n",
       " \n",
       "      cg22991936  cg09679690  cg03562264  cg16374471  cg10189525  cg03090513  \\\n",
       " 0        0.8916      0.1611      0.0248      0.0255      0.0482      0.0347   \n",
       " 2        0.8910      0.1814      0.0251      0.0260      0.0501      0.0273   \n",
       " 5        0.8866      0.1861      0.0332      0.0268      0.0489      0.0292   \n",
       " 6        0.8856      0.1708      0.0266      0.0248      0.0628      0.0335   \n",
       " 11       0.8882      0.1940      0.0257      0.0231      0.0530      0.0281   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.8975      0.1373      0.0264      0.0250      0.0458      0.0303   \n",
       " 441      0.8923      0.1623      0.0253      0.0240      0.0539      0.0306   \n",
       " 442      0.9020      0.1716      0.0255      0.0241      0.0559      0.0366   \n",
       " 444      0.9193      0.1540      0.0280      0.0253      0.0589      0.0283   \n",
       " 447      0.8799      0.1336      0.0245      0.0227      0.0486      0.0303   \n",
       " \n",
       "      cg06968181  cg15421363  cg15995771  cg12451177  cg26326527  cg01694276  \\\n",
       " 0        0.0588      0.1614      0.0234      0.0203      0.9272      0.9723   \n",
       " 2        0.0600      0.1691      0.0231      0.0191      0.9377      0.9787   \n",
       " 5        0.0630      0.1806      0.0270      0.0221      0.9699      0.9723   \n",
       " 6        0.0612      0.1165      0.0299      0.0185      0.9653      0.9771   \n",
       " 11       0.0561      0.1660      0.0239      0.0225      0.9256      0.9740   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0537      0.1322      0.0259      0.0168      0.9677      0.9774   \n",
       " 441      0.0667      0.1328      0.0251      0.0195      0.9654      0.9746   \n",
       " 442      0.0587      0.1539      0.0286      0.0176      0.9575      0.9719   \n",
       " 444      0.0593      0.1605      0.0237      0.0268      0.9444      0.9782   \n",
       " 447      0.0574      0.1182      0.0269      0.0179      0.9661      0.9723   \n",
       " \n",
       "      cg06937024  cg18181229  cg03342114  cg23729501  cg20252769  cg20513080  \\\n",
       " 0        0.0204      0.8831      0.0233      0.6147      0.8571      0.9815   \n",
       " 2        0.0208      0.9019      0.0292      0.6205      0.7630      0.9838   \n",
       " 5        0.0232      0.9404      0.0220      0.6550      0.8633      0.9845   \n",
       " 6        0.0224      0.9338      0.0268      0.6511      0.8216      0.9789   \n",
       " 11       0.0189      0.8781      0.0206      0.6255      0.8912      0.9835   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0204      0.9472      0.0245      0.6244      0.8490      0.9804   \n",
       " 441      0.0193      0.9252      0.0224      0.6472      0.7924      0.9859   \n",
       " 442      0.0221      0.9183      0.0234      0.6483      0.8365      0.9805   \n",
       " 444      0.0195      0.9213      0.0190      0.7225      0.8854      0.9842   \n",
       " 447      0.0222      0.9093      0.0230      0.6264      0.7754      0.9848   \n",
       " \n",
       "      cg09775582  cg09774179  cg14222879  cg07493520  cg25975379  cg24513967  \\\n",
       " 0        0.0196      0.9750      0.0553      0.9758      0.0174      0.0409   \n",
       " 2        0.0178      0.9699      0.0330      0.9768      0.0163      0.0370   \n",
       " 5        0.0207      0.9778      0.0357      0.9790      0.0183      0.0317   \n",
       " 6        0.0205      0.9790      0.0333      0.9735      0.0176      0.0380   \n",
       " 11       0.0206      0.9841      0.0756      0.9819      0.0182      0.0400   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0169      0.9847      0.0341      0.9837      0.0169      0.0325   \n",
       " 441      0.0185      0.9730      0.0423      0.9772      0.0169      0.0422   \n",
       " 442      0.0207      0.9806      0.0518      0.9779      0.0190      0.0449   \n",
       " 444      0.0210      0.9801      0.0389      0.9830      0.0197      0.0345   \n",
       " 447      0.0196      0.9715      0.0383      0.9747      0.0186      0.0325   \n",
       " \n",
       "      cg14815005  cg18512446  cg23029363  cg03017418  cg07161166  cg16536399  \\\n",
       " 0        0.0269      0.8984      0.9429      0.0201      0.0185      0.9737   \n",
       " 2        0.0209      0.8969      0.9235      0.0207      0.0225      0.9760   \n",
       " 5        0.0241      0.9252      0.9497      0.0194      0.0204      0.9758   \n",
       " 6        0.0256      0.8721      0.9297      0.0230      0.0221      0.9809   \n",
       " 11       0.0227      0.9116      0.9533      0.0208      0.0208      0.9804   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0250      0.8941      0.9485      0.0203      0.0194      0.9831   \n",
       " 441      0.0290      0.8973      0.9348      0.0203      0.0217      0.9809   \n",
       " 442      0.0240      0.8736      0.9383      0.0201      0.0219      0.9855   \n",
       " 444      0.0238      0.9079      0.9568      0.0207      0.0205      0.9838   \n",
       " 447      0.0251      0.8985      0.9436      0.0206      0.0200      0.9763   \n",
       " \n",
       "      cg06751603  cg09145595  cg24994111  cg03025248  cg04444394  cg09658066  \\\n",
       " 0        0.9387      0.0212      0.0263      0.9353      0.2027      0.1214   \n",
       " 2        0.9248      0.0170      0.0203      0.9430      0.2162      0.1294   \n",
       " 5        0.9297      0.0209      0.0252      0.9564      0.2033      0.1174   \n",
       " 6        0.9171      0.0192      0.0231      0.9323      0.1887      0.1249   \n",
       " 11       0.9202      0.0191      0.0225      0.9553      0.1854      0.1880   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.9356      0.0166      0.0272      0.9546      0.1642      0.1453   \n",
       " 441      0.9190      0.0173      0.0201      0.9501      0.1778      0.1150   \n",
       " 442      0.9183      0.0202      0.0246      0.9279      0.2092      0.1133   \n",
       " 444      0.9200      0.0203      0.0234      0.9419      0.1628      0.1925   \n",
       " 447      0.9255      0.0184      0.0209      0.9618      0.1917      0.1080   \n",
       " \n",
       "      cg19542907  cg22203965  cg05941961  cg01616215  cg12103707  cg15844381  \\\n",
       " 0        0.0297      0.0143      0.0297      0.0110      0.9689      0.0349   \n",
       " 2        0.0262      0.0137      0.0225      0.0096      0.9744      0.0222   \n",
       " 5        0.0240      0.0130      0.0252      0.0106      0.9702      0.0267   \n",
       " 6        0.0204      0.0122      0.0277      0.0106      0.9690      0.0281   \n",
       " 11       0.0237      0.0124      0.0261      0.0086      0.9728      0.0305   \n",
       " ..          ...         ...         ...         ...         ...         ...   \n",
       " 440      0.0240      0.0127      0.0253      0.0098      0.9715      0.0235   \n",
       " 441      0.0274      0.0098      0.0237      0.0107      0.9700      0.0270   \n",
       " 442      0.0231      0.0109      0.0291      0.0094      0.9681      0.0360   \n",
       " 444      0.0287      0.0116      0.0267      0.0114      0.9747      0.0323   \n",
       " 447      0.0208      0.0110      0.0260      0.0119      0.9713      0.0270   \n",
       " \n",
       "      cg15074930  cg15260466  cg19476788  cg11971752  ...  \\\n",
       " 0        0.0567      0.0150      0.8810      0.0275  ...   \n",
       " 2        0.0575      0.0137      0.8655      0.0199  ...   \n",
       " 5        0.0486      0.0155      0.9108      0.0245  ...   \n",
       " 6        0.0505      0.0144      0.8665      0.0248  ...   \n",
       " 11       0.0495      0.0131      0.8819      0.0229  ...   \n",
       " ..          ...         ...         ...         ...  ...   \n",
       " 440      0.0405      0.0151      0.8969      0.0262  ...   \n",
       " 441      0.0558      0.0125      0.8758      0.0218  ...   \n",
       " 442      0.0476      0.0141      0.8805      0.0259  ...   \n",
       " 444      0.0540      0.0151      0.8836      0.0270  ...   \n",
       " 447      0.0436      0.0124      0.8850      0.0236  ...   \n",
       " \n",
       "      w1c1_L1_21_drugs_alcohol  w1c1_L1_23_Divorce  w1c1_L1_24_Lost_Job  \\\n",
       " 0                           1                   2                    2   \n",
       " 2                           2                   2                    2   \n",
       " 5                           2                   2                    1   \n",
       " 6                           2                   2                    2   \n",
       " 11                          2                   1                    2   \n",
       " ..                        ...                 ...                  ...   \n",
       " 440                         2                   2                    1   \n",
       " 441                         1                   2                    2   \n",
       " 442                         2                   1                    1   \n",
       " 444                         1                   2                    2   \n",
       " 447                         2                   1                    1   \n",
       " \n",
       "      w1c1_L1_25_Emotionally_mistreated  w1c1_L1_27_Legal_problems  \\\n",
       " 0                                    2                          2   \n",
       " 2                                    2                          2   \n",
       " 5                                    2                          2   \n",
       " 6                                    2                          2   \n",
       " 11                                   2                          2   \n",
       " ..                                 ...                        ...   \n",
       " 440                                  2                          1   \n",
       " 441                                  2                          2   \n",
       " 442                                  1                          1   \n",
       " 444                                  2                          2   \n",
       " 447                                  2                          2   \n",
       " \n",
       "      w1c1_L1_28_Unemployed  w1c1_L1_29_Financial_probs  \\\n",
       " 0                        2                           1   \n",
       " 2                        2                           1   \n",
       " 5                        2                           1   \n",
       " 6                        2                           2   \n",
       " 11                       2                           1   \n",
       " ..                     ...                         ...   \n",
       " 440                      1                           1   \n",
       " 441                      1                           2   \n",
       " 442                      1                           2   \n",
       " 444                      2                           2   \n",
       " 447                      1                           2   \n",
       " \n",
       "      w2c1_L1_21_drugs_alcohol  w2c1_L1_23_Divorce  w2c1_L1_24_Lost_Job  \\\n",
       " 0                           2                   2                    2   \n",
       " 2                           2                   2                    2   \n",
       " 5                           2                   2                    2   \n",
       " 6                           2                   2                    2   \n",
       " 11                          2                   2                    2   \n",
       " ..                        ...                 ...                  ...   \n",
       " 440                         2                   2                    2   \n",
       " 441                         2                   2                    2   \n",
       " 442                         2                   2                    2   \n",
       " 444                         1                   2                    2   \n",
       " 447                         2                   2                    2   \n",
       " \n",
       "      w2c1_L1_25_Emotionally_mistreated  w2c1_L1_27_Legal_problems  \\\n",
       " 0                                    2                          2   \n",
       " 2                                    2                          2   \n",
       " 5                                    1                          2   \n",
       " 6                                    2                          2   \n",
       " 11                                   2                          2   \n",
       " ..                                 ...                        ...   \n",
       " 440                                  2                          2   \n",
       " 441                                  2                          2   \n",
       " 442                                  2                          2   \n",
       " 444                                  2                          2   \n",
       " 447                                  2                          2   \n",
       " \n",
       "      w2c1_L1_28_Unemployed  w2c1_L1_29_Financial_probs  \\\n",
       " 0                        2                           2   \n",
       " 2                        1                           1   \n",
       " 5                        2                           1   \n",
       " 6                        2                           2   \n",
       " 11                       2                           1   \n",
       " ..                     ...                         ...   \n",
       " 440                      2                           2   \n",
       " 441                      1                           2   \n",
       " 442                      1                           2   \n",
       " 444                      2                           2   \n",
       " 447                      2                           2   \n",
       " \n",
       "      w3_L1_21_drugs_alcohol  w3_L1_23_Divorce  w3_L1_24_Lost_Job  \\\n",
       " 0                         2                 2                  2   \n",
       " 2                         2                 2                  2   \n",
       " 5                         2                 2                  2   \n",
       " 6                         2                 2                  2   \n",
       " 11                        2                 2                  2   \n",
       " ..                      ...               ...                ...   \n",
       " 440                       2                 2                  2   \n",
       " 441                       1                 2                  2   \n",
       " 442                       2                 2                  2   \n",
       " 444                       1                 2                  2   \n",
       " 447                       2                 2                  2   \n",
       " \n",
       "      w3_L1_25_Emotionally_mistreated  w3_L1_27_Legal_problems  \\\n",
       " 0                                  2                        2   \n",
       " 2                                  2                        1   \n",
       " 5                                  2                        2   \n",
       " 6                                  2                        2   \n",
       " 11                                 2                        2   \n",
       " ..                               ...                      ...   \n",
       " 440                                2                        2   \n",
       " 441                                2                        2   \n",
       " 442                                2                        2   \n",
       " 444                                2                        2   \n",
       " 447                                2                        2   \n",
       " \n",
       "      w3_L1_28_Unemployed  w3_L1_29_Financial_probs  w3_NN1_Loneliness_Scale1  \\\n",
       " 0                      2                         2                         2   \n",
       " 2                      1                         1                         2   \n",
       " 5                      1                         1                         3   \n",
       " 6                      2                         2                         1   \n",
       " 11                     2                         1                         2   \n",
       " ..                   ...                       ...                       ...   \n",
       " 440                    2                         2                         1   \n",
       " 441                    2                         2                         2   \n",
       " 442                    2                         2                         1   \n",
       " 444                    2                         1                         1   \n",
       " 447                    2                         2                         1   \n",
       " \n",
       "      w3_NN2_Loneliness_Scale2  w3_NN3_Loneliness_Scale3  \\\n",
       " 0                           1                         2   \n",
       " 2                           1                         2   \n",
       " 5                           2                         1   \n",
       " 6                           1                         1   \n",
       " 11                          1                         1   \n",
       " ..                        ...                       ...   \n",
       " 440                         1                         1   \n",
       " 441                         2                         2   \n",
       " 442                         1                         1   \n",
       " 444                         1                         1   \n",
       " 447                         1                         1   \n",
       " \n",
       "      w3_J1_Perceived_discrimination1  w3_J2_Perceived_discrimination2  \\\n",
       " 0                                  4                                2   \n",
       " 2                                  3                                3   \n",
       " 5                                  4                                4   \n",
       " 6                                  4                                4   \n",
       " 11                                 4                                4   \n",
       " ..                               ...                              ...   \n",
       " 440                                2                                4   \n",
       " 441                                4                                2   \n",
       " 442                                4                                3   \n",
       " 444                                4                                4   \n",
       " 447                                4                                4   \n",
       " \n",
       "      w3_J3_Perceived_discrimination3  w3_J4_Perceived_discrimination4  \\\n",
       " 0                                  4                                4   \n",
       " 2                                  4                                2   \n",
       " 5                                  2                                4   \n",
       " 6                                  4                                4   \n",
       " 11                                 4                                4   \n",
       " ..                               ...                              ...   \n",
       " 440                                2                                4   \n",
       " 441                                4                                1   \n",
       " 442                                4                                3   \n",
       " 444                                4                                4   \n",
       " 447                                4                                4   \n",
       " \n",
       "      w3_J5_Perceived_discrimination5  w3_J6_Perceived_discrimination6  \\\n",
       " 0                                  4                                4   \n",
       " 2                                  2                                2   \n",
       " 5                                  4                                4   \n",
       " 6                                  4                                4   \n",
       " 11                                 4                                4   \n",
       " ..                               ...                              ...   \n",
       " 440                                4                                1   \n",
       " 441                                2                                4   \n",
       " 442                                3                                3   \n",
       " 444                                4                                4   \n",
       " 447                                4                                3   \n",
       " \n",
       "      w3_J7_Perceived_discrimination7  w3_J8_Perceived_discrimination8  \\\n",
       " 0                                  3                                4   \n",
       " 2                                  2                                2   \n",
       " 5                                  4                                4   \n",
       " 6                                  4                                4   \n",
       " 11                                 4                                4   \n",
       " ..                               ...                              ...   \n",
       " 440                                4                                4   \n",
       " 441                                2                                4   \n",
       " 442                                4                                4   \n",
       " 444                                2                                4   \n",
       " 447                                4                                4   \n",
       " \n",
       "      w3_J9_Perceived_discrimination9  w1_educ_Participant  \\\n",
       " 0                                  4                    5   \n",
       " 2                                  2                    7   \n",
       " 5                                  4                    3   \n",
       " 6                                  4                    3   \n",
       " 11                                 4                    7   \n",
       " ..                               ...                  ...   \n",
       " 440                                4                    6   \n",
       " 441                                4                    5   \n",
       " 442                                4                    7   \n",
       " 444                                4                    5   \n",
       " 447                                4                    6   \n",
       " \n",
       "      w2_educ_Participant  w3_educ_Participant  w3_U8B_Mothers_edu  \\\n",
       " 0                      5                    5                   1   \n",
       " 2                      8                    8                   2   \n",
       " 5                      3                    3                   1   \n",
       " 6                      3                    3                  98   \n",
       " 11                     7                    7                   2   \n",
       " ..                   ...                  ...                 ...   \n",
       " 440                    6                    6                   2   \n",
       " 441                    5                    7                   2   \n",
       " 442                    8                    8                   5   \n",
       " 444                    5                    5                   2   \n",
       " 447                    6                    6                   2   \n",
       " \n",
       "      w3_U8C_Fathers_edu  w1c1_stress2_drugs_alcohol  w1c1_stress4_Divorce  \\\n",
       " 0                     1                           1                     0   \n",
       " 2                     2                           0                     0   \n",
       " 5                     1                           0                     0   \n",
       " 6                    98                           0                     0   \n",
       " 11                    2                           0                     1   \n",
       " ..                  ...                         ...                   ...   \n",
       " 440                   2                           0                     0   \n",
       " 441                   2                           1                     0   \n",
       " 442                   4                           0                     1   \n",
       " 444                  98                           1                     0   \n",
       " 447                   2                           0                     1   \n",
       " \n",
       "      w1c1_stress5_Lost_Job  w1c1_stress6_Emotionally_mistreated  \\\n",
       " 0                        0                                    0   \n",
       " 2                        0                                    0   \n",
       " 5                        1                                    0   \n",
       " 6                        0                                    0   \n",
       " 11                       0                                    0   \n",
       " ..                     ...                                  ...   \n",
       " 440                      1                                    0   \n",
       " 441                      0                                    0   \n",
       " 442                      1                                    1   \n",
       " 444                      0                                    0   \n",
       " 447                      1                                    0   \n",
       " \n",
       "      w1c1_stress8_Legal_problems  w1c1_stress9_Unemployed  \\\n",
       " 0                              0                        0   \n",
       " 2                              0                        0   \n",
       " 5                              0                        0   \n",
       " 6                              0                        0   \n",
       " 11                             0                        0   \n",
       " ..                           ...                      ...   \n",
       " 440                            1                        1   \n",
       " 441                            0                        1   \n",
       " 442                            1                        1   \n",
       " 444                            0                        0   \n",
       " 447                            0                        1   \n",
       " \n",
       "      w1c1_stress10_Financial_probs  w1c1_traumanum  w1c1_PTSDlife  \\\n",
       " 0                                1               6              0   \n",
       " 2                                1               0              0   \n",
       " 5                                1               4              0   \n",
       " 6                                0               1              0   \n",
       " 11                               1               3              0   \n",
       " ..                             ...             ...            ...   \n",
       " 440                              1              10              0   \n",
       " 441                              0               4              0   \n",
       " 442                              0               6              0   \n",
       " 444                              0               3              0   \n",
       " 447                              0               6              0   \n",
       " \n",
       "      w1c1_PTSDpy  w1c1_PTSDpm  w1c1_phq9cat_Depression_severity  \\\n",
       " 0              0            0                                 3   \n",
       " 2              0            0                                 2   \n",
       " 5              0            0                                 3   \n",
       " 6              0            0                                 2   \n",
       " 11             0            0                                 1   \n",
       " ..           ...          ...                               ...   \n",
       " 440            0            0                                 2   \n",
       " 441            0            0                                 3   \n",
       " 442            0            0                                 4   \n",
       " 444            0            0                                 3   \n",
       " 447            0            0                                 1   \n",
       " \n",
       "      w1c1_gad7cat_generalized_anx_symp_severity  w2c1_stress2_drugs_alcohol  \\\n",
       " 0                                             3                           0   \n",
       " 2                                             2                           0   \n",
       " 5                                             1                           0   \n",
       " 6                                             2                           0   \n",
       " 11                                            3                           0   \n",
       " ..                                          ...                         ...   \n",
       " 440                                           2                           0   \n",
       " 441                                           2                           0   \n",
       " 442                                           3                           0   \n",
       " 444                                           1                           1   \n",
       " 447                                           2                           0   \n",
       " \n",
       "      w2c1_stress4_Divorce  w2c1_stress5_Lost_Job  \\\n",
       " 0                       0                      0   \n",
       " 2                       0                      0   \n",
       " 5                       0                      0   \n",
       " 6                       0                      0   \n",
       " 11                      0                      0   \n",
       " ..                    ...                    ...   \n",
       " 440                     0                      0   \n",
       " 441                     0                      0   \n",
       " 442                     0                      0   \n",
       " 444                     0                      0   \n",
       " 447                     0                      0   \n",
       " \n",
       "      w2c1_stress6_Emotionally_mistreated  w2c1_stress8_Legal_problems  \\\n",
       " 0                                      0                            0   \n",
       " 2                                      0                            0   \n",
       " 5                                      1                            0   \n",
       " 6                                      0                            0   \n",
       " 11                                     0                            0   \n",
       " ..                                   ...                          ...   \n",
       " 440                                    0                            0   \n",
       " 441                                    0                            0   \n",
       " 442                                    0                            0   \n",
       " 444                                    0                            0   \n",
       " 447                                    0                            0   \n",
       " \n",
       "      w2c1_stress9_Unemployed  w2c1_stress10_Financial_probs  w2c1_traumanum  \\\n",
       " 0                          0                              0               0   \n",
       " 2                          1                              1               1   \n",
       " 5                          0                              1               3   \n",
       " 6                          0                              0               0   \n",
       " 11                         0                              1               0   \n",
       " ..                       ...                            ...             ...   \n",
       " 440                        0                              0               0   \n",
       " 441                        1                              0               0   \n",
       " 442                        1                              0               2   \n",
       " 444                        0                              0               0   \n",
       " 447                        0                              0               0   \n",
       " \n",
       "      w2c1_pyphq9cat_Depression_severity  \\\n",
       " 0                                     1   \n",
       " 2                                     1   \n",
       " 5                                     3   \n",
       " 6                                     2   \n",
       " 11                                    2   \n",
       " ..                                  ...   \n",
       " 440                                   1   \n",
       " 441                                   3   \n",
       " 442                                   4   \n",
       " 444                                   3   \n",
       " 447                                   2   \n",
       " \n",
       "      w2c1_gad7cat_py_generalized_anx_symp_severity  w2c1_PTSDlife  \\\n",
       " 0                                                1              0   \n",
       " 2                                                1              0   \n",
       " 5                                                1              0   \n",
       " 6                                                1              0   \n",
       " 11                                               1              0   \n",
       " ..                                             ...            ...   \n",
       " 440                                              1              0   \n",
       " 441                                              1              1   \n",
       " 442                                              1              0   \n",
       " 444                                              1              0   \n",
       " 447                                              1              0   \n",
       " \n",
       "      w2c1_PTSDpy  w2c1_PTSDpm  w3_stress2_drugs_alcohol  w3_stress4_Divorce  \\\n",
       " 0              0            0                         0                   0   \n",
       " 2              0            0                         0                   0   \n",
       " 5              0            0                         0                   0   \n",
       " 6              0            0                         0                   0   \n",
       " 11             0            0                         0                   0   \n",
       " ..           ...          ...                       ...                 ...   \n",
       " 440            0            0                         0                   0   \n",
       " 441            1            0                         1                   0   \n",
       " 442            0            0                         0                   0   \n",
       " 444            0            0                         1                   0   \n",
       " 447            0            0                         0                   0   \n",
       " \n",
       "      w3_stress5_Lost_Job  w3_stress6_Emotionally_mistreated  \\\n",
       " 0                      0                                  0   \n",
       " 2                      0                                  0   \n",
       " 5                      0                                  0   \n",
       " 6                      0                                  0   \n",
       " 11                     0                                  0   \n",
       " ..                   ...                                ...   \n",
       " 440                    0                                  0   \n",
       " 441                    0                                  0   \n",
       " 442                    0                                  0   \n",
       " 444                    0                                  0   \n",
       " 447                    0                                  0   \n",
       " \n",
       "      w3_stress8_Legal_problems  w3_stress9_Unemployed  \\\n",
       " 0                            0                      0   \n",
       " 2                            1                      1   \n",
       " 5                            0                      1   \n",
       " 6                            0                      0   \n",
       " 11                           0                      0   \n",
       " ..                         ...                    ...   \n",
       " 440                          0                      0   \n",
       " 441                          0                      0   \n",
       " 442                          0                      0   \n",
       " 444                          0                      0   \n",
       " 447                          0                      0   \n",
       " \n",
       "      w3_stress10_Financial_probs  w3_traumanum  \\\n",
       " 0                              0             1   \n",
       " 2                              1             1   \n",
       " 5                              1             0   \n",
       " 6                              0             0   \n",
       " 11                             1             1   \n",
       " ..                           ...           ...   \n",
       " 440                            0             2   \n",
       " 441                            0             2   \n",
       " 442                            0             0   \n",
       " 444                            1             1   \n",
       " 447                            0             1   \n",
       " \n",
       "      w3_slphq9cat_Depression_severity  \\\n",
       " 0                                   2   \n",
       " 2                                   1   \n",
       " 5                                   3   \n",
       " 6                                   1   \n",
       " 11                                  2   \n",
       " ..                                ...   \n",
       " 440                                 1   \n",
       " 441                                 5   \n",
       " 442                                 2   \n",
       " 444                                 2   \n",
       " 447                                 1   \n",
       " \n",
       "      w3_gad7cat_sl_generalized_anx_symp_severity  w3_PTSDlife  w3_PTSDsl  \\\n",
       " 0                                              3            0          0   \n",
       " 2                                              2            1          1   \n",
       " 5                                              1            0          0   \n",
       " 6                                              3            0          0   \n",
       " 11                                             3            0          0   \n",
       " ..                                           ...          ...        ...   \n",
       " 440                                            2            0          0   \n",
       " 441                                            3            1          1   \n",
       " 442                                            2            0          0   \n",
       " 444                                            2            0          0   \n",
       " 447                                            2            0          0   \n",
       " \n",
       "      w3_PTSDpm  w1c1_life_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0            0                                           35   \n",
       " 2            1                                           44   \n",
       " 5            0                                           28   \n",
       " 6            0                                           21   \n",
       " 11           0                                           18   \n",
       " ..         ...                                          ...   \n",
       " 440          0                                           32   \n",
       " 441          1                                           31   \n",
       " 442          0                                           23   \n",
       " 444          0                                           50   \n",
       " 447          0                                           26   \n",
       " \n",
       "      w1c1_life_worst_intrusion  w1c1_life_worst_avoidance  \\\n",
       " 0                           13                         17   \n",
       " 2                           10                         18   \n",
       " 5                           10                          9   \n",
       " 6                            9                          7   \n",
       " 11                           5                          7   \n",
       " ..                         ...                        ...   \n",
       " 440                          9                         13   \n",
       " 441                         10                         12   \n",
       " 442                          6                         10   \n",
       " 444                         18                         18   \n",
       " 447                         10                         11   \n",
       " \n",
       "      w1c1_life_worst_hyperarousal  w2c1_inc_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                               5                                          40   \n",
       " 2                              15                                          31   \n",
       " 5                               8                                          31   \n",
       " 6                               5                                          18   \n",
       " 11                              6                                          27   \n",
       " ..                            ...                                         ...   \n",
       " 440                            10                                          17   \n",
       " 441                             9                                          17   \n",
       " 442                             7                                          20   \n",
       " 444                            14                                          20   \n",
       " 447                             5                                          23   \n",
       " \n",
       "      w2c1_inc_worst_intrusion  w2c1_inc_worst_avoidance  \\\n",
       " 0                           5                        18   \n",
       " 2                          11                        11   \n",
       " 5                          14                        10   \n",
       " 6                           5                         7   \n",
       " 11                          5                         8   \n",
       " ..                        ...                       ...   \n",
       " 440                         5                         7   \n",
       " 441                         5                         7   \n",
       " 442                         7                         8   \n",
       " 444                        10                         8   \n",
       " 447                         5                         8   \n",
       " \n",
       "      w2c1_inc_worst_hyperarousal  w2c1_r_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                             14                                        27   \n",
       " 2                              9                                        34   \n",
       " 5                              7                                        25   \n",
       " 6                              5                                        29   \n",
       " 11                             6                                        18   \n",
       " ..                           ...                                       ...   \n",
       " 440                            5                                        17   \n",
       " 441                            5                                        44   \n",
       " 442                            5                                        41   \n",
       " 444                            5                                        30   \n",
       " 447                            7                                        24   \n",
       " \n",
       "      w2c1_r_worst_intrusion  w2c1_r_worst_avoidance  \\\n",
       " 0                        10                      11   \n",
       " 2                         7                      10   \n",
       " 5                         7                       9   \n",
       " 6                         8                      15   \n",
       " 11                        5                       7   \n",
       " ..                      ...                     ...   \n",
       " 440                       5                       7   \n",
       " 441                       8                      23   \n",
       " 442                      11                      19   \n",
       " 444                       9                      11   \n",
       " 447                       9                       9   \n",
       " \n",
       "      w2c1_r_worst_hyperarousal  w3_inc_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                            6                                        33   \n",
       " 2                           10                                        43   \n",
       " 5                            9                                        35   \n",
       " 6                            6                                        47   \n",
       " 11                           6                                        19   \n",
       " ..                         ...                                       ...   \n",
       " 440                          5                                        21   \n",
       " 441                         13                                        79   \n",
       " 442                         10                                        19   \n",
       " 444                         10                                        34   \n",
       " 447                          6                                        17   \n",
       " \n",
       "      w3_inc_worst_intrusion  w3_inc_worst_avoidance  \\\n",
       " 0                        17                      15   \n",
       " 2                        15                      17   \n",
       " 5                        10                      15   \n",
       " 6                        16                      18   \n",
       " 11                        6                       8   \n",
       " ..                      ...                     ...   \n",
       " 440                       7                       9   \n",
       " 441                      23                      31   \n",
       " 442                       6                       8   \n",
       " 444                      12                       9   \n",
       " 447                       5                       7   \n",
       " \n",
       "      w3_inc_worst_hyperarousal  w3_r_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                           10                                      32   \n",
       " 2                           11                                      17   \n",
       " 5                           10                                      27   \n",
       " 6                           19                                      17   \n",
       " 11                           5                                      17   \n",
       " ..                         ...                                     ...   \n",
       " 440                          5                                      19   \n",
       " 441                         25                                      20   \n",
       " 442                          5                                      21   \n",
       " 444                         13                                      41   \n",
       " 447                          5                                      33   \n",
       " \n",
       "      w3_r_worst_intrusion  w3_r_worst_avoidance  w3_r_worst_hyperarousal  \\\n",
       " 0                       5                    14                       10   \n",
       " 2                       5                     7                        5   \n",
       " 5                       9                    11                        7   \n",
       " 6                       5                     7                       10   \n",
       " 11                     16                     7                       10   \n",
       " ..                    ...                   ...                      ...   \n",
       " 440                     5                     7                       10   \n",
       " 441                    16                     7                       10   \n",
       " 442                     7                     7                        5   \n",
       " 444                     5                    13                       10   \n",
       " 447                     5                    14                       10   \n",
       " \n",
       "      w2c1_life_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                                             35   \n",
       " 2                                             31   \n",
       " 5                                             31   \n",
       " 6                                             29   \n",
       " 11                                            18   \n",
       " ..                                           ...   \n",
       " 440                                           32   \n",
       " 441                                           44   \n",
       " 442                                           23   \n",
       " 444                                           50   \n",
       " 447                                           26   \n",
       " \n",
       "      w3_life_sumptsdworst_PTS_symptom_severity  TraumaNum  \n",
       " 0                                           35          6  \n",
       " 2                                           43          1  \n",
       " 5                                           31          4  \n",
       " 6                                           29          1  \n",
       " 11                                          19          3  \n",
       " ..                                         ...        ...  \n",
       " 440                                         32         10  \n",
       " 441                                         79          4  \n",
       " 442                                         23          6  \n",
       " 444                                         50          3  \n",
       " 447                                         26          6  \n",
       " \n",
       " [210 rows x 2728 columns],\n",
       " 'full_df_long':      cg11188799_1  cg19586199_1  cg03354771_1  cg16246200_1  cg12700033_1  \\\n",
       " 0          0.0128        0.9573        0.0279        0.9758        0.0445   \n",
       " 1          0.0142        0.9600        0.0264        0.9803        0.0405   \n",
       " 2          0.0123        0.9662        0.0271        0.9746        0.0354   \n",
       " 3          0.0092        0.9579        0.0293        0.9793        0.0321   \n",
       " 4          0.0117        0.9552        0.0229        0.9828        0.0381   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0116        0.9597        0.0277        0.9803        0.0347   \n",
       " 144        0.0117        0.9626        0.0234        0.9786        0.0345   \n",
       " 145        0.0128        0.9619        0.0225        0.9761        0.0343   \n",
       " 146        0.0125        0.9668        0.0253        0.9804        0.0371   \n",
       " 147        0.0143        0.9607        0.0256        0.9748        0.0428   \n",
       " \n",
       "      cg15500320_1  cg13374701_1  cg11090676_1  cg00935119_1  cg26116980_1  \\\n",
       " 0          0.0161        0.9554        0.0283        0.0274        0.9857   \n",
       " 1          0.0138        0.9468        0.0243        0.0260        0.9883   \n",
       " 2          0.0150        0.9603        0.0266        0.0233        0.9853   \n",
       " 3          0.0124        0.9520        0.0254        0.0257        0.9858   \n",
       " 4          0.0133        0.9549        0.0243        0.0280        0.9883   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0173        0.9510        0.0285        0.0235        0.9879   \n",
       " 144        0.0154        0.9385        0.0275        0.0227        0.9885   \n",
       " 145        0.0151        0.9476        0.0271        0.0275        0.9876   \n",
       " 146        0.0163        0.9497        0.0269        0.0255        0.9857   \n",
       " 147        0.0164        0.9509        0.0296        0.0262        0.9864   \n",
       " \n",
       "      cg01529076_1  cg01362515_1  cg01320969_1  cg27005894_1  cg22402853_1  \\\n",
       " 0          0.4791        0.8271        0.0261        0.0310        0.0262   \n",
       " 1          0.3465        0.7882        0.0240        0.0269        0.0258   \n",
       " 2          0.5169        0.7536        0.0248        0.0272        0.0212   \n",
       " 3          0.4396        0.7273        0.0265        0.0278        0.0208   \n",
       " 4          0.4182        0.6808        0.0227        0.0276        0.0232   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.3944        0.7694        0.0249        0.0296        0.0216   \n",
       " 144        0.4504        0.7519        0.0286        0.0299        0.0232   \n",
       " 145        0.3915        0.7912        0.0224        0.0302        0.0219   \n",
       " 146        0.4502        0.8074        0.0224        0.0272        0.0230   \n",
       " 147        0.3782        0.7883        0.0268        0.0321        0.0218   \n",
       " \n",
       "      cg15096815_1  cg16101035_1  cg18071894_1  cg06846259_1  cg10105971_1  \\\n",
       " 0          0.0455        0.0401        0.4430        0.7145        0.0948   \n",
       " 1          0.0339        0.0377        0.4112        0.5670        0.0657   \n",
       " 2          0.0341        0.0392        0.4984        0.6336        0.0884   \n",
       " 3          0.0310        0.0365        0.4269        0.5899        0.0901   \n",
       " 4          0.0384        0.0340        0.4519        0.7285        0.1017   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0280        0.0357        0.3623        0.6809        0.0829   \n",
       " 144        0.0425        0.0383        0.4097        0.7210        0.1044   \n",
       " 145        0.0455        0.0400        0.4492        0.6495        0.1001   \n",
       " 146        0.0302        0.0359        0.4633        0.5940        0.0985   \n",
       " 147        0.0437        0.0408        0.3802        0.7176        0.0791   \n",
       " \n",
       "      cg03384545_1  cg05859578_1  cg05898629_1  cg25053252_1  cg22322863_1  \\\n",
       " 0          0.0215        0.9113        0.9552        0.0299        0.0225   \n",
       " 1          0.0255        0.9225        0.9683        0.0216        0.0192   \n",
       " 2          0.0197        0.9066        0.9664        0.0273        0.0234   \n",
       " 3          0.0215        0.9053        0.9712        0.0270        0.0224   \n",
       " 4          0.0181        0.8883        0.9584        0.0240        0.0194   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0188        0.8934        0.9647        0.0265        0.0221   \n",
       " 144        0.0193        0.8995        0.9609        0.0263        0.0235   \n",
       " 145        0.0203        0.9021        0.9637        0.0290        0.0227   \n",
       " 146        0.0195        0.8971        0.9466        0.0282        0.0247   \n",
       " 147        0.0227        0.8914        0.9625        0.0275        0.0233   \n",
       " \n",
       "      cg00039463_1  cg06633814_1  cg12271199_1  cg15900987_1  cg06959103_1  \\\n",
       " 0          0.6294        0.0350        0.0257        0.9270        0.0457   \n",
       " 1          0.6641        0.0221        0.0233        0.9137        0.0426   \n",
       " 2          0.6951        0.0268        0.0240        0.9320        0.0326   \n",
       " 3          0.6119        0.0370        0.0265        0.9183        0.0402   \n",
       " 4          0.6593        0.0287        0.0225        0.9190        0.0277   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.6035        0.0324        0.0229        0.9159        0.0413   \n",
       " 144        0.6715        0.0287        0.0243        0.9324        0.0396   \n",
       " 145        0.6295        0.0213        0.0242        0.9385        0.0429   \n",
       " 146        0.5680        0.0229        0.0239        0.9274        0.0436   \n",
       " 147        0.6149        0.0310        0.0265        0.9204        0.0441   \n",
       " \n",
       "      cg11872076_1  cg25034766_1  cg24718866_1  cg23014605_1  cg05970790_1  \\\n",
       " 0          0.0196        0.9589        0.0319        0.0404        0.0390   \n",
       " 1          0.0133        0.9625        0.0427        0.0318        0.0291   \n",
       " 2          0.0132        0.9661        0.0376        0.0392        0.0180   \n",
       " 3          0.0186        0.9663        0.0223        0.0364        0.0284   \n",
       " 4          0.0126        0.9610        0.0232        0.0408        0.0262   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0154        0.9627        0.0232        0.0369        0.0237   \n",
       " 144        0.0193        0.9499        0.0287        0.0377        0.0326   \n",
       " 145        0.0145        0.9621        0.0252        0.0354        0.0336   \n",
       " 146        0.0147        0.9627        0.0211        0.0354        0.0219   \n",
       " 147        0.0146        0.9572        0.0261        0.0362        0.0288   \n",
       " \n",
       "      cg15001636_1  cg06432200_1  cg16606005_1  cg12100463_1  cg10913456_1  \\\n",
       " 0          0.6868        0.5946        0.9752        0.8612        0.0167   \n",
       " 1          0.7150        0.6517        0.9633        0.8621        0.0141   \n",
       " 2          0.7103        0.6391        0.9689        0.8475        0.0139   \n",
       " 3          0.7028        0.6546        0.9710        0.8412        0.0186   \n",
       " 4          0.7182        0.6456        0.9719        0.8183        0.0135   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.6964        0.6123        0.9680        0.8526        0.0139   \n",
       " 144        0.6679        0.6100        0.9719        0.8695        0.0144   \n",
       " 145        0.6944        0.6270        0.9693        0.8700        0.0170   \n",
       " 146        0.6644        0.5795        0.9690        0.8413        0.0165   \n",
       " 147        0.7383        0.6486        0.9705        0.8575        0.0171   \n",
       " \n",
       "      cg11065262_1  cg15684811_1  cg09781971_1  cg02072813_1  cg14274357_1  \\\n",
       " 0          0.0355        0.0568        0.0419        0.8818        0.9372   \n",
       " 1          0.0277        0.0645        0.0420        0.8784        0.9123   \n",
       " 2          0.0286        0.0595        0.0439        0.8812        0.8816   \n",
       " 3          0.0314        0.0703        0.0436        0.8468        0.8924   \n",
       " 4          0.0325        0.0734        0.0450        0.8735        0.9403   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0304        0.0534        0.0444        0.8689        0.8363   \n",
       " 144        0.0343        0.0628        0.0441        0.8659        0.8852   \n",
       " 145        0.0273        0.0552        0.0374        0.8660        0.8638   \n",
       " 146        0.0312        0.0718        0.0456        0.8976        0.9487   \n",
       " 147        0.0340        0.0578        0.0446        0.8680        0.8552   \n",
       " \n",
       "      cg21209684_1  cg18014042_1  cg25579739_1  cg11844358_1  cg23564290_1  \\\n",
       " 0          0.0257        0.9657        0.0243        0.9849        0.0309   \n",
       " 1          0.0226        0.9699        0.0215        0.9859        0.0301   \n",
       " 2          0.0260        0.9675        0.0255        0.9857        0.0290   \n",
       " 3          0.0244        0.9687        0.0230        0.9863        0.0260   \n",
       " 4          0.0228        0.9594        0.0214        0.9861        0.0296   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0242        0.9717        0.0235        0.9851        0.0272   \n",
       " 144        0.0242        0.9627        0.0243        0.9853        0.0291   \n",
       " 145        0.0234        0.9690        0.0267        0.9844        0.0283   \n",
       " 146        0.0226        0.9674        0.0249        0.9849        0.0286   \n",
       " 147        0.0271        0.9632        0.0250        0.9834        0.0318   \n",
       " \n",
       "      cg05513979_1  cg06462174_1  cg20787340_1  cg01921845_1  cg22991936_1  \\\n",
       " 0          0.0345        0.2827        0.0150        0.9784        0.8866   \n",
       " 1          0.0390        0.2461        0.0149        0.9812        0.9011   \n",
       " 2          0.0321        0.2367        0.0139        0.9800        0.9135   \n",
       " 3          0.0312        0.2599        0.0155        0.9815        0.8873   \n",
       " 4          0.0285        0.2469        0.0172        0.9793        0.8829   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0301        0.2514        0.0161        0.9768        0.9011   \n",
       " 144        0.0372        0.2801        0.0171        0.9767        0.9072   \n",
       " 145        0.0305        0.2623        0.0171        0.9768        0.8958   \n",
       " 146        0.0327        0.2378        0.0153        0.9784        0.8922   \n",
       " 147        0.0397        0.2725        0.0162        0.9759        0.9013   \n",
       " \n",
       "      cg09679690_1  cg03562264_1  cg16374471_1  cg10189525_1  cg03090513_1  \\\n",
       " 0          0.1861        0.0332        0.0268        0.0489        0.0292   \n",
       " 1          0.1036        0.0198        0.0214        0.0558        0.0375   \n",
       " 2          0.1268        0.0273        0.0232        0.0407        0.0311   \n",
       " 3          0.1557        0.0312        0.0243        0.0591        0.0293   \n",
       " 4          0.1240        0.0259        0.0226        0.0446        0.0273   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.1523        0.0250        0.0219        0.0477        0.0301   \n",
       " 144        0.1557        0.0291        0.0229        0.0513        0.0329   \n",
       " 145        0.1903        0.0248        0.0238        0.0481        0.0336   \n",
       " 146        0.1720        0.0247        0.0256        0.0516        0.0303   \n",
       " 147        0.1703        0.0268        0.0249        0.0478        0.0312   \n",
       " \n",
       "      cg06968181_1  cg15421363_1  cg15995771_1  cg12451177_1  cg26326527_1  \\\n",
       " 0          0.0630        0.1806        0.0270        0.0221        0.9699   \n",
       " 1          0.0626        0.1170        0.0234        0.0227        0.9606   \n",
       " 2          0.0543        0.1257        0.0257        0.0178        0.9660   \n",
       " 3          0.0517        0.1744        0.0258        0.0171        0.9548   \n",
       " 4          0.0570        0.1506        0.0240        0.0164        0.8976   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0554        0.1444        0.0243        0.0197        0.9570   \n",
       " 144        0.0537        0.1561        0.0258        0.0192        0.9456   \n",
       " 145        0.0582        0.1617        0.0271        0.0190        0.9516   \n",
       " 146        0.0585        0.1571        0.0255        0.0197        0.9199   \n",
       " 147        0.0570        0.1540        0.0265        0.0202        0.9430   \n",
       " \n",
       "      cg01694276_1  cg06937024_1  cg18181229_1  cg03342114_1  cg23729501_1  \\\n",
       " 0          0.9723        0.0232        0.9404        0.0220        0.6550   \n",
       " 1          0.9778        0.0183        0.9190        0.0215        0.6737   \n",
       " 2          0.9793        0.0208        0.9395        0.0202        0.7024   \n",
       " 3          0.9776        0.0212        0.9110        0.0222        0.7541   \n",
       " 4          0.9790        0.0215        0.8778        0.0214        0.7243   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.9784        0.0193        0.9367        0.0180        0.6690   \n",
       " 144        0.9775        0.0188        0.9350        0.0259        0.6783   \n",
       " 145        0.9773        0.0201        0.9342        0.0224        0.7050   \n",
       " 146        0.9754        0.0205        0.8895        0.0207        0.6649   \n",
       " 147        0.9728        0.0197        0.9261        0.0257        0.6751   \n",
       " \n",
       "      cg20252769_1  cg20513080_1  cg09775582_1  cg09774179_1  cg14222879_1  \\\n",
       " 0          0.8633        0.9845        0.0207        0.9778        0.0357   \n",
       " 1          0.8515        0.9852        0.0186        0.9779        0.0496   \n",
       " 2          0.8671        0.9833        0.0192        0.9808        0.0503   \n",
       " 3          0.8635        0.9849        0.0187        0.9846        0.0617   \n",
       " 4          0.8646        0.9862        0.0177        0.9847        0.0298   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.8515        0.9819        0.0190        0.9787        0.0397   \n",
       " 144        0.8710        0.9838        0.0210        0.9829        0.0401   \n",
       " 145        0.8726        0.9826        0.0184        0.9809        0.0369   \n",
       " 146        0.8251        0.9811        0.0194        0.9808        0.0415   \n",
       " 147        0.8633        0.9819        0.0207        0.9808        0.0350   \n",
       " \n",
       "      cg07493520_1  cg25975379_1  cg24513967_1  cg14815005_1  cg18512446_1  \\\n",
       " 0          0.9790        0.0183        0.0317        0.0241        0.9252   \n",
       " 1          0.9799        0.0148        0.0407        0.0304        0.9118   \n",
       " 2          0.9769        0.0165        0.0409        0.0264        0.8953   \n",
       " 3          0.9767        0.0157        0.0315        0.0267        0.9144   \n",
       " 4          0.9778        0.0178        0.0323        0.0231        0.9026   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.9818        0.0164        0.0387        0.0215        0.8961   \n",
       " 144        0.9799        0.0176        0.0391        0.0261        0.9121   \n",
       " 145        0.9817        0.0199        0.0437        0.0207        0.9019   \n",
       " 146        0.9778        0.0193        0.0355        0.0278        0.9024   \n",
       " 147        0.9781        0.0204        0.0349        0.0242        0.9065   \n",
       " \n",
       "      cg23029363_1  cg03017418_1  cg07161166_1  cg16536399_1  cg06751603_1  \\\n",
       " 0          0.9497        0.0194        0.0204        0.9758        0.9297   \n",
       " 1          0.9486        0.0168        0.0191        0.9851        0.9515   \n",
       " 2          0.9509        0.0208        0.0204        0.9826        0.9351   \n",
       " 3          0.9514        0.0222        0.0200        0.9834        0.9387   \n",
       " 4          0.9502        0.0214        0.0195        0.9847        0.9342   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.9447        0.0203        0.0195        0.9830        0.9359   \n",
       " 144        0.9547        0.0194        0.0206        0.9795        0.9460   \n",
       " 145        0.9514        0.0211        0.0204        0.9826        0.9421   \n",
       " 146        0.9466        0.0198        0.0209        0.9742        0.9371   \n",
       " 147        0.9432        0.0234        0.0214        0.9816        0.9237   \n",
       " \n",
       "      cg09145595_1  cg24994111_1  cg03025248_1  cg04444394_1  cg09658066_1  \\\n",
       " 0          0.0209        0.0252        0.9564        0.2033        0.1174   \n",
       " 1          0.0174        0.0222        0.8989        0.1760        0.1342   \n",
       " 2          0.0185        0.0236        0.9452        0.1895        0.1229   \n",
       " 3          0.0187        0.0228        0.9490        0.1870        0.1355   \n",
       " 4          0.0168        0.0198        0.9493        0.1995        0.1347   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0190        0.0215        0.9321        0.1804        0.1361   \n",
       " 144        0.0184        0.0222        0.9454        0.1863        0.1485   \n",
       " 145        0.0209        0.0240        0.9600        0.1832        0.1235   \n",
       " 146        0.0195        0.0243        0.9530        0.2088        0.1236   \n",
       " 147        0.0190        0.0230        0.9554        0.1876        0.1585   \n",
       " \n",
       "      cg19542907_1  cg22203965_1  cg05941961_1  cg01616215_1  cg12103707_1  \\\n",
       " 0          0.0240        0.0130        0.0252        0.0106        0.9702   \n",
       " 1          0.0209        0.0107        0.0330        0.0082        0.9735   \n",
       " 2          0.0251        0.0127        0.0251        0.0124        0.9737   \n",
       " 3          0.0281        0.0123        0.0248        0.0092        0.9729   \n",
       " 4          0.0209        0.0127        0.0224        0.0100        0.9741   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0212        0.0110        0.0255        0.0100        0.9733   \n",
       " 144        0.0234        0.0119        0.0260        0.0110        0.9746   \n",
       " 145        0.0217        0.0102        0.0262        0.0102        0.9715   \n",
       " 146        0.0252        0.0127        0.0241        0.0091        0.9731   \n",
       " 147        0.0242        0.0159        0.0263        0.0108        0.9726   \n",
       " \n",
       "      cg15844381_1  cg15074930_1  cg15260466_1  cg19476788_1  cg11971752_1  \\\n",
       " 0          0.0267        0.0486        0.0155        0.9108        0.0245   \n",
       " 1          0.0274        0.0513        0.0132        0.8637        0.0227   \n",
       " 2          0.0212        0.0596        0.0127        0.8735        0.0232   \n",
       " 3          0.0276        0.0481        0.0142        0.9115        0.0227   \n",
       " 4          0.0226        0.0500        0.0125        0.8985        0.0206   \n",
       " ..            ...           ...           ...           ...           ...   \n",
       " 143        0.0226        0.0542        0.0134        0.8958        0.0231   \n",
       " 144        0.0316        0.0501        0.0152        0.8942        0.0221   \n",
       " 145        0.0314        0.0479        0.0147        0.8749        0.0267   \n",
       " 146        0.0231        0.0505        0.0128        0.8840        0.0221   \n",
       " 147        0.0313        0.0510        0.0148        0.9008        0.0247   \n",
       " \n",
       "      ...  w1c1_L1_21_drugs_alcohol  w1c1_L1_23_Divorce  w1c1_L1_24_Lost_Job  \\\n",
       " 0    ...                         2                   2                    1   \n",
       " 1    ...                         2                   2                    2   \n",
       " 2    ...                         2                   2                    2   \n",
       " 3    ...                         1                   1                    1   \n",
       " 4    ...                         2                   1                    2   \n",
       " ..   ...                       ...                 ...                  ...   \n",
       " 143  ...                         2                   1                    1   \n",
       " 144  ...                         2                   1                    2   \n",
       " 145  ...                         2                   2                    1   \n",
       " 146  ...                         1                   2                    2   \n",
       " 147  ...                         2                   1                    1   \n",
       " \n",
       "      w1c1_L1_25_Emotionally_mistreated  w1c1_L1_27_Legal_problems  \\\n",
       " 0                                    2                          2   \n",
       " 1                                    2                          2   \n",
       " 2                                    2                          2   \n",
       " 3                                    2                          2   \n",
       " 4                                    2                          1   \n",
       " ..                                 ...                        ...   \n",
       " 143                                  1                          2   \n",
       " 144                                  2                          2   \n",
       " 145                                  2                          1   \n",
       " 146                                  2                          2   \n",
       " 147                                  2                          2   \n",
       " \n",
       "      w1c1_L1_28_Unemployed  w1c1_L1_29_Financial_probs  \\\n",
       " 0                        2                           1   \n",
       " 1                        2                           1   \n",
       " 2                        2                           2   \n",
       " 3                        1                           1   \n",
       " 4                        1                           1   \n",
       " ..                     ...                         ...   \n",
       " 143                      1                           1   \n",
       " 144                      2                           2   \n",
       " 145                      1                           1   \n",
       " 146                      2                           2   \n",
       " 147                      1                           2   \n",
       " \n",
       "      w2c1_L1_21_drugs_alcohol  w2c1_L1_23_Divorce  w2c1_L1_24_Lost_Job  \\\n",
       " 0                           2                   2                    2   \n",
       " 1                           2                   2                    2   \n",
       " 2                           1                   2                    2   \n",
       " 3                           2                   2                    2   \n",
       " 4                           2                   2                    2   \n",
       " ..                        ...                 ...                  ...   \n",
       " 143                         2                   1                    1   \n",
       " 144                         2                   2                    2   \n",
       " 145                         2                   2                    2   \n",
       " 146                         1                   2                    2   \n",
       " 147                         2                   2                    2   \n",
       " \n",
       "      w2c1_L1_25_Emotionally_mistreated  w2c1_L1_27_Legal_problems  \\\n",
       " 0                                    1                          2   \n",
       " 1                                    2                          2   \n",
       " 2                                    2                          2   \n",
       " 3                                    2                          2   \n",
       " 4                                    2                          2   \n",
       " ..                                 ...                        ...   \n",
       " 143                                  1                          1   \n",
       " 144                                  2                          2   \n",
       " 145                                  2                          2   \n",
       " 146                                  2                          2   \n",
       " 147                                  2                          2   \n",
       " \n",
       "      w2c1_L1_28_Unemployed  w2c1_L1_29_Financial_probs  \\\n",
       " 0                        2                           1   \n",
       " 1                        2                           2   \n",
       " 2                        2                           1   \n",
       " 3                        2                           1   \n",
       " 4                        2                           1   \n",
       " ..                     ...                         ...   \n",
       " 143                      1                           1   \n",
       " 144                      2                           2   \n",
       " 145                      2                           2   \n",
       " 146                      2                           2   \n",
       " 147                      2                           2   \n",
       " \n",
       "      w3_L1_21_drugs_alcohol  w3_L1_23_Divorce  w3_L1_24_Lost_Job  \\\n",
       " 0                         2                 2                  2   \n",
       " 1                         2                 2                  2   \n",
       " 2                         2                 2                  2   \n",
       " 3                         2                 2                  2   \n",
       " 4                         2                 2                  2   \n",
       " ..                      ...               ...                ...   \n",
       " 143                       2                 2                  1   \n",
       " 144                       2                 2                  2   \n",
       " 145                       2                 2                  2   \n",
       " 146                       1                 2                  2   \n",
       " 147                       2                 2                  2   \n",
       " \n",
       "      w3_L1_25_Emotionally_mistreated  w3_L1_27_Legal_problems  \\\n",
       " 0                                  2                        2   \n",
       " 1                                  2                        2   \n",
       " 2                                  2                        2   \n",
       " 3                                  2                        2   \n",
       " 4                                  2                        2   \n",
       " ..                               ...                      ...   \n",
       " 143                                1                        1   \n",
       " 144                                2                        2   \n",
       " 145                                2                        2   \n",
       " 146                                2                        2   \n",
       " 147                                2                        2   \n",
       " \n",
       "      w3_L1_28_Unemployed  w3_L1_29_Financial_probs  w3_NN1_Loneliness_Scale1  \\\n",
       " 0                      1                         1                         3   \n",
       " 1                      2                         2                         1   \n",
       " 2                      2                         1                         2   \n",
       " 3                      2                         1                         1   \n",
       " 4                      2                         1                         3   \n",
       " ..                   ...                       ...                       ...   \n",
       " 143                    1                         1                         2   \n",
       " 144                    2                         2                         1   \n",
       " 145                    2                         2                         1   \n",
       " 146                    2                         1                         1   \n",
       " 147                    2                         2                         1   \n",
       " \n",
       "      w3_NN2_Loneliness_Scale2  w3_NN3_Loneliness_Scale3  \\\n",
       " 0                           2                         1   \n",
       " 1                           1                         1   \n",
       " 2                           2                         3   \n",
       " 3                           2                         1   \n",
       " 4                           1                         1   \n",
       " ..                        ...                       ...   \n",
       " 143                         1                         1   \n",
       " 144                         1                         1   \n",
       " 145                         1                         1   \n",
       " 146                         1                         1   \n",
       " 147                         1                         1   \n",
       " \n",
       "      w3_J1_Perceived_discrimination1  w3_J2_Perceived_discrimination2  \\\n",
       " 0                                  4                                4   \n",
       " 1                                  4                                4   \n",
       " 2                                  4                                1   \n",
       " 3                                  4                                4   \n",
       " 4                                  4                                4   \n",
       " ..                               ...                              ...   \n",
       " 143                                2                                2   \n",
       " 144                                4                                4   \n",
       " 145                                2                                4   \n",
       " 146                                4                                4   \n",
       " 147                                4                                4   \n",
       " \n",
       "      w3_J3_Perceived_discrimination3  w3_J4_Perceived_discrimination4  \\\n",
       " 0                                  2                                4   \n",
       " 1                                  4                                2   \n",
       " 2                                  4                                3   \n",
       " 3                                  4                                4   \n",
       " 4                                  4                                4   \n",
       " ..                               ...                              ...   \n",
       " 143                                2                                2   \n",
       " 144                                4                                4   \n",
       " 145                                2                                4   \n",
       " 146                                4                                4   \n",
       " 147                                4                                4   \n",
       " \n",
       "      w3_J5_Perceived_discrimination5  w3_J6_Perceived_discrimination6  \\\n",
       " 0                                  4                                4   \n",
       " 1                                  2                                3   \n",
       " 2                                  4                                2   \n",
       " 3                                  4                                2   \n",
       " 4                                  4                                4   \n",
       " ..                               ...                              ...   \n",
       " 143                                2                                2   \n",
       " 144                                4                                4   \n",
       " 145                                4                                1   \n",
       " 146                                4                                4   \n",
       " 147                                4                                3   \n",
       " \n",
       "      w3_J7_Perceived_discrimination7  w3_J8_Perceived_discrimination8  \\\n",
       " 0                                  4                                4   \n",
       " 1                                  4                                4   \n",
       " 2                                  1                                4   \n",
       " 3                                  4                                4   \n",
       " 4                                  4                                4   \n",
       " ..                               ...                              ...   \n",
       " 143                                2                                2   \n",
       " 144                                4                                4   \n",
       " 145                                4                                4   \n",
       " 146                                2                                4   \n",
       " 147                                4                                4   \n",
       " \n",
       "      w3_J9_Perceived_discrimination9  w1_educ_Participant  \\\n",
       " 0                                  4                    3   \n",
       " 1                                  4                    5   \n",
       " 2                                  4                    6   \n",
       " 3                                  4                    6   \n",
       " 4                                  4                    6   \n",
       " ..                               ...                  ...   \n",
       " 143                                2                    5   \n",
       " 144                                4                    7   \n",
       " 145                                4                    6   \n",
       " 146                                4                    5   \n",
       " 147                                4                    6   \n",
       " \n",
       "      w2_educ_Participant  w3_educ_Participant  w3_U8B_Mothers_edu  \\\n",
       " 0                      3                    3                   1   \n",
       " 1                      5                    5                   2   \n",
       " 2                      6                    6                  98   \n",
       " 3                      6                    6                  98   \n",
       " 4                      6                    6                   7   \n",
       " ..                   ...                  ...                 ...   \n",
       " 143                    6                    6                   4   \n",
       " 144                    7                    8                   2   \n",
       " 145                    6                    6                   2   \n",
       " 146                    5                    5                   2   \n",
       " 147                    6                    6                   2   \n",
       " \n",
       "      w3_U8C_Fathers_edu  w1c1_stress2_drugs_alcohol  w1c1_stress4_Divorce  \\\n",
       " 0                     1                           0                     0   \n",
       " 1                    98                           0                     0   \n",
       " 2                    98                           0                     0   \n",
       " 3                    98                           1                     1   \n",
       " 4                    98                           0                     1   \n",
       " ..                  ...                         ...                   ...   \n",
       " 143                   2                           0                     1   \n",
       " 144                   1                           0                     1   \n",
       " 145                   2                           0                     0   \n",
       " 146                  98                           1                     0   \n",
       " 147                   2                           0                     1   \n",
       " \n",
       "      w1c1_stress5_Lost_Job  w1c1_stress6_Emotionally_mistreated  \\\n",
       " 0                        1                                    0   \n",
       " 1                        0                                    0   \n",
       " 2                        0                                    0   \n",
       " 3                        1                                    0   \n",
       " 4                        0                                    0   \n",
       " ..                     ...                                  ...   \n",
       " 143                      1                                    0   \n",
       " 144                      0                                    0   \n",
       " 145                      1                                    0   \n",
       " 146                      0                                    0   \n",
       " 147                      1                                    0   \n",
       " \n",
       "      w1c1_stress8_Legal_problems  w1c1_stress9_Unemployed  \\\n",
       " 0                              0                        0   \n",
       " 1                              0                        0   \n",
       " 2                              0                        0   \n",
       " 3                              0                        1   \n",
       " 4                              1                        1   \n",
       " ..                           ...                      ...   \n",
       " 143                            0                        1   \n",
       " 144                            0                        0   \n",
       " 145                            1                        1   \n",
       " 146                            0                        0   \n",
       " 147                            0                        1   \n",
       " \n",
       "      w1c1_stress10_Financial_probs  w1c1_traumanum  w1c1_PTSDlife  \\\n",
       " 0                                1               4              0   \n",
       " 1                                1               1              1   \n",
       " 2                                0               5              0   \n",
       " 3                                1               9              1   \n",
       " 4                                1               7              0   \n",
       " ..                             ...             ...            ...   \n",
       " 143                              1               3              0   \n",
       " 144                              0               1              0   \n",
       " 145                              1              10              0   \n",
       " 146                              0               3              0   \n",
       " 147                              0               6              0   \n",
       " \n",
       "      w1c1_PTSDpy  w1c1_PTSDpm  w1c1_phq9cat_Depression_severity  \\\n",
       " 0              0            0                                 3   \n",
       " 1              1            0                                 2   \n",
       " 2              0            0                                 4   \n",
       " 3              1            1                                 3   \n",
       " 4              0            0                                 4   \n",
       " ..           ...          ...                               ...   \n",
       " 143            0            1                                 3   \n",
       " 144            0            0                                 1   \n",
       " 145            0            0                                 2   \n",
       " 146            0            0                                 3   \n",
       " 147            0            0                                 1   \n",
       " \n",
       "      w1c1_gad7cat_generalized_anx_symp_severity  w2c1_stress2_drugs_alcohol  \\\n",
       " 0                                             1                           0   \n",
       " 1                                             1                           0   \n",
       " 2                                             1                           0   \n",
       " 3                                             2                           0   \n",
       " 4                                             2                           0   \n",
       " ..                                          ...                         ...   \n",
       " 143                                           3                           0   \n",
       " 144                                           3                           0   \n",
       " 145                                           2                           0   \n",
       " 146                                           1                           1   \n",
       " 147                                           2                           0   \n",
       " \n",
       "      w2c1_stress4_Divorce  w2c1_stress5_Lost_Job  \\\n",
       " 0                       0                      0   \n",
       " 1                       0                      0   \n",
       " 2                       0                      0   \n",
       " 3                       0                      0   \n",
       " 4                       0                      0   \n",
       " ..                    ...                    ...   \n",
       " 143                     1                      1   \n",
       " 144                     0                      0   \n",
       " 145                     0                      0   \n",
       " 146                     0                      0   \n",
       " 147                     0                      0   \n",
       " \n",
       "      w2c1_stress6_Emotionally_mistreated  w2c1_stress8_Legal_problems  \\\n",
       " 0                                      1                            0   \n",
       " 1                                      0                            0   \n",
       " 2                                      0                            0   \n",
       " 3                                      0                            0   \n",
       " 4                                      0                            0   \n",
       " ..                                   ...                          ...   \n",
       " 143                                    1                            1   \n",
       " 144                                    0                            0   \n",
       " 145                                    0                            0   \n",
       " 146                                    0                            0   \n",
       " 147                                    0                            0   \n",
       " \n",
       "      w2c1_stress9_Unemployed  w2c1_stress10_Financial_probs  w2c1_traumanum  \\\n",
       " 0                          0                              1               3   \n",
       " 1                          0                              0               1   \n",
       " 2                          0                              0               2   \n",
       " 3                          0                              1               2   \n",
       " 4                          0                              1               0   \n",
       " ..                       ...                            ...             ...   \n",
       " 143                        1                              1               6   \n",
       " 144                        0                              0               0   \n",
       " 145                        0                              0               0   \n",
       " 146                        0                              0               0   \n",
       " 147                        0                              0               0   \n",
       " \n",
       "      w2c1_pyphq9cat_Depression_severity  \\\n",
       " 0                                     3   \n",
       " 1                                     1   \n",
       " 2                                     1   \n",
       " 3                                     4   \n",
       " 4                                     2   \n",
       " ..                                  ...   \n",
       " 143                                   3   \n",
       " 144                                   1   \n",
       " 145                                   1   \n",
       " 146                                   3   \n",
       " 147                                   2   \n",
       " \n",
       "      w2c1_gad7cat_py_generalized_anx_symp_severity  w2c1_PTSDlife  \\\n",
       " 0                                                1              0   \n",
       " 1                                                1              1   \n",
       " 2                                                1              0   \n",
       " 3                                                1              1   \n",
       " 4                                                1              0   \n",
       " ..                                             ...            ...   \n",
       " 143                                              1              0   \n",
       " 144                                              1              0   \n",
       " 145                                              1              0   \n",
       " 146                                              1              0   \n",
       " 147                                              1              0   \n",
       " \n",
       "      w2c1_PTSDpy  w2c1_PTSDpm  w3_stress2_drugs_alcohol  w3_stress4_Divorce  \\\n",
       " 0              0            0                         0                   0   \n",
       " 1              0            0                         0                   0   \n",
       " 2              0            0                         0                   0   \n",
       " 3              0            0                         0                   0   \n",
       " 4              0            0                         0                   0   \n",
       " ..           ...          ...                       ...                 ...   \n",
       " 143            0            0                         0                   0   \n",
       " 144            0            0                         0                   0   \n",
       " 145            0            0                         0                   0   \n",
       " 146            0            0                         1                   0   \n",
       " 147            0            0                         0                   0   \n",
       " \n",
       "      w3_stress5_Lost_Job  w3_stress6_Emotionally_mistreated  \\\n",
       " 0                      0                                  0   \n",
       " 1                      0                                  0   \n",
       " 2                      0                                  0   \n",
       " 3                      0                                  0   \n",
       " 4                      0                                  0   \n",
       " ..                   ...                                ...   \n",
       " 143                    1                                  1   \n",
       " 144                    0                                  0   \n",
       " 145                    0                                  0   \n",
       " 146                    0                                  0   \n",
       " 147                    0                                  0   \n",
       " \n",
       "      w3_stress8_Legal_problems  w3_stress9_Unemployed  \\\n",
       " 0                            0                      1   \n",
       " 1                            0                      0   \n",
       " 2                            0                      0   \n",
       " 3                            0                      0   \n",
       " 4                            0                      0   \n",
       " ..                         ...                    ...   \n",
       " 143                          1                      1   \n",
       " 144                          0                      0   \n",
       " 145                          0                      0   \n",
       " 146                          0                      0   \n",
       " 147                          0                      0   \n",
       " \n",
       "      w3_stress10_Financial_probs  w3_traumanum  \\\n",
       " 0                              1             0   \n",
       " 1                              0             1   \n",
       " 2                              1             0   \n",
       " 3                              1             0   \n",
       " 4                              1             0   \n",
       " ..                           ...           ...   \n",
       " 143                            1             1   \n",
       " 144                            0             0   \n",
       " 145                            0             2   \n",
       " 146                            1             1   \n",
       " 147                            0             1   \n",
       " \n",
       "      w3_slphq9cat_Depression_severity  \\\n",
       " 0                                   3   \n",
       " 1                                   1   \n",
       " 2                                   3   \n",
       " 3                                   5   \n",
       " 4                                   2   \n",
       " ..                                ...   \n",
       " 143                                 2   \n",
       " 144                                 1   \n",
       " 145                                 1   \n",
       " 146                                 2   \n",
       " 147                                 1   \n",
       " \n",
       "      w3_gad7cat_sl_generalized_anx_symp_severity  w3_PTSDlife  w3_PTSDsl  \\\n",
       " 0                                              1            0          0   \n",
       " 1                                              2            1          0   \n",
       " 2                                              2            0          0   \n",
       " 3                                              2            1          0   \n",
       " 4                                              2            0          0   \n",
       " ..                                           ...          ...        ...   \n",
       " 143                                            1            0          0   \n",
       " 144                                            2            0          0   \n",
       " 145                                            2            0          0   \n",
       " 146                                            2            0          0   \n",
       " 147                                            2            0          0   \n",
       " \n",
       "      w3_PTSDpm  w1c1_life_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0            0                                           28   \n",
       " 1            0                                           50   \n",
       " 2            0                                           28   \n",
       " 3            0                                           50   \n",
       " 4            0                                           19   \n",
       " ..         ...                                          ...   \n",
       " 143          0                                           34   \n",
       " 144          0                                           17   \n",
       " 145          0                                           32   \n",
       " 146          0                                           50   \n",
       " 147          0                                           26   \n",
       " \n",
       "      w1c1_life_worst_intrusion  w1c1_life_worst_avoidance  \\\n",
       " 0                           10                          9   \n",
       " 1                           18                         17   \n",
       " 2                            6                         10   \n",
       " 3                           20                         22   \n",
       " 4                            6                          8   \n",
       " ..                         ...                        ...   \n",
       " 143                          9                         14   \n",
       " 144                          5                          7   \n",
       " 145                          9                         13   \n",
       " 146                         18                         18   \n",
       " 147                         10                         11   \n",
       " \n",
       "      w1c1_life_worst_hyperarousal  w2c1_inc_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                               8                                          31   \n",
       " 1                              15                                          29   \n",
       " 2                              12                                          44   \n",
       " 3                              18                                          40   \n",
       " 4                               5                                          19   \n",
       " ..                            ...                                         ...   \n",
       " 143                             6                                          26   \n",
       " 144                             5                                          44   \n",
       " 145                            10                                          17   \n",
       " 146                            14                                          20   \n",
       " 147                             5                                          23   \n",
       " \n",
       "      w2c1_inc_worst_intrusion  w2c1_inc_worst_avoidance  \\\n",
       " 0                          14                        10   \n",
       " 1                          11                        11   \n",
       " 2                          10                        14   \n",
       " 3                          16                        10   \n",
       " 4                           5                         7   \n",
       " ..                        ...                       ...   \n",
       " 143                         5                        10   \n",
       " 144                        10                        14   \n",
       " 145                         5                         7   \n",
       " 146                        10                         8   \n",
       " 147                         5                         8   \n",
       " \n",
       "      w2c1_inc_worst_hyperarousal  w2c1_r_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                              7                                        25   \n",
       " 1                              7                                        20   \n",
       " 2                             11                                        17   \n",
       " 3                             14                                        53   \n",
       " 4                              6                                        22   \n",
       " ..                           ...                                       ...   \n",
       " 143                           11                                        19   \n",
       " 144                           11                                        34   \n",
       " 145                            5                                        17   \n",
       " 146                            5                                        30   \n",
       " 147                            7                                        24   \n",
       " \n",
       "      w2c1_r_worst_intrusion  w2c1_r_worst_avoidance  \\\n",
       " 0                         7                       9   \n",
       " 1                         7                       8   \n",
       " 2                        11                       7   \n",
       " 3                        18                      18   \n",
       " 4                         7                       7   \n",
       " ..                      ...                     ...   \n",
       " 143                       7                       7   \n",
       " 144                       9                      18   \n",
       " 145                       5                       7   \n",
       " 146                       9                      11   \n",
       " 147                       9                       9   \n",
       " \n",
       "      w2c1_r_worst_hyperarousal  w3_inc_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                            9                                        35   \n",
       " 1                            5                                        27   \n",
       " 2                           10                                        21   \n",
       " 3                           17                                        35   \n",
       " 4                           22                                        29   \n",
       " ..                         ...                                       ...   \n",
       " 143                         10                                        21   \n",
       " 144                          7                                        28   \n",
       " 145                          5                                        21   \n",
       " 146                         10                                        34   \n",
       " 147                          6                                        17   \n",
       " \n",
       "      w3_inc_worst_intrusion  w3_inc_worst_avoidance  \\\n",
       " 0                        10                      15   \n",
       " 1                        13                       9   \n",
       " 2                         7                       7   \n",
       " 3                        10                      15   \n",
       " 4                         9                      10   \n",
       " ..                      ...                     ...   \n",
       " 143                       7                       7   \n",
       " 144                       8                       7   \n",
       " 145                       7                       9   \n",
       " 146                      12                       9   \n",
       " 147                       5                       7   \n",
       " \n",
       "      w3_inc_worst_hyperarousal  w3_r_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                           10                                      27   \n",
       " 1                            5                                      27   \n",
       " 2                            7                                      30   \n",
       " 3                           10                                      17   \n",
       " 4                           11                                      47   \n",
       " ..                         ...                                     ...   \n",
       " 143                          7                                      32   \n",
       " 144                          7                                      29   \n",
       " 145                          5                                      19   \n",
       " 146                         13                                      41   \n",
       " 147                          5                                      33   \n",
       " \n",
       "      w3_r_worst_intrusion  w3_r_worst_avoidance  w3_r_worst_hyperarousal  \\\n",
       " 0                       9                    11                        7   \n",
       " 1                       9                     8                       10   \n",
       " 2                       5                     9                        6   \n",
       " 3                       5                     7                        5   \n",
       " 4                      16                    19                       10   \n",
       " ..                    ...                   ...                      ...   \n",
       " 143                     9                    14                        9   \n",
       " 144                     5                    12                        6   \n",
       " 145                     5                     7                       10   \n",
       " 146                     5                    13                       10   \n",
       " 147                     5                    14                       10   \n",
       " \n",
       "      w2c1_life_sumptsdworst_PTS_symptom_severity  \\\n",
       " 0                                             31   \n",
       " 1                                             50   \n",
       " 2                                             28   \n",
       " 3                                             53   \n",
       " 4                                             19   \n",
       " ..                                           ...   \n",
       " 143                                           33   \n",
       " 144                                           34   \n",
       " 145                                           32   \n",
       " 146                                           50   \n",
       " 147                                           26   \n",
       " \n",
       "      w3_life_sumptsdworst_PTS_symptom_severity  TraumaNum  \n",
       " 0                                           31          4  \n",
       " 1                                           50          1  \n",
       " 2                                           28          5  \n",
       " 3                                           53          9  \n",
       " 4                                           19          7  \n",
       " ..                                         ...        ...  \n",
       " 143                                         33          6  \n",
       " 144                                         34          1  \n",
       " 145                                         32         10  \n",
       " 146                                         50          3  \n",
       " 147                                         26          6  \n",
       " \n",
       " [148 rows x 5356 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Functions to fit the model and select the top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahwani\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# we will try reducing the features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "class SelectFeatures():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function constructor\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fit_lis = []\n",
    "        self.df_imp_lis = []\n",
    "        \n",
    "        \n",
    "    def CallFit(self, df, labels, top_fea):\n",
    "        \"\"\"\n",
    "        Fit model for feature selection. \n",
    "        The model will fit the data to find the predictive \n",
    "        features for response variable. \n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        df : List of data frames you want to select features from\n",
    "        labels : List of response variable. \n",
    "        top_fea : Number of features you want to select\n",
    "        \n",
    "        \"\"\"\n",
    "        top_selected = SelectKBest(score_func = f_regression, k = top_fea)\n",
    "        fit = top_selected.fit(df, labels)\n",
    "        self.fit_lis.append(fit)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def UnivFeatureSelection(self, df, index):\n",
    "        \"\"\"\n",
    "        This function will call the fitted models to select the features\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        df : List of data frames you want to select features from\n",
    "        index : Index of the model fitted on the data\n",
    "        \n",
    "        \"\"\"\n",
    "        cols = self.fit_lis[index].get_support(indices=True)\n",
    "        df_impt_uvs = df.iloc[:,cols]\n",
    "        self.df_imp_lis.append(df_impt_uvs)\n",
    "        return self.df_imp_lis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Call the functions for cross-sectional and longitudinal data and select the features. We will save it to use for machine learning. We will call some functions which are in other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from Epic_ML_3.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahwani\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# First we will import some functions from other notebook Epic_ML_3.ipynb\n",
    "import nbimporter\n",
    "import Epic_ML_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model. It was in other notebook but \"np\" gives some issue\n",
    "# when calling from other notebook. So I have copied that function \n",
    "# here to make it locally available\n",
    "\n",
    "from sklearn import metrics\n",
    "def evaluate_model(data_scaled, preds, df_indx, df_types, \n",
    "                   model_name, store ):\n",
    "    for i in range(len(data_scaled)):\n",
    "        print(\"\\nModel : ........ \", model_name)\n",
    "        print(\"\\n\", df_types[i], \": \")\n",
    "        abe = metrics.mean_absolute_error(data_scaled[i][df_indx], preds[i])\n",
    "        mse = metrics.mean_squared_error(data_scaled[i][df_indx], preds[i])\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(data_scaled[i][df_indx], preds[i]))\n",
    "        r2 = metrics.r2_score(data_scaled[i][df_indx], preds[i])\n",
    "        print('Mean Absolute Error:', abe)\n",
    "        print('Mean Squared Error:', mse)\n",
    "        print('Root Mean Squared Error:', rmse) \n",
    "        print(\"R2 on data:\", r2)\n",
    "        key = model_name+ '_' +df_types[i] \n",
    "        store[key] = [abe, mse, rmse, r2]\n",
    "\n",
    "    return store\n",
    "\n",
    "\n",
    "# Function to predict and evaluate the model\n",
    "def PredictEvaluate(trained_models_base, df_types, model_names, \n",
    "                   data_scaled):\n",
    "    base_pred = [{},{}]\n",
    "    base_m_score = [{},{}]\n",
    "    for i in range(2): # for train and test data\n",
    "        if i == 0:\n",
    "            print(\"Fitting training data -------\")\n",
    "            indx = 0\n",
    "        else:\n",
    "            print(\"Fitting test data ===========\")\n",
    "            indx = 2\n",
    "        base_pred[i] = Epic_ML_3.make_predictions(data_scaled=data_scaled, \n",
    "                                        model_names=model_names, \n",
    "                                        df_types=df_types, indx=indx,\n",
    "                                        trained_models=trained_models_base)\n",
    "\n",
    "\n",
    "        # Get scores for each model on each data set\n",
    "        for j in range(len(model_names)):\n",
    "            print(\"Model :\",model_names[j])\n",
    "            predictions = [value for key,value in base_pred[i].items() if key.startswith(model_names[j])]\n",
    "            base_m_score[i] = evaluate_model(data_scaled=data_scaled, \n",
    "                                                             preds=predictions, df_indx=indx+1, \n",
    "                                                             df_types=df_types, \n",
    "                                                             model_name = model_names[j],\n",
    "                                                             store=base_m_score[i]\n",
    "                                                            )\n",
    "    return base_m_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  30,  50,  70,  90, 110, 130, 150, 170, 190, 210, 230, 250,\n",
       "       270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510,\n",
       "       530, 550, 570, 590])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = np.arange(10,600, 20)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patience, selecting features : 10\n",
      "Patience, selecting features : 10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.63 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.73 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros10\n",
      "Wall time: 209 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros10\n",
      "Wall time: 91.5 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros10\n",
      "Wall time: 88.7 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long10\n",
      "Wall time: 234 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long10\n",
      "Wall time: 106 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long10\n",
      "Wall time: 64.7 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros10 : \n",
      "Mean Absolute Error: 0.06540061269430522\n",
      "Mean Squared Error: 0.012832430253002304\n",
      "Root Mean Squared Error: 0.11328031714734163\n",
      "R2 on data: 0.9871675697469977\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long10 : \n",
      "Mean Absolute Error: 0.08400389345852476\n",
      "Mean Squared Error: 0.018787582519172702\n",
      "Root Mean Squared Error: 0.1370678026349467\n",
      "R2 on data: 0.9812124174808273\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros10 : \n",
      "Mean Absolute Error: 0.19075108761930737\n",
      "Mean Squared Error: 0.05513924179370579\n",
      "Root Mean Squared Error: 0.23481746483961918\n",
      "R2 on data: 0.9448607582062942\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long10 : \n",
      "Mean Absolute Error: 0.18955505561185043\n",
      "Mean Squared Error: 0.052046277254676254\n",
      "Root Mean Squared Error: 0.22813653204753565\n",
      "R2 on data: 0.9479537227453237\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros10 : \n",
      "Mean Absolute Error: 0.057299884173303145\n",
      "Mean Squared Error: 0.006036283834555768\n",
      "Root Mean Squared Error: 0.07769352504910411\n",
      "R2 on data: 0.9939637161654442\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long10 : \n",
      "Mean Absolute Error: 0.04560016552537259\n",
      "Mean Squared Error: 0.003859111637429218\n",
      "Root Mean Squared Error: 0.06212174850589138\n",
      "R2 on data: 0.9961408883625708\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros10 : \n",
      "Mean Absolute Error: 0.13613600712602383\n",
      "Mean Squared Error: 0.0549395971314988\n",
      "Root Mean Squared Error: 0.23439197326593503\n",
      "R2 on data: 0.9450604028685012\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long10 : \n",
      "Mean Absolute Error: 0.19649672893160727\n",
      "Mean Squared Error: 0.10205497163818979\n",
      "Root Mean Squared Error: 0.31946043829900095\n",
      "R2 on data: 0.8979450283618102\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros10 : \n",
      "Mean Absolute Error: 0.20714673290982413\n",
      "Mean Squared Error: 0.08067972424311715\n",
      "Root Mean Squared Error: 0.2840417649626849\n",
      "R2 on data: 0.9193202757568828\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long10 : \n",
      "Mean Absolute Error: 0.2726999122953657\n",
      "Mean Squared Error: 0.11970033008659793\n",
      "Root Mean Squared Error: 0.34597735487542813\n",
      "R2 on data: 0.880299669913402\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros10 : \n",
      "Mean Absolute Error: 0.18408154419598738\n",
      "Mean Squared Error: 0.07088524457238701\n",
      "Root Mean Squared Error: 0.2662428300863462\n",
      "R2 on data: 0.929114755427613\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long10 : \n",
      "Mean Absolute Error: 0.2515177937006753\n",
      "Mean Squared Error: 0.1363359868117608\n",
      "Root Mean Squared Error: 0.3692370333698406\n",
      "R2 on data: 0.8636640131882392\n",
      "Patience, selecting features : 30\n",
      "Patience, selecting features : 30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.77 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 11.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.93 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.5 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros30\n",
      "Wall time: 236 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros30\n",
      "Wall time: 128 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros30\n",
      "Wall time: 133 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long30\n",
      "Wall time: 206 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long30\n",
      "Wall time: 102 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long30\n",
      "Wall time: 98.6 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros30 : \n",
      "Mean Absolute Error: 0.06721207977240172\n",
      "Mean Squared Error: 0.01283318246957747\n",
      "Root Mean Squared Error: 0.11328363725436022\n",
      "R2 on data: 0.9871668175304226\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long30 : \n",
      "Mean Absolute Error: 0.08187518293515665\n",
      "Mean Squared Error: 0.01737587147644586\n",
      "Root Mean Squared Error: 0.13181756892177104\n",
      "R2 on data: 0.9826241285235542\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros30 : \n",
      "Mean Absolute Error: 0.19844808826879712\n",
      "Mean Squared Error: 0.054308918509227005\n",
      "Root Mean Squared Error: 0.2330427396621208\n",
      "R2 on data: 0.945691081490773\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long30 : \n",
      "Mean Absolute Error: 0.16538508211032818\n",
      "Mean Squared Error: 0.0384347193598853\n",
      "Root Mean Squared Error: 0.19604774765318092\n",
      "R2 on data: 0.9615652806401147\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros30 : \n",
      "Mean Absolute Error: 0.03742574937178282\n",
      "Mean Squared Error: 0.003047555485972602\n",
      "Root Mean Squared Error: 0.055204669059533376\n",
      "R2 on data: 0.9969524445140274\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long30 : \n",
      "Mean Absolute Error: 0.02219961127090268\n",
      "Mean Squared Error: 0.0009250734128479731\n",
      "Root Mean Squared Error: 0.030415019527331773\n",
      "R2 on data: 0.999074926587152\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros30 : \n",
      "Mean Absolute Error: 0.1174926702113014\n",
      "Mean Squared Error: 0.042568319661056626\n",
      "Root Mean Squared Error: 0.20632091425993784\n",
      "R2 on data: 0.9574316803389433\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long30 : \n",
      "Mean Absolute Error: 0.19592089377193309\n",
      "Mean Squared Error: 0.09265401141483787\n",
      "Root Mean Squared Error: 0.3043912144179557\n",
      "R2 on data: 0.9073459885851621\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros30 : \n",
      "Mean Absolute Error: 0.2373832512912458\n",
      "Mean Squared Error: 0.08814995896766367\n",
      "Root Mean Squared Error: 0.29690058768494154\n",
      "R2 on data: 0.9118500410323364\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long30 : \n",
      "Mean Absolute Error: 0.27039061406933196\n",
      "Mean Squared Error: 0.12347876397909338\n",
      "Root Mean Squared Error: 0.35139545241663755\n",
      "R2 on data: 0.8765212360209066\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros30 : \n",
      "Mean Absolute Error: 0.15984113427642804\n",
      "Mean Squared Error: 0.0570590928485351\n",
      "Root Mean Squared Error: 0.23887045202061954\n",
      "R2 on data: 0.942940907151465\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long30 : \n",
      "Mean Absolute Error: 0.23167499091479218\n",
      "Mean Squared Error: 0.11536903723120595\n",
      "Root Mean Squared Error: 0.3396601790484218\n",
      "R2 on data: 0.884630962768794\n",
      "Patience, selecting features : 50\n",
      "Patience, selecting features : 50\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.66 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.7 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.2 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros50\n",
      "Wall time: 381 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros50\n",
      "Wall time: 149 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 149 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long50\n",
      "Wall time: 277 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long50\n",
      "Wall time: 114 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long50\n",
      "Wall time: 134 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros50 : \n",
      "Mean Absolute Error: 0.0723960838295898\n",
      "Mean Squared Error: 0.013575889393043675\n",
      "Root Mean Squared Error: 0.11651561866566934\n",
      "R2 on data: 0.9864241106069563\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long50 : \n",
      "Mean Absolute Error: 0.08849353747144649\n",
      "Mean Squared Error: 0.01745982752369418\n",
      "Root Mean Squared Error: 0.13213564062619207\n",
      "R2 on data: 0.9825401724763059\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros50 : \n",
      "Mean Absolute Error: 0.1818459302968234\n",
      "Mean Squared Error: 0.049059337408388054\n",
      "Root Mean Squared Error: 0.2214934252035217\n",
      "R2 on data: 0.9509406625916119\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long50 : \n",
      "Mean Absolute Error: 0.15102294114964035\n",
      "Mean Squared Error: 0.03429134098050923\n",
      "Root Mean Squared Error: 0.18517921314367128\n",
      "R2 on data: 0.9657086590194908\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros50 : \n",
      "Mean Absolute Error: 0.0383077865192554\n",
      "Mean Squared Error: 0.002969644026370171\n",
      "Root Mean Squared Error: 0.05449444032532283\n",
      "R2 on data: 0.9970303559736299\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long50 : \n",
      "Mean Absolute Error: 0.023682556952823373\n",
      "Mean Squared Error: 0.0008678997201157013\n",
      "Root Mean Squared Error: 0.02946013781562641\n",
      "R2 on data: 0.9991321002798843\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros50 : \n",
      "Mean Absolute Error: 0.12762581445575455\n",
      "Mean Squared Error: 0.04457702385240631\n",
      "Root Mean Squared Error: 0.21113271620572288\n",
      "R2 on data: 0.9554229761475936\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long50 : \n",
      "Mean Absolute Error: 0.19528733174491034\n",
      "Mean Squared Error: 0.08585968372955409\n",
      "Root Mean Squared Error: 0.29301823105321295\n",
      "R2 on data: 0.9141403162704459\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros50 : \n",
      "Mean Absolute Error: 0.22043895929701288\n",
      "Mean Squared Error: 0.08692576470891816\n",
      "Root Mean Squared Error: 0.29483175661539274\n",
      "R2 on data: 0.9130742352910818\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long50 : \n",
      "Mean Absolute Error: 0.25454574571910643\n",
      "Mean Squared Error: 0.10094668572657327\n",
      "Root Mean Squared Error: 0.3177210816527183\n",
      "R2 on data: 0.8990533142734267\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros50 : \n",
      "Mean Absolute Error: 0.15451632342144814\n",
      "Mean Squared Error: 0.0582445991881633\n",
      "Root Mean Squared Error: 0.2413391787260479\n",
      "R2 on data: 0.9417554008118367\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long50 : \n",
      "Mean Absolute Error: 0.21907901461192078\n",
      "Mean Squared Error: 0.08343182458873491\n",
      "Root Mean Squared Error: 0.28884567607761574\n",
      "R2 on data: 0.9165681754112651\n",
      "Patience, selecting features : 70\n",
      "Patience, selecting features : 70\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.84 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.35 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.2 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros70\n",
      "Wall time: 362 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros70\n",
      "Wall time: 146 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros70\n",
      "Wall time: 270 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long70\n",
      "Wall time: 308 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long70\n",
      "Wall time: 134 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long70\n",
      "Wall time: 182 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros70 : \n",
      "Mean Absolute Error: 0.07663718601675332\n",
      "Mean Squared Error: 0.014565551661715751\n",
      "Root Mean Squared Error: 0.12068782731375916\n",
      "R2 on data: 0.9854344483382842\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long70 : \n",
      "Mean Absolute Error: 0.08594461396164735\n",
      "Mean Squared Error: 0.017397433124084025\n",
      "Root Mean Squared Error: 0.13189932950581676\n",
      "R2 on data: 0.982602566875916\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros70 : \n",
      "Mean Absolute Error: 0.18542073986499116\n",
      "Mean Squared Error: 0.04805725320618299\n",
      "Root Mean Squared Error: 0.21921964603151559\n",
      "R2 on data: 0.951942746793817\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long70 : \n",
      "Mean Absolute Error: 0.14341374008245097\n",
      "Mean Squared Error: 0.03128986673267064\n",
      "Root Mean Squared Error: 0.17688941950458947\n",
      "R2 on data: 0.9687101332673294\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros70 : \n",
      "Mean Absolute Error: 0.026830486352031557\n",
      "Mean Squared Error: 0.0012247393176531463\n",
      "Root Mean Squared Error: 0.034996275768332065\n",
      "R2 on data: 0.9987752606823469\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long70 : \n",
      "Mean Absolute Error: 0.01614623320035993\n",
      "Mean Squared Error: 0.0004193383200905679\n",
      "Root Mean Squared Error: 0.02047775183194112\n",
      "R2 on data: 0.9995806616799094\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros70 : \n",
      "Mean Absolute Error: 0.14273328822580583\n",
      "Mean Squared Error: 0.049772086053067946\n",
      "Root Mean Squared Error: 0.2230965845840495\n",
      "R2 on data: 0.9502279139469321\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long70 : \n",
      "Mean Absolute Error: 0.21025898777504237\n",
      "Mean Squared Error: 0.1008112337122904\n",
      "Root Mean Squared Error: 0.3175078482688111\n",
      "R2 on data: 0.8991887662877096\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros70 : \n",
      "Mean Absolute Error: 0.2349272682107416\n",
      "Mean Squared Error: 0.0913795155550943\n",
      "Root Mean Squared Error: 0.30229044899747376\n",
      "R2 on data: 0.9086204844449057\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long70 : \n",
      "Mean Absolute Error: 0.2376707727121383\n",
      "Mean Squared Error: 0.10289945004041118\n",
      "Root Mean Squared Error: 0.3207794414241835\n",
      "R2 on data: 0.8971005499595888\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros70 : \n",
      "Mean Absolute Error: 0.17060010203726955\n",
      "Mean Squared Error: 0.06406203196984249\n",
      "Root Mean Squared Error: 0.25310478456529123\n",
      "R2 on data: 0.9359379680301575\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long70 : \n",
      "Mean Absolute Error: 0.22572124134414304\n",
      "Mean Squared Error: 0.10520301498441913\n",
      "Root Mean Squared Error: 0.3243501425688281\n",
      "R2 on data: 0.8947969850155808\n",
      "Patience, selecting features : 90\n",
      "Patience, selecting features : 90\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.2 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.59 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.8 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.6 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.36 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.2 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros90\n",
      "Wall time: 478 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros90\n",
      "Wall time: 167 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros90\n",
      "Wall time: 265 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long90\n",
      "Wall time: 429 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long90\n",
      "Wall time: 155 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long90\n",
      "Wall time: 251 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros90 : \n",
      "Mean Absolute Error: 0.07872643746319745\n",
      "Mean Squared Error: 0.015340238604242624\n",
      "Root Mean Squared Error: 0.12385571688154981\n",
      "R2 on data: 0.9846597613957574\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long90 : \n",
      "Mean Absolute Error: 0.08460103822871629\n",
      "Mean Squared Error: 0.01698564094552895\n",
      "Root Mean Squared Error: 0.13032897201132582\n",
      "R2 on data: 0.9830143590544711\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros90 : \n",
      "Mean Absolute Error: 0.17758703272939946\n",
      "Mean Squared Error: 0.04590400907819971\n",
      "Root Mean Squared Error: 0.21425220903925288\n",
      "R2 on data: 0.9540959909218003\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long90 : \n",
      "Mean Absolute Error: 0.1363964286826393\n",
      "Mean Squared Error: 0.029600624359650204\n",
      "Root Mean Squared Error: 0.17204831983966076\n",
      "R2 on data: 0.9703993756403498\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros90 : \n",
      "Mean Absolute Error: 0.02690339674753822\n",
      "Mean Squared Error: 0.001173960866466553\n",
      "Root Mean Squared Error: 0.03426311232895449\n",
      "R2 on data: 0.9988260391335334\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long90 : \n",
      "Mean Absolute Error: 0.01861183576586458\n",
      "Mean Squared Error: 0.0005121649476558276\n",
      "Root Mean Squared Error: 0.022631061567143233\n",
      "R2 on data: 0.9994878350523442\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros90 : \n",
      "Mean Absolute Error: 0.1372767710016643\n",
      "Mean Squared Error: 0.048613744593015186\n",
      "Root Mean Squared Error: 0.22048524801676683\n",
      "R2 on data: 0.9513862554069848\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long90 : \n",
      "Mean Absolute Error: 0.21366756788182917\n",
      "Mean Squared Error: 0.10769732978575317\n",
      "Root Mean Squared Error: 0.3281727133473366\n",
      "R2 on data: 0.8923026702142468\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros90 : \n",
      "Mean Absolute Error: 0.23086538680821642\n",
      "Mean Squared Error: 0.09287454878742991\n",
      "Root Mean Squared Error: 0.3047532588626903\n",
      "R2 on data: 0.90712545121257\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long90 : \n",
      "Mean Absolute Error: 0.23692298046334573\n",
      "Mean Squared Error: 0.10811905414842238\n",
      "Root Mean Squared Error: 0.3288146197303617\n",
      "R2 on data: 0.8918809458515776\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros90 : \n",
      "Mean Absolute Error: 0.1615845750280744\n",
      "Mean Squared Error: 0.058966292963781655\n",
      "Root Mean Squared Error: 0.24282976128098807\n",
      "R2 on data: 0.9410337070362184\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long90 : \n",
      "Mean Absolute Error: 0.22201739008182886\n",
      "Mean Squared Error: 0.10306247986410892\n",
      "Root Mean Squared Error: 0.32103345598879396\n",
      "R2 on data: 0.896937520135891\n",
      "Patience, selecting features : 110\n",
      "Patience, selecting features : 110\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.99 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.6 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.9 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros110\n",
      "Wall time: 539 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros110\n",
      "Wall time: 193 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros110\n",
      "Wall time: 318 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long110\n",
      "Wall time: 441 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long110\n",
      "Wall time: 171 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long110\n",
      "Wall time: 274 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros110 : \n",
      "Mean Absolute Error: 0.08249022003151052\n",
      "Mean Squared Error: 0.016621453288362474\n",
      "Root Mean Squared Error: 0.12892421529085402\n",
      "R2 on data: 0.9833785467116375\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long110 : \n",
      "Mean Absolute Error: 0.08919020637000334\n",
      "Mean Squared Error: 0.01777023516550304\n",
      "Root Mean Squared Error: 0.13330504553655514\n",
      "R2 on data: 0.982229764834497\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros110 : \n",
      "Mean Absolute Error: 0.1835630372575742\n",
      "Mean Squared Error: 0.04680796763454338\n",
      "Root Mean Squared Error: 0.21635149094596826\n",
      "R2 on data: 0.9531920323654566\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long110 : \n",
      "Mean Absolute Error: 0.1394239649647221\n",
      "Mean Squared Error: 0.02867914962955689\n",
      "Root Mean Squared Error: 0.16934919435756668\n",
      "R2 on data: 0.9713208503704431\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros110 : \n",
      "Mean Absolute Error: 0.022028535482606353\n",
      "Mean Squared Error: 0.0007262820560376373\n",
      "Root Mean Squared Error: 0.026949620703038423\n",
      "R2 on data: 0.9992737179439624\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long110 : \n",
      "Mean Absolute Error: 0.017668420740494278\n",
      "Mean Squared Error: 0.00045815280199908783\n",
      "Root Mean Squared Error: 0.02140450424558083\n",
      "R2 on data: 0.9995418471980009\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros110 : \n",
      "Mean Absolute Error: 0.1367390512250302\n",
      "Mean Squared Error: 0.04985791581325201\n",
      "Root Mean Squared Error: 0.22328886182085306\n",
      "R2 on data: 0.950142084186748\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long110 : \n",
      "Mean Absolute Error: 0.21667963616848562\n",
      "Mean Squared Error: 0.1074462532316748\n",
      "Root Mean Squared Error: 0.3277899529144766\n",
      "R2 on data: 0.8925537467683251\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros110 : \n",
      "Mean Absolute Error: 0.24298322412095447\n",
      "Mean Squared Error: 0.10752064614235607\n",
      "Root Mean Squared Error: 0.3279034097754338\n",
      "R2 on data: 0.8924793538576439\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long110 : \n",
      "Mean Absolute Error: 0.24357287695761043\n",
      "Mean Squared Error: 0.10651025549968213\n",
      "Root Mean Squared Error: 0.32635908980704387\n",
      "R2 on data: 0.8934897445003178\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros110 : \n",
      "Mean Absolute Error: 0.14679797805500466\n",
      "Mean Squared Error: 0.0552241282024957\n",
      "Root Mean Squared Error: 0.23499814510437247\n",
      "R2 on data: 0.9447758717975043\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long110 : \n",
      "Mean Absolute Error: 0.22200961346721365\n",
      "Mean Squared Error: 0.10764671419546161\n",
      "Root Mean Squared Error: 0.3280955869795594\n",
      "R2 on data: 0.8923532858045383\n",
      "Patience, selecting features : 130\n",
      "Patience, selecting features : 130\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13.2 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.5 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.54 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros130\n",
      "Wall time: 615 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 282 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros130\n",
      "Wall time: 381 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long130\n",
      "Wall time: 551 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long130\n",
      "Wall time: 193 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long130\n",
      "Wall time: 323 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros130 : \n",
      "Mean Absolute Error: 0.08205984988336658\n",
      "Mean Squared Error: 0.0166244669611589\n",
      "Root Mean Squared Error: 0.1289359025297411\n",
      "R2 on data: 0.9833755330388411\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long130 : \n",
      "Mean Absolute Error: 0.09402818483220371\n",
      "Mean Squared Error: 0.018854591939366432\n",
      "Root Mean Squared Error: 0.13731202401598497\n",
      "R2 on data: 0.9811454080606336\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros130 : \n",
      "Mean Absolute Error: 0.1711970480814366\n",
      "Mean Squared Error: 0.041219847031311485\n",
      "Root Mean Squared Error: 0.20302671506802125\n",
      "R2 on data: 0.9587801529686886\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long130 : \n",
      "Mean Absolute Error: 0.13464091746526047\n",
      "Mean Squared Error: 0.026953373223610827\n",
      "Root Mean Squared Error: 0.1641748251822149\n",
      "R2 on data: 0.9730466267763892\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros130 : \n",
      "Mean Absolute Error: 0.021338281545209073\n",
      "Mean Squared Error: 0.0006808866098091458\n",
      "Root Mean Squared Error: 0.02609380405017915\n",
      "R2 on data: 0.9993191133901909\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long130 : \n",
      "Mean Absolute Error: 0.014879696423544357\n",
      "Mean Squared Error: 0.0003147908125425487\n",
      "Root Mean Squared Error: 0.01774234518158602\n",
      "R2 on data: 0.9996852091874574\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros130 : \n",
      "Mean Absolute Error: 0.14213295866437442\n",
      "Mean Squared Error: 0.05282573971569529\n",
      "Root Mean Squared Error: 0.2298385079043442\n",
      "R2 on data: 0.9471742602843047\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long130 : \n",
      "Mean Absolute Error: 0.22604673433878572\n",
      "Mean Squared Error: 0.10975477005062681\n",
      "Root Mean Squared Error: 0.3312925746989009\n",
      "R2 on data: 0.8902452299493732\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros130 : \n",
      "Mean Absolute Error: 0.24020282279885125\n",
      "Mean Squared Error: 0.08964942097007379\n",
      "Root Mean Squared Error: 0.2994151314981823\n",
      "R2 on data: 0.9103505790299262\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long130 : \n",
      "Mean Absolute Error: 0.25562130898761454\n",
      "Mean Squared Error: 0.12336872650152388\n",
      "Root Mean Squared Error: 0.35123884537665234\n",
      "R2 on data: 0.876631273498476\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros130 : \n",
      "Mean Absolute Error: 0.1577037709242061\n",
      "Mean Squared Error: 0.06297235218424245\n",
      "Root Mean Squared Error: 0.2509429261490398\n",
      "R2 on data: 0.9370276478157575\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long130 : \n",
      "Mean Absolute Error: 0.2288911195377928\n",
      "Mean Squared Error: 0.11116810436491141\n",
      "Root Mean Squared Error: 0.33341881225406494\n",
      "R2 on data: 0.8888318956350886\n",
      "Patience, selecting features : 150\n",
      "Patience, selecting features : 150\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.85 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.6 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.92 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.3 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros150\n",
      "Wall time: 725 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros150\n",
      "Wall time: 255 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros150\n",
      "Wall time: 475 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long150\n",
      "Wall time: 526 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long150\n",
      "Wall time: 215 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long150\n",
      "Wall time: 398 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros150 : \n",
      "Mean Absolute Error: 0.08250586985507934\n",
      "Mean Squared Error: 0.016304296670384275\n",
      "Root Mean Squared Error: 0.1276882792991756\n",
      "R2 on data: 0.9836957033296158\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long150 : \n",
      "Mean Absolute Error: 0.09203770226489837\n",
      "Mean Squared Error: 0.0183107524843644\n",
      "Root Mean Squared Error: 0.13531722907436583\n",
      "R2 on data: 0.9816892475156356\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros150 : \n",
      "Mean Absolute Error: 0.16609669048852557\n",
      "Mean Squared Error: 0.03935468895074425\n",
      "Root Mean Squared Error: 0.1983801626946209\n",
      "R2 on data: 0.9606453110492558\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long150 : \n",
      "Mean Absolute Error: 0.13030937942864443\n",
      "Mean Squared Error: 0.025383389395613593\n",
      "Root Mean Squared Error: 0.159321653881742\n",
      "R2 on data: 0.9746166106043864\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros150 : \n",
      "Mean Absolute Error: 0.01862965706529406\n",
      "Mean Squared Error: 0.0005330977421332149\n",
      "Root Mean Squared Error: 0.023088909505067902\n",
      "R2 on data: 0.9994669022578668\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long150 : \n",
      "Mean Absolute Error: 0.014778066414507116\n",
      "Mean Squared Error: 0.000319497757000732\n",
      "Root Mean Squared Error: 0.017874500188836944\n",
      "R2 on data: 0.9996805022429993\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros150 : \n",
      "Mean Absolute Error: 0.14032689632550352\n",
      "Mean Squared Error: 0.049010557418218734\n",
      "Root Mean Squared Error: 0.22138328170442034\n",
      "R2 on data: 0.9509894425817813\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long150 : \n",
      "Mean Absolute Error: 0.2204899705050585\n",
      "Mean Squared Error: 0.10699609882336675\n",
      "Root Mean Squared Error: 0.32710258149908683\n",
      "R2 on data: 0.8930039011766332\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros150 : \n",
      "Mean Absolute Error: 0.216080211060427\n",
      "Mean Squared Error: 0.08341059646559264\n",
      "Root Mean Squared Error: 0.2888089272609014\n",
      "R2 on data: 0.9165894035344073\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long150 : \n",
      "Mean Absolute Error: 0.24524245436996078\n",
      "Mean Squared Error: 0.12042543722639097\n",
      "Root Mean Squared Error: 0.347023683955996\n",
      "R2 on data: 0.879574562773609\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros150 : \n",
      "Mean Absolute Error: 0.13528803844812257\n",
      "Mean Squared Error: 0.04712312585830335\n",
      "Root Mean Squared Error: 0.21707861676891013\n",
      "R2 on data: 0.9528768741416966\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long150 : \n",
      "Mean Absolute Error: 0.20587171142582006\n",
      "Mean Squared Error: 0.09511042519337334\n",
      "Root Mean Squared Error: 0.30839978144183783\n",
      "R2 on data: 0.9048895748066266\n",
      "Patience, selecting features : 170\n",
      "Patience, selecting features : 170\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.74 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.99 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 15 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros170\n",
      "Wall time: 762 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros170\n",
      "Wall time: 281 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros170\n",
      "Wall time: 531 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long170\n",
      "Wall time: 601 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long170\n",
      "Wall time: 240 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long170\n",
      "Wall time: 420 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros170 : \n",
      "Mean Absolute Error: 0.07876556202211957\n",
      "Mean Squared Error: 0.015770251740977008\n",
      "Root Mean Squared Error: 0.1255796629274701\n",
      "R2 on data: 0.984229748259023\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long170 : \n",
      "Mean Absolute Error: 0.09386231128492821\n",
      "Mean Squared Error: 0.017756366349969976\n",
      "Root Mean Squared Error: 0.1332530162884502\n",
      "R2 on data: 0.98224363365003\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros170 : \n",
      "Mean Absolute Error: 0.16448033486114394\n",
      "Mean Squared Error: 0.03762453893591403\n",
      "Root Mean Squared Error: 0.19397045892587364\n",
      "R2 on data: 0.962375461064086\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long170 : \n",
      "Mean Absolute Error: 0.13642881233075696\n",
      "Mean Squared Error: 0.02662609159776993\n",
      "Root Mean Squared Error: 0.163175033622702\n",
      "R2 on data: 0.97337390840223\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros170 : \n",
      "Mean Absolute Error: 0.019125513769754264\n",
      "Mean Squared Error: 0.0005298431220167896\n",
      "Root Mean Squared Error: 0.0230183214422075\n",
      "R2 on data: 0.9994701568779832\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long170 : \n",
      "Mean Absolute Error: 0.008762306972330365\n",
      "Mean Squared Error: 0.0001234480551373337\n",
      "Root Mean Squared Error: 0.011110718029782491\n",
      "R2 on data: 0.9998765519448627\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros170 : \n",
      "Mean Absolute Error: 0.14247687124978958\n",
      "Mean Squared Error: 0.052448679879063875\n",
      "Root Mean Squared Error: 0.22901676768102347\n",
      "R2 on data: 0.9475513201209361\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long170 : \n",
      "Mean Absolute Error: 0.24271840294882333\n",
      "Mean Squared Error: 0.11844695922684711\n",
      "Root Mean Squared Error: 0.34416124015764343\n",
      "R2 on data: 0.8815530407731529\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros170 : \n",
      "Mean Absolute Error: 0.22083217843171452\n",
      "Mean Squared Error: 0.08999268143888771\n",
      "Root Mean Squared Error: 0.29998780215016696\n",
      "R2 on data: 0.9100073185611123\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long170 : \n",
      "Mean Absolute Error: 0.25594296262007243\n",
      "Mean Squared Error: 0.12392299646324596\n",
      "Root Mean Squared Error: 0.3520269825783898\n",
      "R2 on data: 0.876077003536754\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros170 : \n",
      "Mean Absolute Error: 0.14178231019696624\n",
      "Mean Squared Error: 0.05431286094577794\n",
      "Root Mean Squared Error: 0.2330511981213097\n",
      "R2 on data: 0.9456871390542221\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long170 : \n",
      "Mean Absolute Error: 0.2597720853915017\n",
      "Mean Squared Error: 0.13167792349152377\n",
      "Root Mean Squared Error: 0.36287452857912716\n",
      "R2 on data: 0.8683220765084761\n",
      "Patience, selecting features : 190\n",
      "Patience, selecting features : 190\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.65 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.9 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7.09 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 13.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros190\n",
      "Wall time: 895 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros190\n",
      "Wall time: 313 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros190\n",
      "Wall time: 598 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long190\n",
      "Wall time: 663 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long190\n",
      "Wall time: 257 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long190\n",
      "Wall time: 478 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros190 : \n",
      "Mean Absolute Error: 0.08169990394128257\n",
      "Mean Squared Error: 0.016903729167132245\n",
      "Root Mean Squared Error: 0.13001434215936428\n",
      "R2 on data: 0.9830962708328678\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long190 : \n",
      "Mean Absolute Error: 0.09483543609561074\n",
      "Mean Squared Error: 0.01801218779978835\n",
      "Root Mean Squared Error: 0.13420949221194584\n",
      "R2 on data: 0.9819878122002117\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros190 : \n",
      "Mean Absolute Error: 0.16843540324245437\n",
      "Mean Squared Error: 0.037886727985952016\n",
      "Root Mean Squared Error: 0.19464513347615967\n",
      "R2 on data: 0.962113272014048\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long190 : \n",
      "Mean Absolute Error: 0.12657524141896714\n",
      "Mean Squared Error: 0.023385729388358343\n",
      "Root Mean Squared Error: 0.1529239333405937\n",
      "R2 on data: 0.9766142706116416\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros190 : \n",
      "Mean Absolute Error: 0.016965487644300486\n",
      "Mean Squared Error: 0.0004251539409577745\n",
      "Root Mean Squared Error: 0.020619261406698702\n",
      "R2 on data: 0.9995748460590422\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long190 : \n",
      "Mean Absolute Error: 0.008910396121307333\n",
      "Mean Squared Error: 0.00011900294676764089\n",
      "Root Mean Squared Error: 0.010908847178672954\n",
      "R2 on data: 0.9998809970532324\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros190 : \n",
      "Mean Absolute Error: 0.14255081851067034\n",
      "Mean Squared Error: 0.05434014450231266\n",
      "Root Mean Squared Error: 0.2331097263142674\n",
      "R2 on data: 0.9456598554976874\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long190 : \n",
      "Mean Absolute Error: 0.23767443500782173\n",
      "Mean Squared Error: 0.11376556584982642\n",
      "Root Mean Squared Error: 0.337291514642492\n",
      "R2 on data: 0.8862344341501736\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros190 : \n",
      "Mean Absolute Error: 0.2209235492979867\n",
      "Mean Squared Error: 0.0866965989582871\n",
      "Root Mean Squared Error: 0.29444286195845726\n",
      "R2 on data: 0.9133034010417129\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long190 : \n",
      "Mean Absolute Error: 0.24776870613213806\n",
      "Mean Squared Error: 0.12024400880324775\n",
      "Root Mean Squared Error: 0.3467621790265596\n",
      "R2 on data: 0.8797559911967522\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros190 : \n",
      "Mean Absolute Error: 0.1522474312438008\n",
      "Mean Squared Error: 0.05928615567808877\n",
      "Root Mean Squared Error: 0.2434874856703908\n",
      "R2 on data: 0.9407138443219112\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long190 : \n",
      "Mean Absolute Error: 0.2578710595064868\n",
      "Mean Squared Error: 0.1330951379140037\n",
      "Root Mean Squared Error: 0.3648220633596654\n",
      "R2 on data: 0.8669048620859963\n",
      "Patience, selecting features : 210\n",
      "Patience, selecting features : 210\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.97 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.5 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.9 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros210\n",
      "Wall time: 1.07 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 400 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros210\n",
      "Wall time: 702 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long210\n",
      "Wall time: 707 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long210\n",
      "Wall time: 277 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long210\n",
      "Wall time: 571 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros210 : \n",
      "Mean Absolute Error: 0.08128518361670753\n",
      "Mean Squared Error: 0.017104232134760637\n",
      "Root Mean Squared Error: 0.13078314927681103\n",
      "R2 on data: 0.9828957678652394\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long210 : \n",
      "Mean Absolute Error: 0.0946142713659102\n",
      "Mean Squared Error: 0.0183791430173357\n",
      "Root Mean Squared Error: 0.13556969800562255\n",
      "R2 on data: 0.9816208569826643\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros210 : \n",
      "Mean Absolute Error: 0.1628916265345431\n",
      "Mean Squared Error: 0.037017234134881824\n",
      "Root Mean Squared Error: 0.19239863340180413\n",
      "R2 on data: 0.9629827658651182\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long210 : \n",
      "Mean Absolute Error: 0.12167976984910821\n",
      "Mean Squared Error: 0.022605399454636788\n",
      "Root Mean Squared Error: 0.15035092103022446\n",
      "R2 on data: 0.9773946005453632\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros210 : \n",
      "Mean Absolute Error: 0.013617611003003854\n",
      "Mean Squared Error: 0.00028643382127347295\n",
      "Root Mean Squared Error: 0.016924355859927815\n",
      "R2 on data: 0.9997135661787265\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long210 : \n",
      "Mean Absolute Error: 0.009012853007479638\n",
      "Mean Squared Error: 0.00012146523409187706\n",
      "Root Mean Squared Error: 0.011021126716079308\n",
      "R2 on data: 0.9998785347659082\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros210 : \n",
      "Mean Absolute Error: 0.145790033022655\n",
      "Mean Squared Error: 0.05319684582130514\n",
      "Root Mean Squared Error: 0.230644414242585\n",
      "R2 on data: 0.9468031541786949\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long210 : \n",
      "Mean Absolute Error: 0.2409421788841202\n",
      "Mean Squared Error: 0.11622622450059077\n",
      "Root Mean Squared Error: 0.34091967455779193\n",
      "R2 on data: 0.8837737754994092\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros210 : \n",
      "Mean Absolute Error: 0.213256591419305\n",
      "Mean Squared Error: 0.08442991103321301\n",
      "Root Mean Squared Error: 0.2905682553776531\n",
      "R2 on data: 0.9155700889667869\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long210 : \n",
      "Mean Absolute Error: 0.2711419818367856\n",
      "Mean Squared Error: 0.12896691634842888\n",
      "Root Mean Squared Error: 0.35911964071661256\n",
      "R2 on data: 0.8710330836515711\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros210 : \n",
      "Mean Absolute Error: 0.15711237550249915\n",
      "Mean Squared Error: 0.05852532852992136\n",
      "Root Mean Squared Error: 0.2419200870740612\n",
      "R2 on data: 0.9414746714700787\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long210 : \n",
      "Mean Absolute Error: 0.2586760459026836\n",
      "Mean Squared Error: 0.14352216227616085\n",
      "Root Mean Squared Error: 0.3788431895602201\n",
      "R2 on data: 0.8564778377238391\n",
      "Patience, selecting features : 230\n",
      "Patience, selecting features : 230\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.92 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.4 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.5 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros230\n",
      "Wall time: 1.17 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros230\n",
      "Wall time: 400 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros230\n",
      "Wall time: 743 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long230\n",
      "Wall time: 759 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long230\n",
      "Wall time: 317 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long230\n",
      "Wall time: 612 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros230 : \n",
      "Mean Absolute Error: 0.08004102264298235\n",
      "Mean Squared Error: 0.01631313100945897\n",
      "Root Mean Squared Error: 0.12772286799731272\n",
      "R2 on data: 0.983686868990541\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long230 : \n",
      "Mean Absolute Error: 0.0943820483997246\n",
      "Mean Squared Error: 0.018463672548759472\n",
      "Root Mean Squared Error: 0.13588109709874832\n",
      "R2 on data: 0.9815363274512405\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros230 : \n",
      "Mean Absolute Error: 0.1585210779335757\n",
      "Mean Squared Error: 0.03348263989456355\n",
      "Root Mean Squared Error: 0.1829826218376039\n",
      "R2 on data: 0.9665173601054364\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long230 : \n",
      "Mean Absolute Error: 0.12279549099222048\n",
      "Mean Squared Error: 0.023919729560606943\n",
      "Root Mean Squared Error: 0.15466004513321127\n",
      "R2 on data: 0.976080270439393\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros230 : \n",
      "Mean Absolute Error: 0.014834039919362805\n",
      "Mean Squared Error: 0.0003313852842653481\n",
      "Root Mean Squared Error: 0.018203990888410928\n",
      "R2 on data: 0.9996686147157346\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long230 : \n",
      "Mean Absolute Error: 0.009592402809371016\n",
      "Mean Squared Error: 0.00013727185210862388\n",
      "Root Mean Squared Error: 0.011716307102010593\n",
      "R2 on data: 0.9998627281478913\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros230 : \n",
      "Mean Absolute Error: 0.14375561198952994\n",
      "Mean Squared Error: 0.05149715978689343\n",
      "Root Mean Squared Error: 0.2269298565347747\n",
      "R2 on data: 0.9485028402131066\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long230 : \n",
      "Mean Absolute Error: 0.24175492427079742\n",
      "Mean Squared Error: 0.11747169449676043\n",
      "Root Mean Squared Error: 0.34274143971332155\n",
      "R2 on data: 0.8825283055032396\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros230 : \n",
      "Mean Absolute Error: 0.20743691183387597\n",
      "Mean Squared Error: 0.0806059935421863\n",
      "Root Mean Squared Error: 0.28391194681130677\n",
      "R2 on data: 0.9193940064578137\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long230 : \n",
      "Mean Absolute Error: 0.24967532463413042\n",
      "Mean Squared Error: 0.1321697551809546\n",
      "Root Mean Squared Error: 0.36355158530936793\n",
      "R2 on data: 0.8678302448190454\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros230 : \n",
      "Mean Absolute Error: 0.16073191486963256\n",
      "Mean Squared Error: 0.07031716878253239\n",
      "Root Mean Squared Error: 0.2651738463395898\n",
      "R2 on data: 0.9296828312174676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long230 : \n",
      "Mean Absolute Error: 0.23247688252983542\n",
      "Mean Squared Error: 0.1133335298818674\n",
      "Root Mean Squared Error: 0.3366504565300148\n",
      "R2 on data: 0.8866664701181326\n",
      "Patience, selecting features : 250\n",
      "Patience, selecting features : 250\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.51 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.3 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.94 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.8 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros250\n",
      "Wall time: 1.13 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros250\n",
      "Wall time: 423 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros250\n",
      "Wall time: 910 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long250\n",
      "Wall time: 827 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long250\n",
      "Wall time: 317 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long250\n",
      "Wall time: 675 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros250 : \n",
      "Mean Absolute Error: 0.07948936636217974\n",
      "Mean Squared Error: 0.01624758723100842\n",
      "Root Mean Squared Error: 0.12746602382991484\n",
      "R2 on data: 0.9837524127689916\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long250 : \n",
      "Mean Absolute Error: 0.09541599351107484\n",
      "Mean Squared Error: 0.01857222394100016\n",
      "Root Mean Squared Error: 0.13627994695112028\n",
      "R2 on data: 0.9814277760589999\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros250 : \n",
      "Mean Absolute Error: 0.1615609066571586\n",
      "Mean Squared Error: 0.03506266727548045\n",
      "Root Mean Squared Error: 0.1872502797741046\n",
      "R2 on data: 0.9649373327245195\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long250 : \n",
      "Mean Absolute Error: 0.12202868214644323\n",
      "Mean Squared Error: 0.022749623864717752\n",
      "Root Mean Squared Error: 0.1508297844085105\n",
      "R2 on data: 0.9772503761352822\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros250 : \n",
      "Mean Absolute Error: 0.01600286339023291\n",
      "Mean Squared Error: 0.0003838332523327398\n",
      "Root Mean Squared Error: 0.019591662827150223\n",
      "R2 on data: 0.9996161667476673\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long250 : \n",
      "Mean Absolute Error: 0.007349673400377866\n",
      "Mean Squared Error: 8.02375060257667e-05\n",
      "Root Mean Squared Error: 0.008957539060800499\n",
      "R2 on data: 0.9999197624939742\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros250 : \n",
      "Mean Absolute Error: 0.1538006764116712\n",
      "Mean Squared Error: 0.056332989408402215\n",
      "Root Mean Squared Error: 0.23734571706353205\n",
      "R2 on data: 0.9436670105915977\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long250 : \n",
      "Mean Absolute Error: 0.24787276635301922\n",
      "Mean Squared Error: 0.12029734690782162\n",
      "Root Mean Squared Error: 0.34683907926850116\n",
      "R2 on data: 0.8797026530921783\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros250 : \n",
      "Mean Absolute Error: 0.2338489606672296\n",
      "Mean Squared Error: 0.0976063239000613\n",
      "Root Mean Squared Error: 0.3124201080277345\n",
      "R2 on data: 0.9023936760999387\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long250 : \n",
      "Mean Absolute Error: 0.264302375528793\n",
      "Mean Squared Error: 0.13839781761819456\n",
      "Root Mean Squared Error: 0.3720185716038845\n",
      "R2 on data: 0.8616021823818054\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros250 : \n",
      "Mean Absolute Error: 0.16131035554505604\n",
      "Mean Squared Error: 0.06978752128920046\n",
      "Root Mean Squared Error: 0.26417327890837194\n",
      "R2 on data: 0.9302124787107995\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long250 : \n",
      "Mean Absolute Error: 0.2515187308242923\n",
      "Mean Squared Error: 0.1266689838365707\n",
      "Root Mean Squared Error: 0.3559058637288387\n",
      "R2 on data: 0.8733310161634292\n",
      "Patience, selecting features : 270\n",
      "Patience, selecting features : 270\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.2 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.97 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.6 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.3 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.61 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros270\n",
      "Wall time: 1.18 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros270\n",
      "Wall time: 494 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros270\n",
      "Wall time: 919 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long270\n",
      "Wall time: 933 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long270\n",
      "Wall time: 339 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long270\n",
      "Wall time: 688 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros270 : \n",
      "Mean Absolute Error: 0.07952849092110194\n",
      "Mean Squared Error: 0.01655571725008439\n",
      "Root Mean Squared Error: 0.12866902210743808\n",
      "R2 on data: 0.9834442827499156\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long270 : \n",
      "Mean Absolute Error: 0.0961734827102994\n",
      "Mean Squared Error: 0.018653994640266264\n",
      "Root Mean Squared Error: 0.13657962747154592\n",
      "R2 on data: 0.9813460053597337\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros270 : \n",
      "Mean Absolute Error: 0.16264381090519617\n",
      "Mean Squared Error: 0.036065716332185624\n",
      "Root Mean Squared Error: 0.18990975839115173\n",
      "R2 on data: 0.9639342836678144\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long270 : \n",
      "Mean Absolute Error: 0.13358615809587918\n",
      "Mean Squared Error: 0.025757079837910184\n",
      "Root Mean Squared Error: 0.1604901238017785\n",
      "R2 on data: 0.9742429201620898\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros270 : \n",
      "Mean Absolute Error: 0.016511184625977705\n",
      "Mean Squared Error: 0.000419961909655869\n",
      "Root Mean Squared Error: 0.020492972201607774\n",
      "R2 on data: 0.9995800380903441\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long270 : \n",
      "Mean Absolute Error: 0.007220612271909363\n",
      "Mean Squared Error: 7.431504643285667e-05\n",
      "Root Mean Squared Error: 0.008620617520390094\n",
      "R2 on data: 0.9999256849535672\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros270 : \n",
      "Mean Absolute Error: 0.14779392208299555\n",
      "Mean Squared Error: 0.05433116099255006\n",
      "Root Mean Squared Error: 0.23309045667412054\n",
      "R2 on data: 0.9456688390074499\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long270 : \n",
      "Mean Absolute Error: 0.24621829980136284\n",
      "Mean Squared Error: 0.11956916399005182\n",
      "Root Mean Squared Error: 0.3457877441293312\n",
      "R2 on data: 0.8804308360099481\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros270 : \n",
      "Mean Absolute Error: 0.23980805903929397\n",
      "Mean Squared Error: 0.096238785917835\n",
      "Root Mean Squared Error: 0.31022376749345787\n",
      "R2 on data: 0.903761214082165\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long270 : \n",
      "Mean Absolute Error: 0.2543830503063333\n",
      "Mean Squared Error: 0.12200545485447961\n",
      "Root Mean Squared Error: 0.34929279244564954\n",
      "R2 on data: 0.8779945451455203\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros270 : \n",
      "Mean Absolute Error: 0.17307435790594322\n",
      "Mean Squared Error: 0.06776418830071508\n",
      "Root Mean Squared Error: 0.2603155552415473\n",
      "R2 on data: 0.9322358116992849\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long270 : \n",
      "Mean Absolute Error: 0.24773985421435626\n",
      "Mean Squared Error: 0.12537432292206177\n",
      "Root Mean Squared Error: 0.354082367426086\n",
      "R2 on data: 0.8746256770779381\n",
      "Patience, selecting features : 290\n",
      "Patience, selecting features : 290\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.6 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.3 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros290\n",
      "Wall time: 1.43 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 484 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros290\n",
      "Wall time: 960 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long290\n",
      "Wall time: 924 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long290\n",
      "Wall time: 359 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long290\n",
      "Wall time: 795 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros290 : \n",
      "Mean Absolute Error: 0.08070222768876716\n",
      "Mean Squared Error: 0.016823169896152113\n",
      "Root Mean Squared Error: 0.1297041629869763\n",
      "R2 on data: 0.9831768301038479\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long290 : \n",
      "Mean Absolute Error: 0.09843489207148776\n",
      "Mean Squared Error: 0.019631289723386156\n",
      "Root Mean Squared Error: 0.14011170444822288\n",
      "R2 on data: 0.9803687102766139\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros290 : \n",
      "Mean Absolute Error: 0.16028904396074223\n",
      "Mean Squared Error: 0.0348677470160098\n",
      "Root Mean Squared Error: 0.18672907383696252\n",
      "R2 on data: 0.9651322529839902\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long290 : \n",
      "Mean Absolute Error: 0.1354508088056959\n",
      "Mean Squared Error: 0.026545491750415644\n",
      "Root Mean Squared Error: 0.16292787284690008\n",
      "R2 on data: 0.9734545082495843\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros290 : \n",
      "Mean Absolute Error: 0.013927063649815347\n",
      "Mean Squared Error: 0.00029371324751324116\n",
      "Root Mean Squared Error: 0.017138064287230373\n",
      "R2 on data: 0.9997062867524867\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long290 : \n",
      "Mean Absolute Error: 0.006786217909722941\n",
      "Mean Squared Error: 6.620912460316026e-05\n",
      "Root Mean Squared Error: 0.008136898954955767\n",
      "R2 on data: 0.9999337908753968\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros290 : \n",
      "Mean Absolute Error: 0.1498812069472319\n",
      "Mean Squared Error: 0.05453101209571745\n",
      "Root Mean Squared Error: 0.23351876176384084\n",
      "R2 on data: 0.9454689879042826\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long290 : \n",
      "Mean Absolute Error: 0.24153928865933944\n",
      "Mean Squared Error: 0.11849984557144767\n",
      "Root Mean Squared Error: 0.3442380652563683\n",
      "R2 on data: 0.8815001544285522\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros290 : \n",
      "Mean Absolute Error: 0.2265578544692343\n",
      "Mean Squared Error: 0.08591593404702988\n",
      "Root Mean Squared Error: 0.2931141996680302\n",
      "R2 on data: 0.9140840659529701\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long290 : \n",
      "Mean Absolute Error: 0.26100028834058464\n",
      "Mean Squared Error: 0.12182434456720985\n",
      "Root Mean Squared Error: 0.3490334433363225\n",
      "R2 on data: 0.8781756554327901\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros290 : \n",
      "Mean Absolute Error: 0.16113971147854034\n",
      "Mean Squared Error: 0.06069424710408363\n",
      "Root Mean Squared Error: 0.24636202447634584\n",
      "R2 on data: 0.9393057528959163\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long290 : \n",
      "Mean Absolute Error: 0.2474765669752696\n",
      "Mean Squared Error: 0.1269648514527756\n",
      "Root Mean Squared Error: 0.35632127561061466\n",
      "R2 on data: 0.8730351485472243\n",
      "Patience, selecting features : 310\n",
      "Patience, selecting features : 310\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.6 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.99 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.1 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7.17 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros310\n",
      "Wall time: 1.35 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros310\n",
      "Wall time: 485 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros310\n",
      "Wall time: 1.17 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long310\n",
      "Wall time: 1 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long310\n",
      "Wall time: 380 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long310\n",
      "Wall time: 825 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros310 : \n",
      "Mean Absolute Error: 0.08299883929749878\n",
      "Mean Squared Error: 0.0171143738406625\n",
      "Root Mean Squared Error: 0.13082191651501862\n",
      "R2 on data: 0.9828856261593375\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long310 : \n",
      "Mean Absolute Error: 0.0924136823053894\n",
      "Mean Squared Error: 0.018089231496353803\n",
      "Root Mean Squared Error: 0.13449621368779793\n",
      "R2 on data: 0.9819107685036462\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros310 : \n",
      "Mean Absolute Error: 0.16517176314788568\n",
      "Mean Squared Error: 0.036586734568984196\n",
      "Root Mean Squared Error: 0.191276591795714\n",
      "R2 on data: 0.9634132654310158\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long310 : \n",
      "Mean Absolute Error: 0.13142173664381762\n",
      "Mean Squared Error: 0.024193879443244384\n",
      "Root Mean Squared Error: 0.15554381840254655\n",
      "R2 on data: 0.9758061205567556\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros310 : \n",
      "Mean Absolute Error: 0.012939293650757792\n",
      "Mean Squared Error: 0.00025762421164789894\n",
      "Root Mean Squared Error: 0.01605067636107273\n",
      "R2 on data: 0.9997423757883521\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long310 : \n",
      "Mean Absolute Error: 0.006110851911434445\n",
      "Mean Squared Error: 5.54189626375828e-05\n",
      "Root Mean Squared Error: 0.0074443913544078805\n",
      "R2 on data: 0.9999445810373624\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros310 : \n",
      "Mean Absolute Error: 0.14616139682493753\n",
      "Mean Squared Error: 0.055078152459881825\n",
      "Root Mean Squared Error: 0.23468735044710404\n",
      "R2 on data: 0.9449218475401182\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long310 : \n",
      "Mean Absolute Error: 0.2397824061670758\n",
      "Mean Squared Error: 0.11716956037956149\n",
      "Root Mean Squared Error: 0.34230039494508546\n",
      "R2 on data: 0.8828304396204385\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros310 : \n",
      "Mean Absolute Error: 0.21295687437478766\n",
      "Mean Squared Error: 0.08842432231361792\n",
      "Root Mean Squared Error: 0.2973622745299375\n",
      "R2 on data: 0.911575677686382\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long310 : \n",
      "Mean Absolute Error: 0.27907002242784973\n",
      "Mean Squared Error: 0.140318464295131\n",
      "Root Mean Squared Error: 0.3745910627539464\n",
      "R2 on data: 0.8596815357048689\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros310 : \n",
      "Mean Absolute Error: 0.16669676371544376\n",
      "Mean Squared Error: 0.059525360122332865\n",
      "Root Mean Squared Error: 0.2439781959977835\n",
      "R2 on data: 0.9404746398776671\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long310 : \n",
      "Mean Absolute Error: 0.2744343316562011\n",
      "Mean Squared Error: 0.13674781125492716\n",
      "Root Mean Squared Error: 0.3697942823448291\n",
      "R2 on data: 0.8632521887450728\n",
      "Patience, selecting features : 330\n",
      "Patience, selecting features : 330\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.6 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 5.03 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.67 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros330\n",
      "Wall time: 1.57 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros330\n",
      "Wall time: 579 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros330\n",
      "Wall time: 1.22 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long330\n",
      "Wall time: 1.12 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long330\n",
      "Wall time: 426 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long330\n",
      "Wall time: 862 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros330 : \n",
      "Mean Absolute Error: 0.08138690746990518\n",
      "Mean Squared Error: 0.01669244042317977\n",
      "Root Mean Squared Error: 0.12919922764157596\n",
      "R2 on data: 0.9833075595768203\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long330 : \n",
      "Mean Absolute Error: 0.09597443445356876\n",
      "Mean Squared Error: 0.01903955246284232\n",
      "Root Mean Squared Error: 0.1379838847939944\n",
      "R2 on data: 0.9809604475371577\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros330 : \n",
      "Mean Absolute Error: 0.1559571471218454\n",
      "Mean Squared Error: 0.03478354980868941\n",
      "Root Mean Squared Error: 0.18650348470923916\n",
      "R2 on data: 0.9652164501913106\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long330 : \n",
      "Mean Absolute Error: 0.13836984582620665\n",
      "Mean Squared Error: 0.02579185725080197\n",
      "Root Mean Squared Error: 0.16059843477070992\n",
      "R2 on data: 0.974208142749198\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros330 : \n",
      "Mean Absolute Error: 0.0128063725767857\n",
      "Mean Squared Error: 0.00024532199555664494\n",
      "Root Mean Squared Error: 0.015662758235912504\n",
      "R2 on data: 0.9997546780044434\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long330 : \n",
      "Mean Absolute Error: 0.00514345611786619\n",
      "Mean Squared Error: 4.0701847667379156e-05\n",
      "Root Mean Squared Error: 0.006379799970796824\n",
      "R2 on data: 0.9999592981523326\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros330 : \n",
      "Mean Absolute Error: 0.15130113187283717\n",
      "Mean Squared Error: 0.05503045785650789\n",
      "Root Mean Squared Error: 0.2345857153718186\n",
      "R2 on data: 0.944969542143492\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long330 : \n",
      "Mean Absolute Error: 0.24917084894286562\n",
      "Mean Squared Error: 0.12034486166196824\n",
      "Root Mean Squared Error: 0.34690756933507266\n",
      "R2 on data: 0.8796551383380318\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros330 : \n",
      "Mean Absolute Error: 0.18634523122048663\n",
      "Mean Squared Error: 0.0804644308526481\n",
      "Root Mean Squared Error: 0.2836625298707041\n",
      "R2 on data: 0.9195355691473519\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long330 : \n",
      "Mean Absolute Error: 0.2808167142384326\n",
      "Mean Squared Error: 0.13461538947019644\n",
      "Root Mean Squared Error: 0.36689969946866463\n",
      "R2 on data: 0.8653846105298035\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros330 : \n",
      "Mean Absolute Error: 0.1741531007825599\n",
      "Mean Squared Error: 0.07070289909467624\n",
      "Root Mean Squared Error: 0.26590016753412593\n",
      "R2 on data: 0.9292971009053237\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long330 : \n",
      "Mean Absolute Error: 0.2715072741294647\n",
      "Mean Squared Error: 0.13422165314755732\n",
      "Root Mean Squared Error: 0.3663627343870516\n",
      "R2 on data: 0.8657783468524426\n",
      "Patience, selecting features : 350\n",
      "Patience, selecting features : 350\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13.1 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.53 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7.08 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros350\n",
      "Wall time: 1.54 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros350\n",
      "Wall time: 559 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros350\n",
      "Wall time: 1.32 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long350\n",
      "Wall time: 1.19 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long350\n",
      "Wall time: 435 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long350\n",
      "Wall time: 865 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros350 : \n",
      "Mean Absolute Error: 0.08420778816819396\n",
      "Mean Squared Error: 0.01748824470451223\n",
      "Root Mean Squared Error: 0.13224312724868628\n",
      "R2 on data: 0.9825117552954877\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long350 : \n",
      "Mean Absolute Error: 0.09390654423086843\n",
      "Mean Squared Error: 0.01868991035927828\n",
      "Root Mean Squared Error: 0.13671104695407127\n",
      "R2 on data: 0.9813100896407217\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros350 : \n",
      "Mean Absolute Error: 0.15833548296443348\n",
      "Mean Squared Error: 0.03543847949027974\n",
      "Root Mean Squared Error: 0.18825110754064567\n",
      "R2 on data: 0.9645615205097202\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long350 : \n",
      "Mean Absolute Error: 0.1228285125761068\n",
      "Mean Squared Error: 0.021951760578036248\n",
      "Root Mean Squared Error: 0.14816126544423225\n",
      "R2 on data: 0.9780482394219637\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros350 : \n",
      "Mean Absolute Error: 0.013086688611099831\n",
      "Mean Squared Error: 0.0002611124669787745\n",
      "Root Mean Squared Error: 0.01615897481212142\n",
      "R2 on data: 0.9997388875330212\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long350 : \n",
      "Mean Absolute Error: 0.0052480212203549585\n",
      "Mean Squared Error: 4.1787416963368656e-05\n",
      "Root Mean Squared Error: 0.006464318754777541\n",
      "R2 on data: 0.9999582125830366\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros350 : \n",
      "Mean Absolute Error: 0.15378915553310107\n",
      "Mean Squared Error: 0.058433486737273305\n",
      "Root Mean Squared Error: 0.24173019409513843\n",
      "R2 on data: 0.9415665132627267\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long350 : \n",
      "Mean Absolute Error: 0.2501978878271173\n",
      "Mean Squared Error: 0.12225798107671344\n",
      "Root Mean Squared Error: 0.34965408774489315\n",
      "R2 on data: 0.8777420189232865\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros350 : \n",
      "Mean Absolute Error: 0.20780929385740163\n",
      "Mean Squared Error: 0.08112853866537748\n",
      "Root Mean Squared Error: 0.2848307193147844\n",
      "R2 on data: 0.9188714613346225\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long350 : \n",
      "Mean Absolute Error: 0.28616269375466363\n",
      "Mean Squared Error: 0.14201107289809264\n",
      "Root Mean Squared Error: 0.37684356555219656\n",
      "R2 on data: 0.8579889271019073\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros350 : \n",
      "Mean Absolute Error: 0.175196562554861\n",
      "Mean Squared Error: 0.06597536547626615\n",
      "Root Mean Squared Error: 0.256856702221815\n",
      "R2 on data: 0.9340246345237339\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long350 : \n",
      "Mean Absolute Error: 0.27165314548469216\n",
      "Mean Squared Error: 0.13777190979369527\n",
      "Root Mean Squared Error: 0.3711763863632697\n",
      "R2 on data: 0.8622280902063046\n",
      "Patience, selecting features : 370\n",
      "Patience, selecting features : 370\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.51 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.6 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.1 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.55 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.9 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros370\n",
      "Wall time: 1.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 586 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros370\n",
      "Wall time: 1.29 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long370\n",
      "Wall time: 1.15 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long370\n",
      "Wall time: 468 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long370\n",
      "Wall time: 930 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros370 : \n",
      "Mean Absolute Error: 0.08197377585373787\n",
      "Mean Squared Error: 0.0171181661657604\n",
      "Root Mean Squared Error: 0.13083640993913123\n",
      "R2 on data: 0.9828818338342395\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long370 : \n",
      "Mean Absolute Error: 0.09722401517637715\n",
      "Mean Squared Error: 0.01946555958347425\n",
      "Root Mean Squared Error: 0.1395190294672173\n",
      "R2 on data: 0.9805344404165257\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros370 : \n",
      "Mean Absolute Error: 0.16446175815859346\n",
      "Mean Squared Error: 0.03791040846581795\n",
      "Root Mean Squared Error: 0.19470595385302925\n",
      "R2 on data: 0.962089591534182\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long370 : \n",
      "Mean Absolute Error: 0.12471828550581072\n",
      "Mean Squared Error: 0.023031954350307964\n",
      "Root Mean Squared Error: 0.15176282268825908\n",
      "R2 on data: 0.9769680456496921\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros370 : \n",
      "Mean Absolute Error: 0.014909483313117011\n",
      "Mean Squared Error: 0.0003359249435877511\n",
      "Root Mean Squared Error: 0.01832825533398504\n",
      "R2 on data: 0.9996640750564122\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long370 : \n",
      "Mean Absolute Error: 0.005282709438216246\n",
      "Mean Squared Error: 4.0476061003167914e-05\n",
      "Root Mean Squared Error: 0.00636207992744259\n",
      "R2 on data: 0.9999595239389968\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros370 : \n",
      "Mean Absolute Error: 0.1492264903157171\n",
      "Mean Squared Error: 0.057547880935236016\n",
      "Root Mean Squared Error: 0.2398913940416288\n",
      "R2 on data: 0.942452119064764\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long370 : \n",
      "Mean Absolute Error: 0.24001177231599163\n",
      "Mean Squared Error: 0.11747000022710281\n",
      "Root Mean Squared Error: 0.3427389680603926\n",
      "R2 on data: 0.8825299997728971\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros370 : \n",
      "Mean Absolute Error: 0.24886041115490126\n",
      "Mean Squared Error: 0.10366964761144812\n",
      "Root Mean Squared Error: 0.3219777129110773\n",
      "R2 on data: 0.8963303523885519\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long370 : \n",
      "Mean Absolute Error: 0.25781382948696585\n",
      "Mean Squared Error: 0.1259221565675733\n",
      "Root Mean Squared Error: 0.3548551205317084\n",
      "R2 on data: 0.8740778434324267\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros370 : \n",
      "Mean Absolute Error: 0.16738574344392954\n",
      "Mean Squared Error: 0.06771759520981367\n",
      "Root Mean Squared Error: 0.260226046370869\n",
      "R2 on data: 0.9322824047901863\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long370 : \n",
      "Mean Absolute Error: 0.27160549071514967\n",
      "Mean Squared Error: 0.1374726853872809\n",
      "Root Mean Squared Error: 0.3707730915091883\n",
      "R2 on data: 0.862527314612719\n",
      "Patience, selecting features : 390\n",
      "Patience, selecting features : 390\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.65 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.9 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.97 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 13.9 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros390\n",
      "Wall time: 1.73 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros390\n",
      "Wall time: 610 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros390\n",
      "Wall time: 1.42 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long390\n",
      "Wall time: 1.23 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long390\n",
      "Wall time: 483 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long390\n",
      "Wall time: 1.01 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros390 : \n",
      "Mean Absolute Error: 0.08560062246582331\n",
      "Mean Squared Error: 0.01736768817966371\n",
      "Root Mean Squared Error: 0.1317865250306863\n",
      "R2 on data: 0.9826323118203363\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long390 : \n",
      "Mean Absolute Error: 0.09874452269306858\n",
      "Mean Squared Error: 0.019280012002232935\n",
      "Root Mean Squared Error: 0.13885248288105234\n",
      "R2 on data: 0.980719987997767\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros390 : \n",
      "Mean Absolute Error: 0.162866614574378\n",
      "Mean Squared Error: 0.0357642720019643\n",
      "Root Mean Squared Error: 0.18911444154787413\n",
      "R2 on data: 0.9642357279980357\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long390 : \n",
      "Mean Absolute Error: 0.1220953635050275\n",
      "Mean Squared Error: 0.02361504815454693\n",
      "Root Mean Squared Error: 0.1536718847237416\n",
      "R2 on data: 0.976384951845453\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros390 : \n",
      "Mean Absolute Error: 0.011987174733756215\n",
      "Mean Squared Error: 0.00022215801605684967\n",
      "Root Mean Squared Error: 0.014904966154166525\n",
      "R2 on data: 0.9997778419839431\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long390 : \n",
      "Mean Absolute Error: 0.004780025917201355\n",
      "Mean Squared Error: 3.240322701517061e-05\n",
      "Root Mean Squared Error: 0.005692383245633643\n",
      "R2 on data: 0.9999675967729849\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros390 : \n",
      "Mean Absolute Error: 0.15706591060279457\n",
      "Mean Squared Error: 0.05873813688501093\n",
      "Root Mean Squared Error: 0.24235951989763252\n",
      "R2 on data: 0.941261863114989\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long390 : \n",
      "Mean Absolute Error: 0.2484230758662423\n",
      "Mean Squared Error: 0.11757661172938083\n",
      "Root Mean Squared Error: 0.34289446150292485\n",
      "R2 on data: 0.8824233882706192\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros390 : \n",
      "Mean Absolute Error: 0.2405744450691356\n",
      "Mean Squared Error: 0.09875415815393\n",
      "Root Mean Squared Error: 0.3142517432790628\n",
      "R2 on data: 0.90124584184607\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long390 : \n",
      "Mean Absolute Error: 0.2753564374952889\n",
      "Mean Squared Error: 0.13212367299327332\n",
      "Root Mean Squared Error: 0.3634882020001108\n",
      "R2 on data: 0.8678763270067267\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros390 : \n",
      "Mean Absolute Error: 0.16624913721678503\n",
      "Mean Squared Error: 0.06894191093199385\n",
      "Root Mean Squared Error: 0.2625679167986711\n",
      "R2 on data: 0.9310580890680061\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long390 : \n",
      "Mean Absolute Error: 0.28004789287101095\n",
      "Mean Squared Error: 0.14357003259284776\n",
      "Root Mean Squared Error: 0.37890636388539023\n",
      "R2 on data: 0.8564299674071522\n",
      "Patience, selecting features : 410\n",
      "Patience, selecting features : 410\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.67 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.83 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.5 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros410\n",
      "Wall time: 1.96 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros410\n",
      "Wall time: 674 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros410\n",
      "Wall time: 1.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long410\n",
      "Wall time: 1.3 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long410\n",
      "Wall time: 509 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long410\n",
      "Wall time: 1.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros410 : \n",
      "Mean Absolute Error: 0.08632833926177567\n",
      "Mean Squared Error: 0.017833466450813143\n",
      "Root Mean Squared Error: 0.13354200257152482\n",
      "R2 on data: 0.9821665335491868\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long410 : \n",
      "Mean Absolute Error: 0.09750047108850282\n",
      "Mean Squared Error: 0.019447147008704854\n",
      "Root Mean Squared Error: 0.13945302796535058\n",
      "R2 on data: 0.9805528529912951\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros410 : \n",
      "Mean Absolute Error: 0.14886010892077606\n",
      "Mean Squared Error: 0.03234607852268377\n",
      "Root Mean Squared Error: 0.1798501557482889\n",
      "R2 on data: 0.9676539214773162\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long410 : \n",
      "Mean Absolute Error: 0.1264308198473513\n",
      "Mean Squared Error: 0.023282050736003767\n",
      "Root Mean Squared Error: 0.15258456912808638\n",
      "R2 on data: 0.9767179492639962\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros410 : \n",
      "Mean Absolute Error: 0.009693712908861925\n",
      "Mean Squared Error: 0.0001435490191928479\n",
      "Root Mean Squared Error: 0.011981194397590246\n",
      "R2 on data: 0.9998564509808071\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long410 : \n",
      "Mean Absolute Error: 0.004796711895552067\n",
      "Mean Squared Error: 3.491247613664474e-05\n",
      "Root Mean Squared Error: 0.005908678036299214\n",
      "R2 on data: 0.9999650875238634\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros410 : \n",
      "Mean Absolute Error: 0.1609345091347819\n",
      "Mean Squared Error: 0.06051813697575657\n",
      "Root Mean Squared Error: 0.2460043434083158\n",
      "R2 on data: 0.9394818630242434\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long410 : \n",
      "Mean Absolute Error: 0.24986617572753866\n",
      "Mean Squared Error: 0.11799354912984908\n",
      "Root Mean Squared Error: 0.34350189101349804\n",
      "R2 on data: 0.8820064508701508\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros410 : \n",
      "Mean Absolute Error: 0.2306223638518655\n",
      "Mean Squared Error: 0.08940380114326402\n",
      "Root Mean Squared Error: 0.29900468414936915\n",
      "R2 on data: 0.9105961988567359\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long410 : \n",
      "Mean Absolute Error: 0.30729375586369445\n",
      "Mean Squared Error: 0.16914247828939696\n",
      "Root Mean Squared Error: 0.4112693500485989\n",
      "R2 on data: 0.830857521710603\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros410 : \n",
      "Mean Absolute Error: 0.18123195000700973\n",
      "Mean Squared Error: 0.07513228716782741\n",
      "Root Mean Squared Error: 0.27410269456506153\n",
      "R2 on data: 0.9248677128321726\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long410 : \n",
      "Mean Absolute Error: 0.25565719718180235\n",
      "Mean Squared Error: 0.13143014468523936\n",
      "Root Mean Squared Error: 0.36253295668840835\n",
      "R2 on data: 0.8685698553147606\n",
      "Patience, selecting features : 430\n",
      "Patience, selecting features : 430\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 13.3 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 5.16 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.5 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7.04 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.9 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros430\n",
      "Wall time: 1.88 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros430\n",
      "Wall time: 666 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros430\n",
      "Wall time: 1.6 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long430\n",
      "Wall time: 1.36 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long430\n",
      "Wall time: 565 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long430\n",
      "Wall time: 1.15 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros430 : \n",
      "Mean Absolute Error: 0.08441514833048143\n",
      "Mean Squared Error: 0.017436298502363265\n",
      "Root Mean Squared Error: 0.13204657701872952\n",
      "R2 on data: 0.9825637014976367\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long430 : \n",
      "Mean Absolute Error: 0.09584173561574853\n",
      "Mean Squared Error: 0.01931223231138062\n",
      "Root Mean Squared Error: 0.1389684579729538\n",
      "R2 on data: 0.9806877676886194\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros430 : \n",
      "Mean Absolute Error: 0.16017810842004745\n",
      "Mean Squared Error: 0.035224245106594415\n",
      "Root Mean Squared Error: 0.18768123269681072\n",
      "R2 on data: 0.9647757548934056\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long430 : \n",
      "Mean Absolute Error: 0.1205362727811286\n",
      "Mean Squared Error: 0.02211338195180832\n",
      "Root Mean Squared Error: 0.14870568903645995\n",
      "R2 on data: 0.9778866180481917\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros430 : \n",
      "Mean Absolute Error: 0.009198780010536318\n",
      "Mean Squared Error: 0.00012893089321815016\n",
      "Root Mean Squared Error: 0.011354774027612797\n",
      "R2 on data: 0.9998710691067818\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long430 : \n",
      "Mean Absolute Error: 0.004648130195670313\n",
      "Mean Squared Error: 3.175481615262474e-05\n",
      "Root Mean Squared Error: 0.005635141183025031\n",
      "R2 on data: 0.9999682451838474\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros430 : \n",
      "Mean Absolute Error: 0.16279243858291403\n",
      "Mean Squared Error: 0.060077885768586366\n",
      "Root Mean Squared Error: 0.24510790637714314\n",
      "R2 on data: 0.9399221142314136\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long430 : \n",
      "Mean Absolute Error: 0.2482377231519974\n",
      "Mean Squared Error: 0.11927494520620247\n",
      "Root Mean Squared Error: 0.3453620494585392\n",
      "R2 on data: 0.8807250547937975\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros430 : \n",
      "Mean Absolute Error: 0.22930973080812322\n",
      "Mean Squared Error: 0.09427188205349399\n",
      "Root Mean Squared Error: 0.3070372649264157\n",
      "R2 on data: 0.905728117946506\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long430 : \n",
      "Mean Absolute Error: 0.28604820258593144\n",
      "Mean Squared Error: 0.13998837385891483\n",
      "Root Mean Squared Error: 0.37415020227031126\n",
      "R2 on data: 0.8600116261410851\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros430 : \n",
      "Mean Absolute Error: 0.19612079798581838\n",
      "Mean Squared Error: 0.07659848563450133\n",
      "Root Mean Squared Error: 0.2767643142359602\n",
      "R2 on data: 0.9234015143654987\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long430 : \n",
      "Mean Absolute Error: 0.2706544932518485\n",
      "Mean Squared Error: 0.1382168615882416\n",
      "Root Mean Squared Error: 0.3717752837242433\n",
      "R2 on data: 0.8617831384117584\n",
      "Patience, selecting features : 450\n",
      "Patience, selecting features : 450\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 5.02 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.8 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.43 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.6 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros450\n",
      "Wall time: 1.98 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 702 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros450\n",
      "Wall time: 1.56 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long450\n",
      "Wall time: 1.36 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long450\n",
      "Wall time: 529 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long450\n",
      "Wall time: 1.24 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros450 : \n",
      "Mean Absolute Error: 0.08585884455470962\n",
      "Mean Squared Error: 0.0179112884224989\n",
      "Root Mean Squared Error: 0.13383306176912677\n",
      "R2 on data: 0.9820887115775011\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long450 : \n",
      "Mean Absolute Error: 0.09694755926425133\n",
      "Mean Squared Error: 0.01913057695705795\n",
      "Root Mean Squared Error: 0.13831332892045492\n",
      "R2 on data: 0.980869423042942\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros450 : \n",
      "Mean Absolute Error: 0.1510254945284242\n",
      "Mean Squared Error: 0.0333101872106211\n",
      "Root Mean Squared Error: 0.18251078655964723\n",
      "R2 on data: 0.9666898127893789\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long450 : \n",
      "Mean Absolute Error: 0.13467572924549295\n",
      "Mean Squared Error: 0.026078068941806712\n",
      "Root Mean Squared Error: 0.16148705502858957\n",
      "R2 on data: 0.9739219310581932\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros450 : \n",
      "Mean Absolute Error: 0.009576429469986759\n",
      "Mean Squared Error: 0.00014453112748621482\n",
      "Root Mean Squared Error: 0.012022109943192786\n",
      "R2 on data: 0.9998554688725138\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long450 : \n",
      "Mean Absolute Error: 0.003998632201591348\n",
      "Mean Squared Error: 2.3715077737941266e-05\n",
      "Root Mean Squared Error: 0.004869812905845692\n",
      "R2 on data: 0.9999762849222621\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros450 : \n",
      "Mean Absolute Error: 0.15648782147096718\n",
      "Mean Squared Error: 0.05962564988150046\n",
      "Root Mean Squared Error: 0.24418363966797707\n",
      "R2 on data: 0.9403743501184996\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long450 : \n",
      "Mean Absolute Error: 0.249564711530201\n",
      "Mean Squared Error: 0.12157389358218017\n",
      "Root Mean Squared Error: 0.34867448083015795\n",
      "R2 on data: 0.8784261064178198\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros450 : \n",
      "Mean Absolute Error: 0.2277449922354078\n",
      "Mean Squared Error: 0.0962030872160127\n",
      "Root Mean Squared Error: 0.3101662251374458\n",
      "R2 on data: 0.9037969127839873\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long450 : \n",
      "Mean Absolute Error: 0.29841574290626494\n",
      "Mean Squared Error: 0.1507266249678113\n",
      "Root Mean Squared Error: 0.38823527012342823\n",
      "R2 on data: 0.8492733750321886\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros450 : \n",
      "Mean Absolute Error: 0.19189886750655233\n",
      "Mean Squared Error: 0.07438171106981091\n",
      "Root Mean Squared Error: 0.27273010664356606\n",
      "R2 on data: 0.925618288930189\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long450 : \n",
      "Mean Absolute Error: 0.2655878858106993\n",
      "Mean Squared Error: 0.13708852096645688\n",
      "Root Mean Squared Error: 0.3702546704181554\n",
      "R2 on data: 0.862911479033543\n",
      "Patience, selecting features : 470\n",
      "Patience, selecting features : 470\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.94 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.82 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros470\n",
      "Wall time: 2.05 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros470\n",
      "Wall time: 783 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros470\n",
      "Wall time: 1.65 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long470\n",
      "Wall time: 1.41 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long470\n",
      "Wall time: 551 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long470\n",
      "Wall time: 1.3 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros470 : \n",
      "Mean Absolute Error: 0.08572582105437426\n",
      "Mean Squared Error: 0.017651574234488997\n",
      "Root Mean Squared Error: 0.1328592271334174\n",
      "R2 on data: 0.982348425765511\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long470 : \n",
      "Mean Absolute Error: 0.0978709220107513\n",
      "Mean Squared Error: 0.019513362373886397\n",
      "Root Mean Squared Error: 0.1396902372175178\n",
      "R2 on data: 0.9804866376261137\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros470 : \n",
      "Mean Absolute Error: 0.14501603477296332\n",
      "Mean Squared Error: 0.03054134110560458\n",
      "Root Mean Squared Error: 0.1747608111265354\n",
      "R2 on data: 0.9694586588943954\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long470 : \n",
      "Mean Absolute Error: 0.13441988318852535\n",
      "Mean Squared Error: 0.026709338919199733\n",
      "Root Mean Squared Error: 0.16342992051396138\n",
      "R2 on data: 0.9732906610808003\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros470 : \n",
      "Mean Absolute Error: 0.009903207951019361\n",
      "Mean Squared Error: 0.00014878049555041827\n",
      "Root Mean Squared Error: 0.012197561049259736\n",
      "R2 on data: 0.9998512195044496\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long470 : \n",
      "Mean Absolute Error: 0.003948747123398567\n",
      "Mean Squared Error: 2.3403886865114237e-05\n",
      "Root Mean Squared Error: 0.004837756387532782\n",
      "R2 on data: 0.9999765961131349\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros470 : \n",
      "Mean Absolute Error: 0.15866233826686324\n",
      "Mean Squared Error: 0.06000936623337098\n",
      "Root Mean Squared Error: 0.2449680922760574\n",
      "R2 on data: 0.9399906337666291\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long470 : \n",
      "Mean Absolute Error: 0.24228286280480915\n",
      "Mean Squared Error: 0.11532927689448724\n",
      "Root Mean Squared Error: 0.3396016444225311\n",
      "R2 on data: 0.8846707231055128\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros470 : \n",
      "Mean Absolute Error: 0.22068939325055856\n",
      "Mean Squared Error: 0.09616300408054465\n",
      "Root Mean Squared Error: 0.3101016028345301\n",
      "R2 on data: 0.9038369959194553\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long470 : \n",
      "Mean Absolute Error: 0.2865426092941236\n",
      "Mean Squared Error: 0.14224733900849937\n",
      "Root Mean Squared Error: 0.37715691563127857\n",
      "R2 on data: 0.8577526609915006\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros470 : \n",
      "Mean Absolute Error: 0.19185389432841357\n",
      "Mean Squared Error: 0.0745089776708584\n",
      "Root Mean Squared Error: 0.2729633266042499\n",
      "R2 on data: 0.9254910223291416\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long470 : \n",
      "Mean Absolute Error: 0.2625865631860142\n",
      "Mean Squared Error: 0.13104963586783952\n",
      "Root Mean Squared Error: 0.3620077842641502\n",
      "R2 on data: 0.8689503641321604\n",
      "Patience, selecting features : 490\n",
      "Patience, selecting features : 490\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.3 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.94 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.3 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.7 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.62 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 13.8 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros490\n",
      "Wall time: 2.17 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros490\n",
      "Wall time: 838 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros490\n",
      "Wall time: 1.73 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long490\n",
      "Wall time: 1.48 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long490\n",
      "Wall time: 591 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long490\n",
      "Wall time: 1.36 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros490 : \n",
      "Mean Absolute Error: 0.0877642105742195\n",
      "Mean Squared Error: 0.018521288000017105\n",
      "Root Mean Squared Error: 0.1360929388323182\n",
      "R2 on data: 0.9814787119999829\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long490 : \n",
      "Mean Absolute Error: 0.09886063417616137\n",
      "Mean Squared Error: 0.019420868538558497\n",
      "Root Mean Squared Error: 0.13935877632412857\n",
      "R2 on data: 0.9805791314614415\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros490 : \n",
      "Mean Absolute Error: 0.1615840916647461\n",
      "Mean Squared Error: 0.03634505823213625\n",
      "Root Mean Squared Error: 0.19064379935402107\n",
      "R2 on data: 0.9636549417678637\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long490 : \n",
      "Mean Absolute Error: 0.12154477656215415\n",
      "Mean Squared Error: 0.022443496808916354\n",
      "Root Mean Squared Error: 0.14981153763617927\n",
      "R2 on data: 0.9775565031910837\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros490 : \n",
      "Mean Absolute Error: 0.011067177550591866\n",
      "Mean Squared Error: 0.00017913354659412925\n",
      "Root Mean Squared Error: 0.013384078100270083\n",
      "R2 on data: 0.9998208664534058\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long490 : \n",
      "Mean Absolute Error: 0.004732883624865248\n",
      "Mean Squared Error: 3.2615122490090376e-05\n",
      "Root Mean Squared Error: 0.005710965110214768\n",
      "R2 on data: 0.9999673848775099\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros490 : \n",
      "Mean Absolute Error: 0.16038455799413298\n",
      "Mean Squared Error: 0.06233646418982045\n",
      "Root Mean Squared Error: 0.24967271414758252\n",
      "R2 on data: 0.9376635358101796\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long490 : \n",
      "Mean Absolute Error: 0.24825720231896686\n",
      "Mean Squared Error: 0.12265880695989155\n",
      "Root Mean Squared Error: 0.3502267936065023\n",
      "R2 on data: 0.8773411930401084\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros490 : \n",
      "Mean Absolute Error: 0.21123211471235434\n",
      "Mean Squared Error: 0.08110770909560762\n",
      "Root Mean Squared Error: 0.28479415214432974\n",
      "R2 on data: 0.9188922909043924\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long490 : \n",
      "Mean Absolute Error: 0.26767362886808554\n",
      "Mean Squared Error: 0.14598593264265314\n",
      "Root Mean Squared Error: 0.3820810550690169\n",
      "R2 on data: 0.8540140673573469\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros490 : \n",
      "Mean Absolute Error: 0.18405929577309607\n",
      "Mean Squared Error: 0.07097866459439428\n",
      "Root Mean Squared Error: 0.2664182137061847\n",
      "R2 on data: 0.9290213354056057\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long490 : \n",
      "Mean Absolute Error: 0.2652861184228973\n",
      "Mean Squared Error: 0.13341302571010324\n",
      "Root Mean Squared Error: 0.3652574786504764\n",
      "R2 on data: 0.8665869742898967\n",
      "Patience, selecting features : 510\n",
      "Patience, selecting features : 510\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.6 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.2 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.46 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 13.8 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros510\n",
      "Wall time: 2.39 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros510\n",
      "Wall time: 797 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros510\n",
      "Wall time: 1.83 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long510\n",
      "Wall time: 1.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long510\n",
      "Wall time: 646 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long510\n",
      "Wall time: 1.36 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros510 : \n",
      "Mean Absolute Error: 0.08616792857019483\n",
      "Mean Squared Error: 0.018068977529785705\n",
      "Root Mean Squared Error: 0.13442089692375106\n",
      "R2 on data: 0.9819310224702142\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long510 : \n",
      "Mean Absolute Error: 0.09836854265257766\n",
      "Mean Squared Error: 0.019754945127845515\n",
      "Root Mean Squared Error: 0.1405522860996772\n",
      "R2 on data: 0.9802450548721545\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros510 : \n",
      "Mean Absolute Error: 0.1537954865554703\n",
      "Mean Squared Error: 0.032178152219538396\n",
      "Root Mean Squared Error: 0.17938269765932943\n",
      "R2 on data: 0.9678218477804617\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long510 : \n",
      "Mean Absolute Error: 0.12548518534499634\n",
      "Mean Squared Error: 0.02362452126905116\n",
      "Root Mean Squared Error: 0.15370270416961165\n",
      "R2 on data: 0.9763754787309489\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros510 : \n",
      "Mean Absolute Error: 0.010152028859621976\n",
      "Mean Squared Error: 0.00015720480132162476\n",
      "Root Mean Squared Error: 0.012538133885137165\n",
      "R2 on data: 0.9998427951986784\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long510 : \n",
      "Mean Absolute Error: 0.0037245948316520583\n",
      "Mean Squared Error: 2.025012098930297e-05\n",
      "Root Mean Squared Error: 0.0045000134432358055\n",
      "R2 on data: 0.9999797498790107\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros510 : \n",
      "Mean Absolute Error: 0.1619075423349813\n",
      "Mean Squared Error: 0.06205286087294835\n",
      "Root Mean Squared Error: 0.2491041165315185\n",
      "R2 on data: 0.9379471391270516\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long510 : \n",
      "Mean Absolute Error: 0.25620254523346037\n",
      "Mean Squared Error: 0.1253686346450636\n",
      "Root Mean Squared Error: 0.35407433491438434\n",
      "R2 on data: 0.8746313653549364\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros510 : \n",
      "Mean Absolute Error: 0.22114194302596876\n",
      "Mean Squared Error: 0.09533318558377861\n",
      "Root Mean Squared Error: 0.3087607254554546\n",
      "R2 on data: 0.9046668144162213\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long510 : \n",
      "Mean Absolute Error: 0.2894440494187052\n",
      "Mean Squared Error: 0.14860746349313753\n",
      "Root Mean Squared Error: 0.3854963858366736\n",
      "R2 on data: 0.8513925365068624\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros510 : \n",
      "Mean Absolute Error: 0.1791818644161794\n",
      "Mean Squared Error: 0.06567121985860266\n",
      "Root Mean Squared Error: 0.25626396519722133\n",
      "R2 on data: 0.9343287801413973\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long510 : \n",
      "Mean Absolute Error: 0.26956966040795727\n",
      "Mean Squared Error: 0.1375467003598919\n",
      "Root Mean Squared Error: 0.37087288976129257\n",
      "R2 on data: 0.8624532996401081\n",
      "Patience, selecting features : 530\n",
      "Patience, selecting features : 530\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.5 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.65 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.8 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.42 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros530\n",
      "Wall time: 2.48 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 923 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros530\n",
      "Wall time: 2.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long530\n",
      "Wall time: 1.77 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long530\n",
      "Wall time: 640 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long530\n",
      "Wall time: 1.46 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros530 : \n",
      "Mean Absolute Error: 0.08549889861262565\n",
      "Mean Squared Error: 0.017546105299605378\n",
      "Root Mean Squared Error: 0.13246171257992015\n",
      "R2 on data: 0.9824538947003946\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long530 : \n",
      "Mean Absolute Error: 0.0986726441559159\n",
      "Mean Squared Error: 0.019717546494131277\n",
      "Root Mean Squared Error: 0.14041918136113485\n",
      "R2 on data: 0.9802824535058687\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros530 : \n",
      "Mean Absolute Error: 0.15101134932399324\n",
      "Mean Squared Error: 0.03215614472527837\n",
      "Root Mean Squared Error: 0.1793213448680284\n",
      "R2 on data: 0.9678438552747216\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long530 : \n",
      "Mean Absolute Error: 0.1259546324731932\n",
      "Mean Squared Error: 0.023917317438242457\n",
      "Root Mean Squared Error: 0.15465224679338627\n",
      "R2 on data: 0.9760826825617576\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros530 : \n",
      "Mean Absolute Error: 0.009247465187491952\n",
      "Mean Squared Error: 0.00013267284520113626\n",
      "Root Mean Squared Error: 0.011518369902079733\n",
      "R2 on data: 0.9998673271547989\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long530 : \n",
      "Mean Absolute Error: 0.004185205700244694\n",
      "Mean Squared Error: 2.597977415385466e-05\n",
      "Root Mean Squared Error: 0.0050970358203425116\n",
      "R2 on data: 0.9999740202258461\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros530 : \n",
      "Mean Absolute Error: 0.1560147380899267\n",
      "Mean Squared Error: 0.059637124686976586\n",
      "Root Mean Squared Error: 0.24420713479949063\n",
      "R2 on data: 0.9403628753130234\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long530 : \n",
      "Mean Absolute Error: 0.24992963333420692\n",
      "Mean Squared Error: 0.1202020442263983\n",
      "Root Mean Squared Error: 0.34670166458556023\n",
      "R2 on data: 0.8797979557736016\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros530 : \n",
      "Mean Absolute Error: 0.21400994076992785\n",
      "Mean Squared Error: 0.08402061841091393\n",
      "Root Mean Squared Error: 0.28986310287946954\n",
      "R2 on data: 0.9159793815890861\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long530 : \n",
      "Mean Absolute Error: 0.2915579934461695\n",
      "Mean Squared Error: 0.14155769954555633\n",
      "Root Mean Squared Error: 0.3762415441515681\n",
      "R2 on data: 0.8584423004544436\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros530 : \n",
      "Mean Absolute Error: 0.1919075308310447\n",
      "Mean Squared Error: 0.0911127318696961\n",
      "Root Mean Squared Error: 0.3018488560019668\n",
      "R2 on data: 0.9088872681303038\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long530 : \n",
      "Mean Absolute Error: 0.27200981778013594\n",
      "Mean Squared Error: 0.1394197127150735\n",
      "Root Mean Squared Error: 0.3733894919719535\n",
      "R2 on data: 0.8605802872849264\n",
      "Patience, selecting features : 550\n",
      "Patience, selecting features : 550\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.84 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.2 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.69 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros550\n",
      "Wall time: 2.67 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros550\n",
      "Wall time: 913 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros550\n",
      "Wall time: 1.95 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long550\n",
      "Wall time: 1.61 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long550\n",
      "Wall time: 629 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long550\n",
      "Wall time: 1.34 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros550 : \n",
      "Mean Absolute Error: 0.08553802317154784\n",
      "Mean Squared Error: 0.017580438098305354\n",
      "Root Mean Squared Error: 0.13259124442551007\n",
      "R2 on data: 0.9824195619016947\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long550 : \n",
      "Mean Absolute Error: 0.0990541533146494\n",
      "Mean Squared Error: 0.020106501107592732\n",
      "Root Mean Squared Error: 0.1417973945726533\n",
      "R2 on data: 0.9798934988924073\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros550 : \n",
      "Mean Absolute Error: 0.14840238054600868\n",
      "Mean Squared Error: 0.031409187560409196\n",
      "Root Mean Squared Error: 0.1772263737721031\n",
      "R2 on data: 0.9685908124395908\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long550 : \n",
      "Mean Absolute Error: 0.12419343568156245\n",
      "Mean Squared Error: 0.023435564294892474\n",
      "Root Mean Squared Error: 0.15308678680700197\n",
      "R2 on data: 0.9765644357051075\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros550 : \n",
      "Mean Absolute Error: 0.0072401026871785346\n",
      "Mean Squared Error: 8.0344358664216e-05\n",
      "Root Mean Squared Error: 0.008963501473431909\n",
      "R2 on data: 0.9999196556413358\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long550 : \n",
      "Mean Absolute Error: 0.004075928664146588\n",
      "Mean Squared Error: 2.4247236157744476e-05\n",
      "Root Mean Squared Error: 0.00492414826723815\n",
      "R2 on data: 0.9999757527638422\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros550 : \n",
      "Mean Absolute Error: 0.16394108119948136\n",
      "Mean Squared Error: 0.06285608156491118\n",
      "Root Mean Squared Error: 0.2507111516564654\n",
      "R2 on data: 0.9371439184350888\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long550 : \n",
      "Mean Absolute Error: 0.24941539034268076\n",
      "Mean Squared Error: 0.12094044182355948\n",
      "Root Mean Squared Error: 0.34776492322193664\n",
      "R2 on data: 0.8790595581764404\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros550 : \n",
      "Mean Absolute Error: 0.21912834249998434\n",
      "Mean Squared Error: 0.08802695083526313\n",
      "Root Mean Squared Error: 0.2966933616299211\n",
      "R2 on data: 0.9119730491647369\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long550 : \n",
      "Mean Absolute Error: 0.29959560855155415\n",
      "Mean Squared Error: 0.1502287287801851\n",
      "Root Mean Squared Error: 0.3875935097240214\n",
      "R2 on data: 0.8497712712198149\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros550 : \n",
      "Mean Absolute Error: 0.19826987884576644\n",
      "Mean Squared Error: 0.0878830636937247\n",
      "Root Mean Squared Error: 0.29645077785987456\n",
      "R2 on data: 0.9121169363062753\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long550 : \n",
      "Mean Absolute Error: 0.2675621143293695\n",
      "Mean Squared Error: 0.13281211665116782\n",
      "Root Mean Squared Error: 0.3644339674771931\n",
      "R2 on data: 0.8671878833488321\n",
      "Patience, selecting features : 570\n",
      "Patience, selecting features : 570\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.6 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.78 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 10.4 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 15.9 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 6.38 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.2 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros570\n",
      "Wall time: 2.82 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros570\n",
      "Wall time: 918 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros570\n",
      "Wall time: 2.03 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long570\n",
      "Wall time: 1.69 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long570\n",
      "Wall time: 650 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long570\n",
      "Wall time: 1.42 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros570 : \n",
      "Mean Absolute Error: 0.08535022528872133\n",
      "Mean Squared Error: 0.01749096037457599\n",
      "Root Mean Squared Error: 0.13225339456730778\n",
      "R2 on data: 0.982509039625424\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long570 : \n",
      "Mean Absolute Error: 0.09837407177082007\n",
      "Mean Squared Error: 0.019832636963331148\n",
      "Root Mean Squared Error: 0.14082839544399825\n",
      "R2 on data: 0.9801673630366688\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros570 : \n",
      "Mean Absolute Error: 0.14879096282740287\n",
      "Mean Squared Error: 0.03154340293036914\n",
      "Root Mean Squared Error: 0.1776046253068009\n",
      "R2 on data: 0.9684565970696308\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long570 : \n",
      "Mean Absolute Error: 0.12793430384318424\n",
      "Mean Squared Error: 0.023989705818929417\n",
      "Root Mean Squared Error: 0.1548861059583119\n",
      "R2 on data: 0.9760102941810705\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros570 : \n",
      "Mean Absolute Error: 0.008888893488703056\n",
      "Mean Squared Error: 0.00012384850020357623\n",
      "Root Mean Squared Error: 0.011128724104926685\n",
      "R2 on data: 0.9998761514997965\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long570 : \n",
      "Mean Absolute Error: 0.0036980632524718383\n",
      "Mean Squared Error: 1.987406701328796e-05\n",
      "Root Mean Squared Error: 0.004458033985210068\n",
      "R2 on data: 0.9999801259329867\n",
      "Fitting test data ===========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros570 : \n",
      "Mean Absolute Error: 0.15984773153959428\n",
      "Mean Squared Error: 0.05949805186127791\n",
      "Root Mean Squared Error: 0.2439222250252689\n",
      "R2 on data: 0.9405019481387221\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long570 : \n",
      "Mean Absolute Error: 0.24941542533765307\n",
      "Mean Squared Error: 0.11824668766284148\n",
      "Root Mean Squared Error: 0.3438701610533276\n",
      "R2 on data: 0.8817533123371585\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros570 : \n",
      "Mean Absolute Error: 0.22552412700317953\n",
      "Mean Squared Error: 0.09544476359207012\n",
      "Root Mean Squared Error: 0.30894135947145396\n",
      "R2 on data: 0.9045552364079299\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long570 : \n",
      "Mean Absolute Error: 0.2744826528820205\n",
      "Mean Squared Error: 0.1352733650022469\n",
      "Root Mean Squared Error: 0.36779527593791483\n",
      "R2 on data: 0.864726634997753\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros570 : \n",
      "Mean Absolute Error: 0.1843987127899165\n",
      "Mean Squared Error: 0.07912003254408144\n",
      "Root Mean Squared Error: 0.2812828337173839\n",
      "R2 on data: 0.9208799674559185\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long570 : \n",
      "Mean Absolute Error: 0.2792154326289486\n",
      "Mean Squared Error: 0.1374760434595926\n",
      "Root Mean Squared Error: 0.3707776199551324\n",
      "R2 on data: 0.8625239565404074\n",
      "Patience, selecting features : 590\n",
      "Patience, selecting features : 590\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 12.4 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 4.77 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 11.1 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 16.1 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 7.09 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 14.7 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros590\n",
      "Wall time: 2.61 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros590\n",
      "Wall time: 966 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros590\n",
      "Wall time: 2.27 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long590\n",
      "Wall time: 1.79 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long590\n",
      "Wall time: 700 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long590\n",
      "Wall time: 1.54 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Fitting training data -------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros590 : \n",
      "Mean Absolute Error: 0.0866139485419076\n",
      "Mean Squared Error: 0.018105165635821277\n",
      "Root Mean Squared Error: 0.13455543703552553\n",
      "R2 on data: 0.9818948343641787\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long590 : \n",
      "Mean Absolute Error: 0.10050278229418828\n",
      "Mean Squared Error: 0.020545959655866718\n",
      "Root Mean Squared Error: 0.14333861885712001\n",
      "R2 on data: 0.9794540403441333\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros590 : \n",
      "Mean Absolute Error: 0.15173576942792955\n",
      "Mean Squared Error: 0.03339108160717927\n",
      "Root Mean Squared Error: 0.18273226755879562\n",
      "R2 on data: 0.9666089183928207\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long590 : \n",
      "Mean Absolute Error: 0.12342385112467787\n",
      "Mean Squared Error: 0.022892958091884845\n",
      "Root Mean Squared Error: 0.15130419059591457\n",
      "R2 on data: 0.9771070419081151\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros590 : \n",
      "Mean Absolute Error: 0.007845647563159074\n",
      "Mean Squared Error: 9.510949549765068e-05\n",
      "Root Mean Squared Error: 0.00975240972773656\n",
      "R2 on data: 0.9999048905045024\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long590 : \n",
      "Mean Absolute Error: 0.003608666310552678\n",
      "Mean Squared Error: 1.997683697286289e-05\n",
      "Root Mean Squared Error: 0.004469545499585264\n",
      "R2 on data: 0.9999800231630271\n",
      "Fitting test data ===========\n",
      "Model : Random Forest\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros590 : \n",
      "Mean Absolute Error: 0.16494998315973977\n",
      "Mean Squared Error: 0.06146486776343123\n",
      "Root Mean Squared Error: 0.2479210918083236\n",
      "R2 on data: 0.9385351322365687\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long590 : \n",
      "Mean Absolute Error: 0.2597659346876405\n",
      "Mean Squared Error: 0.1282233181087503\n",
      "Root Mean Squared Error: 0.3580828369368606\n",
      "R2 on data: 0.8717766818912497\n",
      "Model : Adaboost\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros590 : \n",
      "Mean Absolute Error: 0.2337836670293418\n",
      "Mean Squared Error: 0.10271949663978887\n",
      "Root Mean Squared Error: 0.3204988247089042\n",
      "R2 on data: 0.8972805033602111\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long590 : \n",
      "Mean Absolute Error: 0.279455452467567\n",
      "Mean Squared Error: 0.13800278431902832\n",
      "Root Mean Squared Error: 0.37148725996866744\n",
      "R2 on data: 0.8619972156809717\n",
      "Model : Gradient Boost\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros590 : \n",
      "Mean Absolute Error: 0.19202411099677347\n",
      "Mean Squared Error: 0.08427610888922378\n",
      "Root Mean Squared Error: 0.2903034772255127\n",
      "R2 on data: 0.9157238911107762\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long590 : \n",
      "Mean Absolute Error: 0.2816536760320602\n",
      "Mean Squared Error: 0.14259605160742653\n",
      "Root Mean Squared Error: 0.3776189237941162\n",
      "R2 on data: 0.8574039483925734\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# call training function\n",
    "model_names = ['Random Forest', \"Adaboost\", \"Gradient Boost\"]\n",
    "df_types = [\"full_cros\", \"full_long\", \"imp_cros\", \"imp_long\"]\n",
    "\n",
    "# Set different set of features to find optimal set\n",
    "# top = np.arange(50,600, 50) \n",
    "top = np.arange(10,600, 20)\n",
    "\n",
    "# Base models scores for training and testing\n",
    "final_score = [{} for i in range(len(top))]\n",
    "\n",
    "# Now get each set of important features do the following steps\n",
    "# 1. Split data into train and test\n",
    "# 2. Perform scaling \n",
    "# 3. Train models\n",
    "# 4. Predict and evaluate\n",
    "for k in range(len(top)):\n",
    "    FS = SelectFeatures()\n",
    "    for index, key in enumerate(full_data):\n",
    "        print(\"Patience, selecting features :\", top[k])\n",
    "        FS.CallFit(df = full_data[key],labels = labels[index], top_fea=top[k])\n",
    "        important_features = FS.UnivFeatureSelection(df = full_data[key], index = index)\n",
    "     \n",
    "    TT = Epic_ML_3.TrainTest()\n",
    "    \n",
    "    # save the data, full data and import features together in a list\n",
    "    dfs_final = [full_data['full_df_cross'], full_data['full_df_long'], \n",
    "                 important_features[0], important_features[1]]\n",
    "    \n",
    "    df_types1 = [\"full_cros\", \"full_long\"]\n",
    "    df_types2 = [\"imp_cros\", \"imp_long\"]\n",
    "    df_types = df_types1 + [s + str(top[k]) for s in df_types2] # add number to important features\n",
    "    \n",
    "    for i in range(len(dfs_final)):\n",
    "        print(i)\n",
    "        if i == 0 or i == 2:\n",
    "            j = 0 # labels\n",
    "        else:\n",
    "            j = 1\n",
    "            \n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(dfs_final[i],\n",
    "                                                                                    labels[j], \n",
    "                                                                                    test_size = 0.25, \n",
    "                                                                                    random_state = 42)\n",
    "        \n",
    "        # Scale data\n",
    "        data, data_scaled = TT.ScaleData(train_features, test_features, train_labels, test_labels)\n",
    "        \n",
    "    \n",
    "    # Train models\n",
    "    trained_models_base = Epic_ML_3.train_models(data_scaled=data_scaled, \n",
    "                                model_names=model_names, \n",
    "                                df_types=df_types,\n",
    "                                indx1=0, indx2=1)\n",
    "    \n",
    "    # Predict and get the scores\n",
    "    key = str(top[k]) + \" Features\"\n",
    "    final_score[k][key] = PredictEvaluate(trained_models_base, df_types, model_names, \n",
    "                   data_scaled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Output Data/Epic Scores on different set of features.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save scores on different set of features\n",
    "joblib.dump(final_score, \"E:/Machine Learning/Output Data/Epic Scores on different set of features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Now get the scores and calcuate average of the model for error and r2 and compare it with the full data to find out which feature set is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Mean Absolute Error', 'Mean Square Error',\n",
    "    \"Root Mean Sq Error\", \"R Squared\"]\n",
    "\n",
    "def CreatDF(data, cols):\n",
    "    \"\"\"\n",
    "    Funtion to create a dataframe out of various accuracy measures\n",
    "    Parameters:\n",
    "    data: A dictionary\n",
    "    cols: Names for the columns of dataframe\n",
    "    \"\"\"\n",
    "    score = pd.DataFrame(data, index=[cols]).T\n",
    "    score.sort_index(inplace = True)\n",
    "    return score\n",
    "\n",
    "\n",
    "def GetAverage(score, patern, colname):\n",
    "    \"\"\"\n",
    "    Get average of the accuracy measures\n",
    "    Parameters: \n",
    "    score: dataframe of scores\n",
    "    patern: A string mentioning the pattern of the score you want to pull out\n",
    "    colname: Name for the column\n",
    "    \"\"\"\n",
    "    imp = score.iloc[score.index.str.contains(patern),:]\n",
    "    mean_score = imp[[colname]].mean()\n",
    "    return mean_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store\n",
    "test_rmse = {}\n",
    "test_mabe = {}\n",
    "\n",
    "# get all keys\n",
    "keys = [z for y in (x.keys() for x in final_score) for z in y]\n",
    "\n",
    "# Now get the data for each feature set, convert to data frame\n",
    "# And calculate average score from all three models\n",
    "for i in range(len(final_score)):\n",
    "    key = keys[i]\n",
    "    df = final_score[i][key][1]\n",
    "    df_score = CreatDF(data=df, cols=cols)\n",
    "    mean_mabe = GetAverage(score = df_score, patern='_imp_', \n",
    "                         colname='Mean Absolute Error')\n",
    "    mean_rmse = GetAverage(score = df_score, patern='_imp_', \n",
    "                         colname='Root Mean Sq Error')\n",
    "    \n",
    "    test_mabe[key] = mean_mabe\n",
    "    test_rmse[key] = mean_rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mabe = pd.DataFrame(test_mabe).T\n",
    "rmse = pd.DataFrame(test_rmse).T\n",
    "final = pd.merge(mabe, rmse, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features Mean Absolute Error Root Mean Sq Error\n",
      "0       10               0.2080             0.3032\n",
      "1       30               0.2021             0.2896\n",
      "2       50               0.1952             0.2745\n",
      "3       70               0.2037             0.2902\n",
      "4       90               0.2004             0.2910\n",
      "5      110               0.2015             0.2947\n",
      "6      130               0.2084             0.2994\n",
      "7      150               0.1939             0.2850\n",
      "8      170               0.2106             0.3035\n",
      "9      190               0.2098             0.3033\n",
      "10     210               0.2145             0.3070\n",
      "11     230               0.2060             0.3032\n",
      "12     250               0.2188             0.3148\n",
      "13     270               0.2182             0.3088\n",
      "14     290               0.2146             0.3038\n",
      "15     310               0.2199             0.3105\n",
      "16     330               0.2189             0.3107\n",
      "17     350               0.2241             0.3135\n",
      "18     370               0.2225             0.3151\n",
      "19     390               0.2280             0.3174\n",
      "20     410               0.2309             0.3227\n",
      "21     430               0.2322             0.3200\n",
      "22     450               0.2316             0.3224\n",
      "23     470               0.2271             0.3178\n",
      "24     490               0.2228             0.3164\n",
      "25     510               0.2296             0.3208\n",
      "26     530               0.2292             0.3220\n",
      "27     550               0.2330             0.3239\n",
      "28     570               0.2288             0.3194\n",
      "29     590               0.2353             0.3277\n"
     ]
    }
   ],
   "source": [
    "final.reset_index(inplace= True)\n",
    "final.rename(columns = {'index': 'Features'}, inplace = True)\n",
    "final.replace(regex=['Features'], value='', inplace=True)\n",
    "print(final)\n",
    "final.to_csv(\"E:/Machine Learning/Output Data/Error Rate on different feature sets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now when we have find out the best set of features, \n",
    "# we will save that set\n",
    "FS = SelectFeatures()\n",
    "for index, key in enumerate(full_data):\n",
    "    FS.CallFit(df = full_data[key],labels = labels[index], top_fea=150)\n",
    "    important_features = FS.UnivFeatureSelection(df = full_data[key], index = index)\n",
    "    \n",
    "# save the data, full data and import features together in a list\n",
    "dfs_final = [full_data['full_df_cross'], full_data['full_df_long'], \n",
    "             important_features[0], important_features[1]]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(210, 2728), (148, 5356), (210, 150), (148, 150)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.shape for s in dfs_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Output Data/Epic Final set of features (n=150).pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dfs_final, \"E:/Machine Learning/Output Data/Epic Final set of features (n=150).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 79)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cpgs in important cross-sectional\n",
    "dfs_final[2].loc[:, dfs_final[2].columns.str.contains('^cg')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
