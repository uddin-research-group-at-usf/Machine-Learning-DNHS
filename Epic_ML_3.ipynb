{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook has code to implement various machine learning approaches for Epic Methylation data on GRRN genes. It has 4 datasets, cross-sectional and longitudinal full and important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings imported from other notebook Settings.ipynb\n",
    "%run Settings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the data, data and the labels (outcome variable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_final = joblib.load(\"E:/Machine Learning/Output Data/Epic Final set of features (n=150).pkl\")\n",
    "labels = joblib.load(\"E:/Machine Learning/Output Data/Response Variable (PTSS Epic).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of different datasets :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(210, 2728), (148, 5356), (210, 150), (148, 150)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of different datasets :\")\n",
    "[dfs_final[i].shape for i in range(len(dfs_final))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split the data into training and testing and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahwani\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class TrainTest:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.data_scaled = []\n",
    "        self.scaler_trn_f = preprocessing.StandardScaler()\n",
    "        self.scaler_tst_f = preprocessing.StandardScaler()\n",
    "        self.scaler_trn_l = preprocessing.StandardScaler()\n",
    "        self.scaler_tst_l = preprocessing.StandardScaler()\n",
    "\n",
    "    def ScaleData(self, train_f, test_f, train_l, test_l):\n",
    "        \"\"\"\n",
    "        Function to scale the data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        train_f : Training features\n",
    "        test_f : Test features\n",
    "        train_l : Training labels\n",
    "        test_l : Test labels\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.scaler_trn_f.fit(train_f)\n",
    "        self.scaler_tst_f.fit(test_f)\n",
    "        self.scaler_trn_l.fit(train_l.reshape(-1,1))\n",
    "        self.scaler_tst_l.fit(test_l.reshape(-1,1))\n",
    "        \n",
    "        scal_trn_f = self.scaler_trn_f.transform(train_f)\n",
    "        scal_tst_f = self.scaler_tst_f.transform(test_f)\n",
    "        scal_trn_l = self.scaler_trn_l.transform(train_l.reshape(-1,1))\n",
    "        scal_tst_l = self.scaler_tst_l.transform(test_l.reshape(-1,1))\n",
    "\n",
    "        self.data.append([train_f, train_l, test_f, test_l])\n",
    "        self.data_scaled.append([scal_trn_f, scal_trn_l, scal_tst_f, scal_tst_l])\n",
    "        return [self.data, self.data_scaled]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# The following code splits the data sets with another single line:\n",
    "# split into traning and testing\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "# labels are for 3 prediction types\n",
    "\n",
    "# Initialize constructor\n",
    "Sdata = TrainTest()\n",
    "\n",
    "# split into train and test and store\n",
    "for i in range(len(dfs_final)):\n",
    "    print(i)\n",
    "    if i == 0 or i == 2:\n",
    "        j = 0 # labels\n",
    "    else:\n",
    "        j = 1\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(dfs_final[i],\n",
    "                                                                                labels[j], \n",
    "                                                                                test_size = 0.25, \n",
    "                                                                                random_state = 42)\n",
    "    \n",
    "    data, data_scaled = Sdata.ScaleData(train_features, test_features, train_labels, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without scaling..............\n",
      "(157, 2728)\n",
      "(157,)\n",
      "(53, 2728)\n",
      "(53,)\n",
      "(111, 5356)\n",
      "(111,)\n",
      "(37, 5356)\n",
      "(37,)\n",
      "(157, 150)\n",
      "(157,)\n",
      "(53, 150)\n",
      "(53,)\n",
      "(111, 150)\n",
      "(111,)\n",
      "(37, 150)\n",
      "(37,)\n",
      "With scaling..............\n",
      "(157, 2728)\n",
      "(157, 1)\n",
      "(53, 2728)\n",
      "(53, 1)\n",
      "(111, 5356)\n",
      "(111, 1)\n",
      "(37, 5356)\n",
      "(37, 1)\n",
      "(157, 150)\n",
      "(157, 1)\n",
      "(53, 150)\n",
      "(53, 1)\n",
      "(111, 150)\n",
      "(111, 1)\n",
      "(37, 150)\n",
      "(37, 1)\n"
     ]
    }
   ],
   "source": [
    "# We can look at the shape of all the data to make sure we did everything correctly. \n",
    "# We expect the training features number of columns to match the testing feature \n",
    "# number of columns and the number of rows to match for the respective training \n",
    "# and testing features and the labels :\n",
    "\n",
    "def CheckShape(df, name):\n",
    "        \"\"\"\n",
    "        Function to check the shape of the data\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        df: Data frame list\n",
    "        name: Name of the data to print message\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        print(name + \"..............\")\n",
    "        for i in range(len(df)):\n",
    "            for j in range(len(df[i])):\n",
    "                print(df[i][j].shape)\n",
    "\n",
    "    \n",
    "CheckShape(df = data, name=\"Without scaling\")\n",
    "CheckShape(df= data_scaled, name=\"With scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Output Data/Final/Epic_ML_without_scaling_Data.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scaled data\n",
    "import joblib\n",
    "joblib.dump(data_scaled, \"E:/Machine Learning/Output Data/Final/Epic_ML_Scaled_Data.pkl\")\n",
    "joblib.dump(data, \"E:/Machine Learning/Output Data/Final/Epic_ML_without_scaling_Data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# After all the work of data preparation, creating and training the model is pretty simple \n",
    "# using Scikit-learn. We import the random forest regression model from skicit-learn, \n",
    "# instantiate the model, and fit (scikit-learnâ€™s name for training) the model on the training data. \n",
    "# (Again setting the random state for reproducible results). \n",
    "# Import the model we are using\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_models(data_scaled, model_names, df_types, \n",
    "                 indx1, indx2):\n",
    "    \n",
    "    \"\"\"\n",
    "     Function to train the models(random forest, adaboost, gradient boost)\n",
    "     on cross-sectional and longitudinal full and important data\n",
    "        \n",
    "     Parameters:\n",
    "     ----------\n",
    "     data_scaled: List of data frames containing scaled data \n",
    "     model_names: Model names e.g, random forest etc\n",
    "     df_types: Data name e.g, full data\n",
    "     indx1 : Index of the data, e.g indx1 = 0 for training features\n",
    "     indx2 : Index of the labes, e.g indx1 = 1 for taining labels\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    store_models = []\n",
    "    for i in range(len(data_scaled)):\n",
    "        # default setting\n",
    "        rforest = RandomForestRegressor(random_state=42)\n",
    "        aboost = AdaBoostRegressor(random_state=42)\n",
    "        gboost = GradientBoostingRegressor(random_state=42)\n",
    "                \n",
    "        training_models = [rforest, aboost, gboost]\n",
    "        \n",
    "        # After scaling, labels change into column. We need to reshape into an array\n",
    "        scaled_trn_labels = data_scaled[i][indx2].ravel() \n",
    "        \n",
    "        # loop over models for each data set\n",
    "        for m in range(len(training_models)):\n",
    "            print(\"Training ...... \", model_names[m], \"on\", df_types[i])\n",
    "            %time training_models[m].fit(data_scaled[i][indx1], scaled_trn_labels) # train data and train features for each case\n",
    "            print(training_models[m])\n",
    "            store_models.append(training_models[m])\n",
    "            \n",
    "    return store_models\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  After training we will first check the accuracy on the training data. This will help us to find out if the model is overfitting the data. If the model performed well on the training data but didn't perform well on the test data, then the model is overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using training data, we will predict the labels of the training set\n",
    "# input: training set\n",
    "# output: training labels\n",
    "\n",
    "def make_predictions(data_scaled, model_names, df_types, indx, \n",
    "                    trained_models):\n",
    "    \"\"\"\n",
    "    Function to evaluate the models\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data_scaled: List of data frames containing scaled data \n",
    "    model_names: Model names e.g, random forest etc\n",
    "    df_types: Data name e.g, full data\n",
    "    indx : Index of the data, e.g indx = 0 for training features\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = {}\n",
    "    m = 0 # models \n",
    "    for i in range(len(data_scaled)):\n",
    "        for j in range(len(model_names)):\n",
    "            key = model_names[j]+\"_\"+df_types[i]\n",
    "            predictions[key] = trained_models[m].predict(data_scaled[i][indx])\n",
    "            m = m+1\n",
    "    return predictions\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the error rate on the training set\n",
    "# input: training labels and predicted labels on the training set\n",
    "# output: error rate\n",
    "# df_indx will be 1 for training and 3 for testing\n",
    "from sklearn import metrics\n",
    " \n",
    "def evaluate_model(data_scaled, preds, df_indx, df_types, \n",
    "                   model_name, store ):\n",
    "    for i in range(len(data_scaled)):\n",
    "        print(\"\\nModel : ........ \", model_name)\n",
    "        print(\"\\n\", df_types[i], \": \")\n",
    "        abe = metrics.mean_absolute_error(data_scaled[i][df_indx], preds[i])\n",
    "        mse = metrics.mean_squared_error(data_scaled[i][df_indx], preds[i])\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(data_scaled[i][df_indx], preds[i]))\n",
    "        r2 = metrics.r2_score(data_scaled[i][df_indx], preds[i])\n",
    "        print('Mean Absolute Error:', abe)\n",
    "        print('Mean Squared Error:', mse)\n",
    "        print('Root Mean Squared Error:', rmse) \n",
    "        print(\"R2 on data:\", r2)\n",
    "        key = model_name+ '_' +df_types[i] \n",
    "        store[key] = [abe, mse, rmse, r2]\n",
    "\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ......  Random Forest on full_cros\n",
      "Wall time: 9.66 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_cros\n",
      "Wall time: 3.66 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_cros\n",
      "Wall time: 8.2 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on full_long\n",
      "Wall time: 11.8 s\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on full_long\n",
      "Wall time: 5.09 s\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on full_long\n",
      "Wall time: 11 s\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_cros\n",
      "Wall time: 558 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_cros\n",
      "Wall time: 202 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_cros\n",
      "Wall time: 363 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Training ......  Random Forest on imp_long\n",
      "Wall time: 424 ms\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Training ......  Adaboost on imp_long\n",
      "Wall time: 151 ms\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=42)\n",
      "Training ......  Gradient Boost on imp_long\n",
      "Wall time: 272 ms\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "[array([ 0.02567745, -1.02531384, -0.96020275,  0.59632088, -0.86622165,\n",
      "       -0.44422807, -0.33611909, -1.48170573,  1.41143803, -1.35578334,\n",
      "       -0.6567605 ,  0.59202109, -0.76425522,  0.28673607,  1.69215282,\n",
      "       -1.32077077, -0.0676894 , -0.72555712, -0.57322174, -0.794968  ,\n",
      "        0.50541105, -1.55480215,  0.52322446, -0.50135384, -0.43255721,\n",
      "        0.07236087,  0.9624172 , -0.60700579, -1.29312927, -1.06401194,\n",
      "        0.01400659,  0.55823703, -1.20344796, -1.01671426, -0.74398479,\n",
      "        0.29902118,  0.58833555,  0.47776955, -0.89877719,  0.15282835,\n",
      "        2.19461388,  0.12887238,  1.05394128, -1.35271206, -0.89079187,\n",
      "       -0.61376261, -0.72739989, -0.5916494 ,  2.13810237,  0.4992685 ,\n",
      "       -0.75934118, -0.90737677,  0.30639225,  0.168799  , -0.40798699,\n",
      "       -0.61499112,  0.50233977, -1.32752758, -0.25749437, -1.35455483,\n",
      "        0.16142793, -0.22309606,  0.37518887,  0.82052416, -1.49399084,\n",
      "        0.06744683,  0.30639225, -0.40737273,  0.12395834, -0.2169535 ,\n",
      "       -0.41412954, -0.0345196 , -0.32506249, -0.5916494 , -0.67580242,\n",
      "        1.86967268,  1.82790331,  1.48084891,  0.01154957, -0.44668509,\n",
      "       -1.08796791,  0.54472341, -0.47739787, -1.59165748, -0.14324284,\n",
      "        1.49743381,  1.99559508,  0.87273589,  0.43907145,  0.51093935,\n",
      "       -0.86806441,  0.48329785, -0.60700579,  0.15282835,  1.87397247,\n",
      "        0.03427703,  0.59570662, -0.75872692, -0.59963473, -1.41659464,\n",
      "       -0.40552997,  0.49558296,  2.13380258,  0.58649279, -0.72494286,\n",
      "        2.06623447,  0.03673405,  0.24680946,  0.5379666 , -0.86376462,\n",
      "        0.10491642, -0.49336851, -0.63833283,  0.52936702, -0.02960555,\n",
      "        1.18723474, -1.19239136, -0.09041686, -0.83243759, -1.58182939,\n",
      "        0.91634803,  2.12397449,  1.69583836, -1.23784627,  1.95751123,\n",
      "       -0.37481719,  0.1411575 , -0.07014642,  1.73023667,  1.94768314,\n",
      "        1.1823207 ,  1.39546738, -0.64816092, -0.56216514, -0.59717771,\n",
      "       -0.32260546,  1.50787615, -0.11682985,  0.15282835, -0.02960555,\n",
      "       -0.61376261,  1.88134354,  1.43170846,  0.113516  , -0.40307294,\n",
      "       -1.20160519, -0.05540429,  0.4937402 , -1.01548575, -0.01977746,\n",
      "        0.04901916,  0.54226639, -0.43992828, -1.4669636 , -0.36744612,\n",
      "        0.91389101, -0.03267683]), array([ 0.33380946, -0.09273437,  1.58091313, -1.3981426 ,  0.89660181,\n",
      "       -0.46711097,  0.3117151 , -0.64509328,  1.8362257 ,  0.60692025,\n",
      "        1.00461867, -0.654913  ,  1.87980068,  0.01160009, -0.37382368,\n",
      "       -0.38487086, -1.00780897, -0.53032538, -0.81325589, -0.77643196,\n",
      "        0.23929471, -0.39407684, -0.63220491,  0.86346028, -0.62422639,\n",
      "       -1.27600991,  0.17730776,  0.52406641,  0.57009632, -0.3989867 ,\n",
      "       -0.77581823,  0.89476062,  2.11179142, -0.43949302, -0.62974998,\n",
      "        1.80247043, -0.21854946,  1.36794809, -0.05468298, -0.586175  ,\n",
      "        0.35099396,  0.55291182, -0.89242733,  1.74171095, -0.74513162,\n",
      "       -0.35172933, -1.11091597,  0.47619531, -0.05591044,  1.46553149,\n",
      "        0.60078293, -0.84394249,  1.41950158, -0.96484772, -1.47056299,\n",
      "       -0.1105326 , -0.56039825,  0.19265107,  0.01037263,  1.95958585,\n",
      "        0.54125091, -0.30569942, -1.3809581 , -0.49657011, -1.34720283,\n",
      "       -0.5327803 , -1.30424159,  1.94792494,  0.25156935, -0.74820028,\n",
      "       -1.02683467,  0.58052977,  0.6689072 , -0.08721078,  2.00745696,\n",
      "        1.65824338, -0.58494754, -0.66350525,  0.84566205,  0.12329934,\n",
      "        0.86530148, -1.33983805, -0.48613666, -0.15410758,  0.54370584,\n",
      "       -1.05690754, -1.3312458 , -0.49166025, -0.54812361, -0.42108106,\n",
      "       -0.71260382,  1.53181456,  0.56702766, -0.34129588,  1.24949779,\n",
      "        0.34915276, -0.24248501, -0.9605516 , -0.12096605, -0.67762109,\n",
      "        1.20101295, -0.06450269,  0.18528628,  0.60569279, -0.99062447,\n",
      "        1.50787901,  0.4626932 , -1.34720283, -0.60949682, -1.49818094,\n",
      "       -0.28421879]), array([ 0.09447407, -1.0038149 , -1.02285682,  0.60000641, -0.97064509,\n",
      "       -0.46511276, -0.19975435, -1.52408937,  1.40038143, -1.39018165,\n",
      "       -0.70467243,  0.59202109, -0.7286284 ,  0.29349288,  1.56930171,\n",
      "       -1.35271206,  0.00233574, -0.63034751, -0.61007707, -0.81216716,\n",
      "        0.47654104, -1.57445833,  0.5434949 , -0.47371233, -0.43501423,\n",
      "        0.11535876,  0.97224529, -0.61314835, -1.28268693, -1.1143809 ,\n",
      "        0.05024767,  0.54718043, -1.20037668, -1.00074362, -0.67764519,\n",
      "        0.29103586,  0.59939216,  0.47469827, -0.81585269,  0.19275496,\n",
      "        2.2566537 ,  0.11781578,  1.09878194, -1.35148355, -0.83980866,\n",
      "       -0.61437686, -0.80909588, -0.61069133,  2.2124273 ,  0.48329785,\n",
      "       -0.80663886, -0.99337255,  0.28857883,  0.14238601, -0.50135384,\n",
      "       -0.69852987,  0.48206934, -1.36376866, -0.25872288, -1.31524247,\n",
      "        0.20504008, -0.20466839,  0.38071717,  0.82543821, -1.53821725,\n",
      "        0.06253278,  0.30946352, -0.42088636,  0.13992898, -0.25749437,\n",
      "       -0.41904359, -0.07383196, -0.26916523, -0.59472068, -0.7175718 ,\n",
      "        1.90038546,  1.74866434,  1.45136464,  0.00786404, -0.5087249 ,\n",
      "       -1.17212092,  0.55393724, -0.48354042, -1.62237026, -0.0676894 ,\n",
      "        1.4587357 ,  2.03429318,  0.8905493 ,  0.44521401,  0.48391211,\n",
      "       -0.90430549,  0.49251169, -0.62481921,  0.15897091,  1.89792844,\n",
      "        0.10737344,  0.61044876, -0.76671224, -0.6567605 , -1.42396571,\n",
      "       -0.38218825,  0.47776955,  2.21549857,  0.5932496 , -0.7231001 ,\n",
      "        2.15653004,  0.05639023,  0.25786606,  0.54226639, -0.89632017,\n",
      "        0.11474451, -0.51363895, -0.58304983,  0.54840894, -0.06584663,\n",
      "        1.17433537, -1.19484838, -0.05417578, -0.81646695, -1.64264069,\n",
      "        0.90283441,  2.18048601,  1.62458471, -1.17887773,  1.98330997,\n",
      "       -0.37911698,  0.10307365, -0.03943364,  1.72532262,  1.96733932,\n",
      "        1.18109218,  1.35738353, -0.67088837, -0.56523642, -0.64140411,\n",
      "       -0.34533292,  1.50603338, -0.05233301,  0.18415539,  0.00663553,\n",
      "       -0.63034751,  1.91021355,  1.39915291,  0.1411575 , -0.41658657,\n",
      "       -1.16474986,  0.00356425,  0.48636913, -1.05418385,  0.0041785 ,\n",
      "        0.04410512,  0.5490232 , -0.44299956, -1.49214808, -0.36621761,\n",
      "        0.95013209, -0.00994938]), array([ 0.32521721, -0.0589791 ,  1.59502897, -1.47301792,  0.91869617,\n",
      "       -0.43949302,  0.32951333, -0.64938941,  1.87673202,  0.6689072 ,\n",
      "        1.08379011, -0.7389943 ,  1.851569  ,  0.08708914, -0.45729125,\n",
      "       -0.40144163, -1.09189027, -0.6052007 , -0.82246187, -0.7905478 ,\n",
      "        0.15214475, -0.46342857, -0.66596018,  0.87941731, -0.62790878,\n",
      "       -1.31835742,  0.16135073,  0.49644847,  0.54738824, -0.38241593,\n",
      "       -0.72733339,  0.93465321,  2.18421181, -0.46649724, -0.60826936,\n",
      "        1.80983522, -0.1946139 ,  1.36794809, -0.02154144, -0.59047112,\n",
      "        0.32767213,  0.55352556, -0.91145303,  1.68954372, -0.71935487,\n",
      "       -0.32779378, -1.0961864 ,  0.41236717, -0.00619814,  1.41090933,\n",
      "        0.58850829, -0.90101958,  1.43238996, -1.06979591, -1.55218936,\n",
      "       -0.05591044, -0.55732959,  0.22517887,  0.00914516,  2.02034533,\n",
      "        0.48662875, -0.28299133, -1.38525423, -0.45422259, -1.36684226,\n",
      "       -0.586175  , -1.34536164,  1.98106648,  0.20553944, -0.78625167,\n",
      "       -1.09557266,  0.55720795,  0.70082127, -0.07248121,  2.08233228,\n",
      "        1.60914481, -0.67823482, -0.73776683,  0.8677564 ,  0.13005039,\n",
      "        0.91746871, -1.33492819, -0.46342857, -0.06818509,  0.52836254,\n",
      "       -1.10232372, -1.32449475, -0.57758275, -0.58126514, -0.43703809,\n",
      "       -0.66227778,  1.51708499,  0.51179177, -0.3149054 ,  1.21696998,\n",
      "        0.34485663, -0.21118467, -0.96853011, -0.07861853, -0.75372387,\n",
      "        1.19426189, -0.06388896,  0.2257926 ,  0.61796743, -1.09986879,\n",
      "        1.45693924,  0.3804531 , -1.32817714, -0.64693448, -1.54482458,\n",
      "       -0.32349765])]\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.09287387796945532\n",
      "Mean Squared Error: 0.018924610666195562\n",
      "Root Mean Squared Error: 0.13756674985691697\n",
      "R2 on data: 0.9810753893338044\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.10747500039799918\n",
      "Mean Squared Error: 0.02186663263078799\n",
      "Root Mean Squared Error: 0.14787370500122052\n",
      "R2 on data: 0.978133367369212\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros : \n",
      "Mean Absolute Error: 0.08250586985507934\n",
      "Mean Squared Error: 0.016304296670384275\n",
      "Root Mean Squared Error: 0.1276882792991756\n",
      "R2 on data: 0.9836957033296158\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long : \n",
      "Mean Absolute Error: 0.09203770226489837\n",
      "Mean Squared Error: 0.0183107524843644\n",
      "Root Mean Squared Error: 0.13531722907436583\n",
      "R2 on data: 0.9816892475156356\n",
      "[array([ 7.34923952e-02, -1.10013602e+00, -1.08237693e+00,  4.60365643e-01,\n",
      "       -7.93739489e-01, -4.02953759e-01, -1.03205455e-01, -1.27333134e+00,\n",
      "        1.40904925e+00, -1.21604020e+00, -6.45294392e-01,  4.60365643e-01,\n",
      "       -6.56214491e-01,  3.98940086e-01,  1.45682469e+00, -1.21604020e+00,\n",
      "        1.55994131e-01, -6.61290631e-01, -6.40175595e-01, -6.61290631e-01,\n",
      "        3.84314953e-01, -1.27333134e+00,  4.51151810e-01, -3.39966621e-01,\n",
      "       -2.95218654e-01,  1.26327612e-01,  9.78387845e-01, -4.86611702e-01,\n",
      "       -1.21604020e+00, -1.08237693e+00,  5.70044823e-02,  4.60365643e-01,\n",
      "       -1.15094246e+00, -1.00685621e+00, -6.45294392e-01,  3.84314953e-01,\n",
      "        4.60365643e-01,  4.51151810e-01, -7.87833186e-01,  1.53969112e-01,\n",
      "        2.16390110e+00,  5.66567905e-02,  1.01949572e+00, -1.27508287e+00,\n",
      "       -1.02159510e+00, -5.50596657e-01, -7.07924372e-01, -5.75678760e-01,\n",
      "        2.11300564e+00,  4.99268496e-01, -6.29369247e-01, -7.87833186e-01,\n",
      "        3.54150617e-01,  3.70846226e-01, -4.86611702e-01, -5.50596657e-01,\n",
      "        4.51151810e-01, -1.27333134e+00, -2.91828026e-01, -1.25408992e+00,\n",
      "        3.54150617e-01, -1.99227843e-01,  3.40439555e-01,  6.95830280e-01,\n",
      "       -1.25408992e+00, -7.19891884e-02,  3.70846226e-01, -4.07392233e-01,\n",
      "        2.81207767e-01, -2.18465518e-01, -3.39966621e-01,  1.03471972e-02,\n",
      "       -1.02701967e-01, -5.12650797e-01, -5.29268339e-01,  1.88339106e+00,\n",
      "        1.61282610e+00,  1.45136464e+00,  5.70044823e-02, -3.39966621e-01,\n",
      "       -1.20221945e+00,  4.51151810e-01, -4.02953759e-01, -1.31676004e+00,\n",
      "       -8.64422608e-02,  1.51739711e+00,  1.97041060e+00,  9.10819732e-01,\n",
      "        3.89384999e-01,  4.51151810e-01, -7.87833186e-01,  4.02216116e-01,\n",
      "       -4.26992778e-01,  5.70044823e-02,  1.83220309e+00,  4.73518947e-02,\n",
      "        6.88742716e-01, -6.61290631e-01, -6.60185436e-01, -1.28514395e+00,\n",
      "       -3.97317141e-01,  4.42449856e-01,  2.12397449e+00,  4.51151810e-01,\n",
      "       -6.60185436e-01,  2.07790532e+00,  1.55994131e-01,  3.40439555e-01,\n",
      "        3.98940086e-01, -7.41527765e-01,  3.70846226e-01, -3.85471344e-01,\n",
      "       -5.75678760e-01,  4.78793311e-01,  1.55994131e-01,  1.14423685e+00,\n",
      "       -1.15034898e+00, -8.64422608e-02, -7.03794923e-01, -1.26978756e+00,\n",
      "        9.02044652e-01,  2.05060508e+00,  1.56602568e+00, -1.10086728e+00,\n",
      "        2.06766773e+00, -2.95266215e-01,  1.98283265e-01,  1.03471972e-02,\n",
      "        1.59673846e+00,  1.88339106e+00,  1.05257102e+00,  1.40904925e+00,\n",
      "       -5.96531120e-01, -5.73631241e-01, -5.77568777e-01, -3.62515474e-01,\n",
      "        1.44131318e+00, -1.69547427e-01,  3.40439555e-01, -1.85626470e-01,\n",
      "       -7.25430033e-01,  1.95505421e+00,  1.45136464e+00,  2.96564157e-01,\n",
      "        1.82488121e-01, -1.10086728e+00, -2.18465518e-01,  4.42449856e-01,\n",
      "       -1.02159510e+00,  1.03471972e-02,  1.92970282e-03,  4.99268496e-01,\n",
      "       -2.95266215e-01, -1.26324221e+00, -3.39966621e-01,  1.04595596e+00,\n",
      "        8.34360859e-02]), array([ 0.26263312, -0.26130613,  1.52806398, -1.31397566,  0.97530393,\n",
      "       -0.40178259,  0.40167069, -0.57810881,  1.85197816,  0.74819023,\n",
      "        1.08072145, -0.61317921,  2.00833372, -0.0345175 , -0.00456152,\n",
      "       -0.28176387, -1.22998   , -0.53204175, -0.96371468, -0.65000314,\n",
      "        0.37561143, -0.5255032 , -0.54829896,  0.99567571, -0.53204175,\n",
      "       -1.25287693,  0.26263312,  0.50469001,  0.48130974, -0.37535801,\n",
      "       -0.66970717,  0.97530393,  2.15884422, -0.51275032, -0.54829896,\n",
      "        1.79060494,  0.21194953,  1.36303823, -0.22959664, -0.53204175,\n",
      "        0.41128133,  0.52563484, -0.81264215,  1.6743678 , -0.63363695,\n",
      "       -0.45899773, -1.21209711,  0.4455087 , -0.00456152,  1.35076359,\n",
      "        0.48130974, -0.87003747,  1.36020562, -1.22998   , -1.32920003,\n",
      "       -0.0345175 , -0.52572239,  0.36879219,  0.13746239,  2.02586892,\n",
      "        0.48130974, -0.28001035, -1.30733141, -0.40178259, -1.32510848,\n",
      "       -0.53204175, -1.25480825,  2.08724214,  0.52222522, -0.66534644,\n",
      "       -1.18688533,  0.65110896,  0.73703146,  0.05510688,  2.05655553,\n",
      "        1.62694304, -0.5255032 , -0.61829365,  0.96206657,  0.18255623,\n",
      "        0.97530393, -1.25480825, -0.35891876, -0.12602934,  0.50469001,\n",
      "       -1.19047099, -1.3159025 , -0.5255032 , -0.66534644, -0.30073377,\n",
      "       -0.53204175,  1.52372446,  0.46523581, -0.45899773,  1.14209466,\n",
      "        0.40167069, -0.30073377, -0.81264215, -0.12901276, -0.61999846,\n",
      "        1.18469489, -0.00590743,  0.36879219,  0.5276405 , -1.16367833,\n",
      "        1.4121368 ,  0.40386259, -1.31458736, -0.59783591, -1.3159025 ,\n",
      "       -0.44951731]), array([ 0.19448933, -0.92755945, -0.92755945,  0.37050233, -0.70240938,\n",
      "       -0.48126285, -0.21190296, -1.37728229,  1.48119991, -1.20982452,\n",
      "       -0.57228419,  0.45091556, -0.57718306,  0.31047183,  1.52507531,\n",
      "       -1.15351775,  0.0365293 , -0.60977621, -0.57718306, -0.60345379,\n",
      "        0.53842729, -1.40659903,  0.36822731, -0.38990795, -0.4718821 ,\n",
      "        0.12478082,  0.97907035, -0.57902924, -1.09879209, -0.94423211,\n",
      "        0.10506095,  0.38723998, -1.00439765, -0.73807258, -0.57718306,\n",
      "        0.18512065,  0.40186511,  0.46036564, -0.62765423,  0.18108411,\n",
      "        2.13165269,  0.07816217,  1.02343325, -1.22339166, -0.9224482 ,\n",
      "       -0.60345379, -0.57228419, -0.4718821 ,  2.0642552 ,  0.44398549,\n",
      "       -0.57718306, -0.73181856,  0.2020633 ,  0.2020633 , -0.48850496,\n",
      "       -0.57228419,  0.36822731, -1.22218275, -0.31277737, -1.20982452,\n",
      "        0.25970882, -0.31277737,  0.2351386 ,  0.582193  , -1.35003708,\n",
      "        0.19448933,  0.37050233, -0.4718821 ,  0.28632656, -0.08563931,\n",
      "       -0.4718821 , -0.05582457, -0.24705203, -0.48376793, -0.54449348,\n",
      "        1.88339106,  1.78306265,  1.4145093 ,  0.01969075, -0.46140404,\n",
      "       -1.09879209,  0.54226639, -0.45138234, -1.43486875,  0.04155502,\n",
      "        1.3868678 ,  2.02876488,  0.90204465,  0.45091556,  0.46036564,\n",
      "       -0.68324839,  0.38723998, -0.48850496,  0.19418823,  1.88339106,\n",
      "       -0.06931851,  0.61137014, -0.57902924, -0.49124299, -1.2134808 ,\n",
      "       -0.38990795,  0.37078671,  2.06035517,  0.46036564, -0.57902924,\n",
      "        1.9704106 ,  0.07816217,  0.37078671,  0.35389468, -0.68324839,\n",
      "        0.25970882, -0.37229191, -0.57718306,  0.43989046, -0.05337538,\n",
      "        1.18382221, -0.98268985,  0.01969075, -0.60345379, -1.37728229,\n",
      "        0.98862544,  2.02876488,  1.55578809, -0.94021582,  2.00624217,\n",
      "       -0.49124299,  0.18512065,  0.04552057,  1.63915134,  1.93457902,\n",
      "        1.03750994,  1.4145093 , -0.48850496, -0.38990795, -0.49124299,\n",
      "       -0.37911698,  1.48040217, -0.00637552,  0.28632656,  0.04155502,\n",
      "       -0.62481921,  1.91410384,  1.47593486,  0.29246912, -0.05582457,\n",
      "       -0.94297209,  0.00618879,  0.37050233, -0.9224482 ,  0.09122729,\n",
      "        0.0892529 ,  0.38723998, -0.37911698, -1.15351775, -0.24524076,\n",
      "        0.97907035,  0.12478082]), array([ 0.19550312,  0.02300653,  1.55789818, -1.27770296,  0.84224268,\n",
      "       -0.43928844,  0.44411386, -0.58362915,  1.77423875,  0.67224863,\n",
      "        1.05266513, -0.58362915,  1.93994643,  0.13864264, -0.17655264,\n",
      "       -0.43928844, -0.99062447, -0.59844964, -0.70629719, -0.7198517 ,\n",
      "        0.30741897, -0.58362915, -0.60963845,  0.90069336, -0.58143445,\n",
      "       -1.23537661,  0.27437186,  0.40970766,  0.4301654 , -0.42053552,\n",
      "       -0.71137635,  0.96615812,  2.16395865, -0.54596093, -0.58999378,\n",
      "        1.71900286,  0.12329934,  1.41895604, -0.13810509, -0.58862993,\n",
      "        0.38106683,  0.52733965, -0.89331823,  1.59625644, -0.62942506,\n",
      "       -0.20684622, -1.00801355,  0.40970766,  0.06874537,  1.33030585,\n",
      "        0.47108087, -0.77274957,  1.26484109, -0.95910096, -1.34746586,\n",
      "        0.02685572, -0.55030909,  0.28111617,  0.12652951,  2.06269285,\n",
      "        0.4301654 , -0.29515438, -1.26288874, -0.50407128, -1.2951038 ,\n",
      "       -0.58362915, -1.16846066,  1.97983901,  0.4551693 , -0.62942506,\n",
      "       -0.99062447,  0.5467745 ,  0.67224863, -0.03497895,  2.10769987,\n",
      "        1.58748883, -0.62942506, -0.60963845,  0.87205253,  0.12329934,\n",
      "        0.87512119, -1.24736908, -0.60167174,  0.01171168,  0.52733965,\n",
      "       -0.95910096, -1.29095295, -0.64693448, -0.62942506, -0.42053552,\n",
      "       -0.58143445,  1.52806398,  0.51529598, -0.43928844,  1.16664395,\n",
      "        0.21011998, -0.40056487, -0.90930496, -0.0608203 , -0.60963845,\n",
      "        1.16664395,  0.03291333,  0.37390662,  0.52733965, -0.99062447,\n",
      "        1.53488322,  0.36495636, -1.22471944, -0.71291068, -1.34493675,\n",
      "       -0.35891876])]\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.14130647737637705\n",
      "Mean Squared Error: 0.028575112966433443\n",
      "Root Mean Squared Error: 0.16904174918177298\n",
      "R2 on data: 0.9714248870335666\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.12082101422819123\n",
      "Mean Squared Error: 0.022803199348950216\n",
      "Root Mean Squared Error: 0.15100728243680903\n",
      "R2 on data: 0.9771968006510497\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros : \n",
      "Mean Absolute Error: 0.16609669048852557\n",
      "Mean Squared Error: 0.03935468895074425\n",
      "Root Mean Squared Error: 0.1983801626946209\n",
      "R2 on data: 0.9606453110492558\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long : \n",
      "Mean Absolute Error: 0.13030937942864443\n",
      "Mean Squared Error: 0.025383389395613593\n",
      "Root Mean Squared Error: 0.159321653881742\n",
      "R2 on data: 0.9746166106043864\n",
      "[array([ 0.04876647, -1.17142643, -1.17348558,  0.60038803, -1.04997112,\n",
      "       -0.55709622,  0.0412113 , -1.66004429,  1.34582131, -1.42563997,\n",
      "       -0.74415907,  0.60406232, -0.80692857,  0.29899994,  1.57953686,\n",
      "       -1.41823152,  0.28988279, -0.75396197, -0.50602234, -0.87291219,\n",
      "        0.48078642, -1.72449222,  0.5391075 , -0.55371355, -0.50054867,\n",
      "        0.35143208,  0.96709296, -0.68838698, -1.24132196, -1.17412852,\n",
      "        0.10358267,  0.54508433, -1.23917435, -1.11928886, -0.8701945 ,\n",
      "        0.29971362,  0.60137763,  0.47896407, -1.04895026,  0.28723671,\n",
      "        2.37823493,  0.17109146,  1.21223526, -1.4782547 , -1.11250871,\n",
      "       -0.68521656, -0.92891529, -0.74302787,  2.25895117,  0.47887201,\n",
      "       -0.86477691, -1.04819231,  0.29180397,  0.11289124, -0.38392039,\n",
      "       -0.74738511,  0.47649432, -1.36184236, -0.31156304, -1.35801167,\n",
      "        0.17179478, -0.30355113,  0.59434685,  0.72390903, -1.60037287,\n",
      "        0.04995093,  0.35881344, -0.43996095,  0.11698478, -0.26008638,\n",
      "       -0.50366218,  0.22755226,  0.04768403, -0.68263758, -0.74679814,\n",
      "        1.88936903,  1.77234931,  1.3979598 , -0.0057314 , -0.56052807,\n",
      "       -0.99772419,  0.54350191, -0.61575444, -1.72529969, -0.18744402,\n",
      "        1.4020223 ,  2.0753352 ,  0.8555694 ,  0.41892383,  0.48380043,\n",
      "       -0.98346794,  0.48244291, -0.63013418,  0.29287894,  1.89266853,\n",
      "        0.22924628,  0.96498387, -0.86427958, -0.74609464, -1.47796149,\n",
      "       -0.43965361,  0.48263405,  2.25851569,  0.60067998, -0.80628231,\n",
      "        2.19878404,  0.35267107,  0.77430851,  0.5417921 , -0.9893198 ,\n",
      "        0.1154062 , -0.61702231, -0.68921188,  0.54135121,  0.2890906 ,\n",
      "        1.15779586, -1.23367589, -0.06747879, -0.92675316, -1.72370816,\n",
      "        0.85292797,  2.195293  ,  1.70272568, -1.23954144,  2.07761684,\n",
      "       -0.26095288,  0.11136795, -0.06699994,  1.70852411,  1.95368266,\n",
      "        1.1542264 ,  1.27852773, -0.69212991, -0.68992873, -0.62761718,\n",
      "       -0.38488435,  1.52649572, -0.13222727,  0.11659606, -0.01712793,\n",
      "       -0.44830135,  1.9504483 ,  1.34063571,  0.11900638,  0.28661081,\n",
      "       -1.23481294, -0.01541879,  0.53985033, -1.17389974, -0.00978235,\n",
      "        0.10681508,  0.53617923, -0.49724989, -1.60114135, -0.37754537,\n",
      "        0.97392222, -0.0623404 ]), array([ 3.07625644e-01, -6.30537659e-02,  1.59720041e+00, -1.59325734e+00,\n",
      "        8.59387481e-01, -4.89549321e-01,  6.11359121e-01, -7.37971754e-01,\n",
      "        1.90148417e+00,  9.77068134e-01,  1.22551546e+00, -8.55300390e-01,\n",
      "        1.96280324e+00,  1.82242285e-01,  5.88829090e-02, -4.27915524e-01,\n",
      "       -1.22694013e+00, -6.13161495e-01, -9.79841589e-01, -8.60436014e-01,\n",
      "        1.26838728e-01, -2.47832132e-01, -7.34871161e-01,  9.20545913e-01,\n",
      "       -6.74385336e-01, -1.34948059e+00,  1.24640284e-01,  4.91336314e-01,\n",
      "        5.51547824e-01, -4.30601034e-01, -9.15398053e-01,  9.82623366e-01,\n",
      "        2.39253670e+00, -3.72533281e-01, -6.75272027e-01,  1.77992084e+00,\n",
      "        3.02832739e-01,  1.28819161e+00,  2.00602529e-03, -6.75805009e-01,\n",
      "        3.08219481e-01,  5.52666592e-01, -1.03991318e+00,  1.71776335e+00,\n",
      "       -7.99653165e-01, -3.68032749e-01, -1.22417134e+00,  4.30055232e-01,\n",
      "        1.39416012e-03,  1.35016964e+00,  6.13375530e-01, -1.10310006e+00,\n",
      "        1.34863136e+00, -1.16459051e+00, -1.71390955e+00, -6.25235335e-02,\n",
      "       -6.71740599e-01,  1.24676755e-01,  2.42620502e-01,  2.08640381e+00,\n",
      "        4.92790918e-01, -3.03614046e-01, -1.41129020e+00, -5.53427705e-01,\n",
      "       -1.47090250e+00, -6.74387233e-01, -1.35126606e+00,  2.08446369e+00,\n",
      "        7.96490990e-01, -9.18055684e-01, -1.16312935e+00,  4.94103053e-01,\n",
      "        7.35779882e-01, -5.84875774e-02,  2.20948831e+00,  1.71598743e+00,\n",
      "       -7.32568940e-01, -7.96617419e-01,  8.59663601e-01,  3.06523545e-01,\n",
      "        9.82386755e-01, -1.35008721e+00, -6.08922153e-01, -1.82418554e-01,\n",
      "        4.91750892e-01, -1.22613168e+00, -1.47154224e+00, -4.90831329e-01,\n",
      "       -4.33167011e-01, -4.29604954e-01, -7.32073349e-01,  1.53533919e+00,\n",
      "        5.52547885e-01, -3.67130807e-01,  1.16747804e+00,  3.08141446e-01,\n",
      "       -6.34086362e-02, -1.10221922e+00, -1.20840739e-01, -8.56019202e-01,\n",
      "        1.16442677e+00,  2.42805296e-01,  1.86169027e-01,  6.16157289e-01,\n",
      "       -1.16430933e+00,  1.41386926e+00,  3.68778774e-01, -1.40709728e+00,\n",
      "       -7.34700086e-01, -1.65513178e+00, -2.47084726e-01]), array([ 0.02723643, -1.16427995, -1.14166295,  0.58240937, -1.04664648,\n",
      "       -0.54500568,  0.00634914, -1.62173467,  1.33555157, -1.45223526,\n",
      "       -0.75002727,  0.61795512, -0.79953339,  0.28883131,  1.56473138,\n",
      "       -1.42208413,  0.27614592, -0.77294361, -0.50747615, -0.86946902,\n",
      "        0.46791389, -1.7228306 ,  0.5303958 , -0.55651658, -0.51803584,\n",
      "        0.31916415,  0.96458387, -0.67652636, -1.23410189, -1.17814287,\n",
      "        0.09905395,  0.5439731 , -1.19601572, -1.10366041, -0.84717355,\n",
      "        0.29745492,  0.60473374,  0.46709689, -1.02486211,  0.25402861,\n",
      "        2.36857807,  0.14556465,  1.19445874, -1.45998219, -1.08035832,\n",
      "       -0.70410762, -0.8827868 , -0.74451339,  2.23273802,  0.47755577,\n",
      "       -0.85315857, -1.04726768,  0.31296624,  0.13103813, -0.41100886,\n",
      "       -0.75998361,  0.47321088, -1.36998793, -0.27787656, -1.34832343,\n",
      "        0.17912877, -0.29896125,  0.56063057,  0.71629262, -1.59463697,\n",
      "        0.05078382,  0.33928895, -0.44393066,  0.13120045, -0.27032293,\n",
      "       -0.54438037,  0.19164856,  0.01741314, -0.65533238, -0.75811795,\n",
      "        1.87092553,  1.77860522,  1.42031609, -0.03867211, -0.54139588,\n",
      "       -1.03324499,  0.53822829, -0.59617682, -1.72301096, -0.16734596,\n",
      "        1.41494681,  2.07217191,  0.86099419,  0.45161596,  0.48359255,\n",
      "       -0.95329912,  0.49067603, -0.64250315,  0.25243781,  1.8784448 ,\n",
      "        0.20907924,  0.95883541, -0.84644573, -0.72741876, -1.47585496,\n",
      "       -0.43604882,  0.48830542,  2.25893069,  0.60395382, -0.80416163,\n",
      "        2.1707994 ,  0.32685852,  0.74791355,  0.55022202, -0.9849523 ,\n",
      "        0.13133457, -0.5802854 , -0.68903152,  0.54022745,  0.256636  ,\n",
      "        1.18025195, -1.20998098, -0.07342972, -0.90390974, -1.70252229,\n",
      "        0.86684324,  2.203364  ,  1.69807388, -1.21188011,  2.05379826,\n",
      "       -0.30079567,  0.10076121, -0.00358552,  1.7186892 ,  1.96186249,\n",
      "        1.13882421,  1.27651043, -0.70531807, -0.66092777, -0.64551433,\n",
      "       -0.40874622,  1.52203996, -0.11658302,  0.13806145, -0.01581059,\n",
      "       -0.4708703 ,  1.94731215,  1.34642284,  0.14264598,  0.25377261,\n",
      "       -1.23354369,  0.00312522,  0.51989154, -1.16328219,  0.01716012,\n",
      "        0.09758329,  0.53925833, -0.49493051, -1.58967954, -0.40152164,\n",
      "        0.97431632, -0.01804451]), array([ 2.84637407e-01, -5.62531200e-02,  1.60619445e+00, -1.57115360e+00,\n",
      "        8.77814581e-01, -4.85664476e-01,  5.83329540e-01, -7.27841518e-01,\n",
      "        1.89547073e+00,  9.61334141e-01,  1.20324848e+00, -8.34906282e-01,\n",
      "        1.94900860e+00,  1.79856947e-01,  3.46581490e-02, -4.10096351e-01,\n",
      "       -1.19574934e+00, -6.26044132e-01, -9.68400314e-01, -8.55076835e-01,\n",
      "        1.18666368e-01, -2.45344352e-01, -7.24026654e-01,  9.18286816e-01,\n",
      "       -6.66500595e-01, -1.37009246e+00,  1.47576476e-01,  4.92979900e-01,\n",
      "        5.27730521e-01, -4.39361057e-01, -9.05797838e-01,  9.70889807e-01,\n",
      "        2.38777433e+00, -4.03136799e-01, -6.82363876e-01,  1.79974430e+00,\n",
      "        2.76235121e-01,  1.30651133e+00, -2.46636438e-02, -6.91709826e-01,\n",
      "        3.25867366e-01,  5.55504879e-01, -1.00433798e+00,  1.70277509e+00,\n",
      "       -8.07830051e-01, -3.59671538e-01, -1.20703512e+00,  4.50954799e-01,\n",
      "        2.31550494e-03,  1.35944955e+00,  6.07603366e-01, -1.08873285e+00,\n",
      "        1.33636023e+00, -1.14581306e+00, -1.70697400e+00, -5.24396465e-02,\n",
      "       -6.75955591e-01,  1.39931110e-01,  2.16551509e-01,  2.05906146e+00,\n",
      "        5.04812299e-01, -2.89608203e-01, -1.40931760e+00, -5.41422863e-01,\n",
      "       -1.45514796e+00, -6.73475569e-01, -1.34667332e+00,  2.06988539e+00,\n",
      "        7.55900977e-01, -8.93947171e-01, -1.15453568e+00,  4.91133029e-01,\n",
      "        7.20931655e-01, -6.26837044e-02,  2.19862010e+00,  1.70088023e+00,\n",
      "       -7.23595927e-01, -8.15716412e-01,  8.88795220e-01,  2.89670065e-01,\n",
      "        9.98819179e-01, -1.34785937e+00, -5.84822921e-01, -1.60160160e-01,\n",
      "        4.94273398e-01, -1.21544124e+00, -1.46065528e+00, -5.20200847e-01,\n",
      "       -4.68002941e-01, -4.22702124e-01, -7.28693060e-01,  1.53996102e+00,\n",
      "        5.47006433e-01, -3.47997015e-01,  1.15623791e+00,  2.98284102e-01,\n",
      "       -9.82998760e-02, -1.10324314e+00, -1.03532526e-01, -8.27297449e-01,\n",
      "        1.15336390e+00,  2.11132910e-01,  1.98873327e-01,  6.21245147e-01,\n",
      "       -1.16001592e+00,  1.41510001e+00,  3.75915209e-01, -1.40060071e+00,\n",
      "       -7.43000599e-01, -1.65664749e+00, -2.60894397e-01])]\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.004105291155992322\n",
      "Mean Squared Error: 2.444212776185014e-05\n",
      "Root Mean Squared Error: 0.004943898033116191\n",
      "R2 on data: 0.9999755578722381\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.0016473820697136066\n",
      "Mean Squared Error: 4.243417735561014e-06\n",
      "Root Mean Squared Error: 0.0020599557605834678\n",
      "R2 on data: 0.9999957565822645\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros : \n",
      "Mean Absolute Error: 0.01862965706529406\n",
      "Mean Squared Error: 0.0005330977421332149\n",
      "Root Mean Squared Error: 0.023088909505067902\n",
      "R2 on data: 0.9994669022578668\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long : \n",
      "Mean Absolute Error: 0.014778066414507116\n",
      "Mean Squared Error: 0.000319497757000732\n",
      "Root Mean Squared Error: 0.017874500188836944\n",
      "R2 on data: 0.9996805022429993\n",
      "[array([-0.26793672, -0.34041887,  0.50295403,  1.84510246, -0.05233301,\n",
      "        1.18293495, -0.33550483, -0.25933714,  0.68661645, -0.4589702 ,\n",
      "       -0.25565161, -1.31954226, -1.1143809 ,  0.55086596, -0.078746  ,\n",
      "       -0.85639356,  0.50233977, -0.55110854,  1.7283939 , -0.31154886,\n",
      "       -0.45159913, -0.60946282,  0.90406292, -0.09348813, -0.34410441,\n",
      "        0.10491642, -0.44115679,  1.33834161, -0.3373476 , -0.52285278,\n",
      "        0.20442582, -1.33367014, -1.01364299,  0.66941729,  1.35554077,\n",
      "       -0.64263262,  0.2572518 , -1.17212092, -0.33120504,  0.14484303,\n",
      "       -0.61191984, -0.50503937, -0.30663482,  2.01893679,  0.83096651,\n",
      "        0.55270873,  1.94461186, -1.1973054 ,  0.04471937, -1.10271004,\n",
      "       -1.27654437, -0.80848162, -0.01302065]), array([-0.35541172, -0.5002525 , -0.35848038, -1.1937698 , -1.26987259,\n",
      "       -0.08168719,  1.77485248, -0.92188647,  0.74562371, -0.16576849,\n",
      "        0.43814392,  1.67174549, -0.48245427,  0.69345648,  0.50995058,\n",
      "        0.22947499, -0.47079336, -1.26680393,  0.66154241, -0.13569562,\n",
      "        0.39947879, -0.10439528,  1.80062923, -0.18295299,  0.56825513,\n",
      "        0.76771807,  0.69529768, -0.69419185, -0.45974618, -0.34559201,\n",
      "       -0.77274957, -0.07002628, -0.4333557 ,  0.55966288, -1.16983425,\n",
      "       -0.28299133, -1.18885995]), array([-0.26609395, -0.21633925,  0.5324383 ,  2.02446509,  0.0041785 ,\n",
      "        1.15775047, -0.52469555, -0.27837906,  0.72900008, -0.56585067,\n",
      "       -0.32567674, -1.38711037, -1.17089241,  0.58956407, -0.03574811,\n",
      "       -0.92089039,  0.50909659, -0.82199525,  1.64301238, -0.33366206,\n",
      "       -0.63649006, -0.69914413,  0.94644656, -0.01424916, -0.59410643,\n",
      "        0.08833152, -0.46081297,  1.3205282 , -0.26547969, -0.57015046,\n",
      "        0.22039647, -1.41659464, -1.11499515,  0.74988477,  1.31008586,\n",
      "       -0.85209377,  0.21548242, -1.13465133, -0.31707716,  0.2130254 ,\n",
      "       -0.71265775, -0.35823229, -0.22616734,  2.19768516,  0.90774845,\n",
      "        0.5324383 ,  2.12274598, -1.10762409, -0.03697662, -1.1475507 ,\n",
      "       -1.40246676, -0.97801616, -0.00319256]), array([-0.38793952, -0.45729125, -0.4505402 , -1.32081235, -1.26557646,\n",
      "        0.04719655,  1.95037987, -0.9912382 ,  0.76587687, -0.08598332,\n",
      "        0.31478376,  1.8877792 , -0.39407684,  0.67688571,  0.43323406,\n",
      "        0.22517887, -0.61808907, -1.3159025 ,  0.72414309, -0.1467428 ,\n",
      "        0.3595862 , -0.02583757,  1.91416968, -0.1811118 ,  0.63515193,\n",
      "        0.83031874,  0.75789835, -0.78747914, -0.61808907, -0.49841131,\n",
      "       -0.81141469,  0.01221382, -0.61931653,  0.54186465, -1.33370073,\n",
      "       -0.14367414, -1.28214723])]\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.17789519378405577\n",
      "Mean Squared Error: 0.07151825492989036\n",
      "Root Mean Squared Error: 0.26742897174743496\n",
      "R2 on data: 0.9284817450701096\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2638132142461889\n",
      "Mean Squared Error: 0.124774981485575\n",
      "Root Mean Squared Error: 0.3532350230166525\n",
      "R2 on data: 0.8752250185144249\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_cros : \n",
      "Mean Absolute Error: 0.14032689632550352\n",
      "Mean Squared Error: 0.049010557418218734\n",
      "Root Mean Squared Error: 0.22138328170442034\n",
      "R2 on data: 0.9509894425817813\n",
      "\n",
      "Model : ........  Random Forest\n",
      "\n",
      " imp_long : \n",
      "Mean Absolute Error: 0.2204899705050585\n",
      "Mean Squared Error: 0.10699609882336675\n",
      "Root Mean Squared Error: 0.32710258149908683\n",
      "R2 on data: 0.8930039011766332\n",
      "[array([-0.25319458, -0.29521865,  0.42414031,  1.56193064, -0.19763237,\n",
      "        1.14500467, -0.39731714, -0.10320546,  0.5545515 , -0.55059666,\n",
      "       -0.39731714, -1.26324221, -1.08271882,  0.4992685 , -0.17928953,\n",
      "       -0.72543003,  0.40080147, -0.59653112,  1.53385039, -0.2743322 ,\n",
      "       -0.6401756 , -0.5126508 ,  0.8630443 , -0.19763237, -0.59653112,\n",
      "        0.39309003, -0.55059666,  1.34079863, -0.18562647, -0.29526621,\n",
      "        0.38431495, -1.25408992, -0.97801616,  0.51155361,  1.29472947,\n",
      "       -0.68499118,  0.40080147, -1.15034898, -0.33996662,  0.37084623,\n",
      "       -0.6401756 , -0.59653112, -0.17928953,  2.01647977,  0.70460536,\n",
      "        0.48084083,  1.77077754, -1.08237693, -0.25319458, -1.10013602,\n",
      "       -1.20221945, -0.77353371, -0.22154707]), array([-0.40178259, -0.45899773, -0.35891876, -1.22998   , -1.25480825,\n",
      "       -0.27903617,  1.85197816, -1.12345364,  0.79499505,  0.00999494,\n",
      "        0.50176748,  1.56556983, -0.37535801,  0.77112769,  0.41211445,\n",
      "        0.26138906, -0.59856654, -1.15486452,  0.73703146, -0.22959664,\n",
      "        0.40386259, -0.26247514,  1.82129155, -0.26130613,  0.66385571,\n",
      "        0.98252431,  0.81374798, -0.66534644, -0.36939117, -0.5255032 ,\n",
      "       -0.74644676,  0.10576413, -0.57810881,  0.52563484, -1.22998   ,\n",
      "       -0.26539768, -1.25287693]), array([-0.24524076, -0.103072  ,  0.43989046,  1.8168467 , -0.20618041,\n",
      "        1.15652196, -0.4718821 , -0.24524076,  0.582193  , -0.57718306,\n",
      "       -0.29601181, -1.18971496, -0.94297209,  0.43989046,  0.01969075,\n",
      "       -0.62140668,  0.4361677 , -0.60977621,  1.66021153, -0.37911698,\n",
      "       -0.48850496, -0.47125531,  0.6212421 ,  0.00833654, -0.4718821 ,\n",
      "        0.28632656, -0.57902924,  1.24586823, -0.16412752, -0.46140404,\n",
      "        0.31047183, -1.22218275, -0.62140668,  0.56683661,  1.22562571,\n",
      "       -0.49124299,  0.25970882, -1.00439765, -0.4718821 ,  0.31047183,\n",
      "       -0.60345379, -0.46140404, -0.20618041,  2.04719255,  0.95549286,\n",
      "        0.4361677 ,  1.95505421, -0.59572289, -0.08563931, -0.93962519,\n",
      "       -1.17963069, -0.93917353,  0.04155502]), array([-0.58143445, -0.57226374, -0.55030909, -1.22471944, -1.23537661,\n",
      "        0.12329934,  2.10088063, -0.70907486,  0.84224268,  0.02624402,\n",
      "        0.36265487,  1.96449571, -0.60963845,  0.52733965,  0.40970766,\n",
      "        0.4219823 , -0.59844964, -1.22471944,  0.72534133,  0.03291333,\n",
      "        0.36265487, -0.29515438,  1.71900286, -0.2190268 ,  0.52733965,\n",
      "        0.90069336,  0.76333427, -0.64693448, -0.54596093, -0.37864587,\n",
      "       -0.89958754,  0.12652951, -0.58143445,  0.45822172, -1.07068862,\n",
      "       -0.35891876, -1.14508039])]\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.2128397205474921\n",
      "Mean Squared Error: 0.08712205679565097\n",
      "Root Mean Squared Error: 0.29516445720250767\n",
      "R2 on data: 0.912877943204349\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2727972039798094\n",
      "Mean Squared Error: 0.14199133716139897\n",
      "Root Mean Squared Error: 0.37681737905966994\n",
      "R2 on data: 0.858008662838601\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_cros : \n",
      "Mean Absolute Error: 0.216080211060427\n",
      "Mean Squared Error: 0.08341059646559264\n",
      "Root Mean Squared Error: 0.2888089272609014\n",
      "R2 on data: 0.9165894035344073\n",
      "\n",
      "Model : ........  Adaboost\n",
      "\n",
      " imp_long : \n",
      "Mean Absolute Error: 0.24524245436996078\n",
      "Mean Squared Error: 0.12042543722639097\n",
      "Root Mean Squared Error: 0.347023683955996\n",
      "R2 on data: 0.879574562773609\n",
      "[array([-0.08646015, -0.31159003,  0.58187613,  1.89934241, -0.03011368,\n",
      "        1.10884322, -0.69234986, -0.35961346,  0.62702157, -0.77387274,\n",
      "       -0.38050759, -1.05976599, -1.19977256,  0.61668554, -0.05864725,\n",
      "       -0.93542535,  0.65633374, -0.82527975,  1.67036465, -0.32812618,\n",
      "       -0.48149907, -0.65099837,  0.88771131,  0.08786346, -0.59037981,\n",
      "        0.13288473, -0.46306079,  1.33944122, -0.38200388, -0.50649696,\n",
      "        0.24334674, -1.16062047, -0.74475318,  0.62655537,  1.27475879,\n",
      "       -0.69763601,  0.25932533, -1.11412557, -0.462703  ,  0.26356546,\n",
      "       -0.65087374, -0.41900398, -0.35927818,  2.08763929,  0.80495512,\n",
      "        0.61710429,  2.0479314 , -0.97431695,  0.30759034, -0.76722812,\n",
      "       -1.27833954, -1.03386588,  0.02640092]), array([-0.42278461, -0.50951305, -0.38571044, -1.3552843 , -1.49243779,\n",
      "       -0.01260984,  1.82245877, -0.91904688,  0.80784544, -0.05280325,\n",
      "        0.4602105 ,  1.69294436, -0.56654386,  0.54946841,  0.38876674,\n",
      "        0.31124323, -0.55202999, -1.33101334,  0.62620541, -0.04329056,\n",
      "        0.34412807, -0.07642608,  1.97279468, -0.06997266,  0.58331457,\n",
      "        0.93531532,  0.8491662 , -0.83638783, -0.5536058 , -0.61819763,\n",
      "       -0.91039609,  0.09956586, -0.49620268,  0.71614268, -1.06879319,\n",
      "       -0.02653219, -1.36886687]), array([-0.32388576, -0.20964891,  0.82466886,  2.13700472,  0.0097338 ,\n",
      "        1.16308579, -0.77106329, -0.142148  ,  0.74540011, -0.44056388,\n",
      "       -0.35950465, -1.43011557, -1.03508657,  0.77196226, -0.03266151,\n",
      "       -0.88271754,  0.6285053 , -1.02604683,  1.68278169, -0.42313743,\n",
      "       -0.78289964, -0.6139275 ,  0.77136224, -0.0947413 , -0.59942919,\n",
      "        0.1653938 , -0.5532648 ,  1.26200237, -0.38959411, -0.63166586,\n",
      "        0.24063477, -1.18171739, -0.94952294,  0.76794067,  1.25161564,\n",
      "       -0.89180013,  0.42738325, -1.01923805, -0.3007545 ,  0.18171338,\n",
      "       -0.75723335, -0.59111458, -0.39605439,  2.3954889 ,  0.79268396,\n",
      "        0.58087529,  2.25324064, -0.94297445,  0.14385026, -1.0532854 ,\n",
      "       -1.16435357, -1.08112912,  0.04673626]), array([-0.41435595, -0.42347533, -0.41611159, -1.37552353, -1.14567651,\n",
      "        0.08984721,  2.15139969, -0.97010532,  0.70178246, -0.02276904,\n",
      "        0.44067192,  2.01464465, -0.32385654,  0.63901027,  0.39025779,\n",
      "        0.30308437, -0.7759722 , -1.34934437,  0.69962121,  0.05305862,\n",
      "        0.48868976,  0.03406509,  2.13520259, -0.08409065,  0.74298093,\n",
      "        0.84511543,  0.83086574, -0.84397536, -0.67042194, -0.58654384,\n",
      "       -0.90446371,  0.0137545 , -0.69145559,  0.60969834, -1.24591135,\n",
      "       -0.03212413, -1.07655312])]\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_cros : \n",
      "Mean Absolute Error: 0.18302772562358338\n",
      "Mean Squared Error: 0.0751798350972752\n",
      "Root Mean Squared Error: 0.2741894146338899\n",
      "R2 on data: 0.9248201649027248\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " full_long : \n",
      "Mean Absolute Error: 0.2639082411385937\n",
      "Mean Squared Error: 0.12035590205553232\n",
      "Root Mean Squared Error: 0.34692348155685904\n",
      "R2 on data: 0.8796440979444676\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_cros : \n",
      "Mean Absolute Error: 0.13528803844812257\n",
      "Mean Squared Error: 0.04712312585830335\n",
      "Root Mean Squared Error: 0.21707861676891013\n",
      "R2 on data: 0.9528768741416966\n",
      "\n",
      "Model : ........  Gradient Boost\n",
      "\n",
      " imp_long : \n",
      "Mean Absolute Error: 0.20587171142582006\n",
      "Mean Squared Error: 0.09511042519337334\n",
      "Root Mean Squared Error: 0.30839978144183783\n",
      "R2 on data: 0.9048895748066266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# call training function\n",
    "model_names = ['Random Forest', \"Adaboost\", \"Gradient Boost\"]\n",
    "df_types = [\"full_cros\", \"full_long\", \"imp_cros\", \"imp_long\"]\n",
    "\n",
    "# Base models scores for training and testing\n",
    "base_pred = [{},{}]\n",
    "base_m_score = [{},{}]\n",
    "\n",
    "# base model on training and testing data to check overfitting\n",
    "trained_models_base =  train_models(data_scaled=data_scaled, \n",
    "                                    model_names=model_names, \n",
    "                                    df_types=df_types,\n",
    "                                    indx1=0, indx2=1)\n",
    "\n",
    "for i in range(2): # for train and test data\n",
    "    if i == 0:\n",
    "        indx = 0\n",
    "    else:\n",
    "        indx = 2\n",
    "       \n",
    "    # Make predictions\n",
    "    base_pred[i] = make_predictions(data_scaled=data_scaled, \n",
    "                                    model_names=model_names, \n",
    "                                    df_types=df_types, indx=indx,\n",
    "                                    trained_models=trained_models_base)\n",
    "    \n",
    "    # Get scores for each model on each data set\n",
    "    for j in range(len(model_names)):\n",
    "        predictions = [value for key,value in base_pred[i].items() if key.startswith(model_names[j])]\n",
    "        print(predictions)\n",
    "        base_m_score[i] = evaluate_model(data_scaled=data_scaled, \n",
    "                                                         preds=predictions, df_indx=indx+1, \n",
    "                                                         df_types=df_types, \n",
    "                                                         model_name = model_names[j],\n",
    "                                                         store=base_m_score[i]\n",
    "                                                        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Random Forest_full_cros': array([ 0.02567745, -1.02531384, -0.96020275,  0.59632088, -0.86622165,\n",
       "         -0.44422807, -0.33611909, -1.48170573,  1.41143803, -1.35578334,\n",
       "         -0.6567605 ,  0.59202109, -0.76425522,  0.28673607,  1.69215282,\n",
       "         -1.32077077, -0.0676894 , -0.72555712, -0.57322174, -0.794968  ,\n",
       "          0.50541105, -1.55480215,  0.52322446, -0.50135384, -0.43255721,\n",
       "          0.07236087,  0.9624172 , -0.60700579, -1.29312927, -1.06401194,\n",
       "          0.01400659,  0.55823703, -1.20344796, -1.01671426, -0.74398479,\n",
       "          0.29902118,  0.58833555,  0.47776955, -0.89877719,  0.15282835,\n",
       "          2.19461388,  0.12887238,  1.05394128, -1.35271206, -0.89079187,\n",
       "         -0.61376261, -0.72739989, -0.5916494 ,  2.13810237,  0.4992685 ,\n",
       "         -0.75934118, -0.90737677,  0.30639225,  0.168799  , -0.40798699,\n",
       "         -0.61499112,  0.50233977, -1.32752758, -0.25749437, -1.35455483,\n",
       "          0.16142793, -0.22309606,  0.37518887,  0.82052416, -1.49399084,\n",
       "          0.06744683,  0.30639225, -0.40737273,  0.12395834, -0.2169535 ,\n",
       "         -0.41412954, -0.0345196 , -0.32506249, -0.5916494 , -0.67580242,\n",
       "          1.86967268,  1.82790331,  1.48084891,  0.01154957, -0.44668509,\n",
       "         -1.08796791,  0.54472341, -0.47739787, -1.59165748, -0.14324284,\n",
       "          1.49743381,  1.99559508,  0.87273589,  0.43907145,  0.51093935,\n",
       "         -0.86806441,  0.48329785, -0.60700579,  0.15282835,  1.87397247,\n",
       "          0.03427703,  0.59570662, -0.75872692, -0.59963473, -1.41659464,\n",
       "         -0.40552997,  0.49558296,  2.13380258,  0.58649279, -0.72494286,\n",
       "          2.06623447,  0.03673405,  0.24680946,  0.5379666 , -0.86376462,\n",
       "          0.10491642, -0.49336851, -0.63833283,  0.52936702, -0.02960555,\n",
       "          1.18723474, -1.19239136, -0.09041686, -0.83243759, -1.58182939,\n",
       "          0.91634803,  2.12397449,  1.69583836, -1.23784627,  1.95751123,\n",
       "         -0.37481719,  0.1411575 , -0.07014642,  1.73023667,  1.94768314,\n",
       "          1.1823207 ,  1.39546738, -0.64816092, -0.56216514, -0.59717771,\n",
       "         -0.32260546,  1.50787615, -0.11682985,  0.15282835, -0.02960555,\n",
       "         -0.61376261,  1.88134354,  1.43170846,  0.113516  , -0.40307294,\n",
       "         -1.20160519, -0.05540429,  0.4937402 , -1.01548575, -0.01977746,\n",
       "          0.04901916,  0.54226639, -0.43992828, -1.4669636 , -0.36744612,\n",
       "          0.91389101, -0.03267683]),\n",
       "  'Adaboost_full_cros': array([ 7.34923952e-02, -1.10013602e+00, -1.08237693e+00,  4.60365643e-01,\n",
       "         -7.93739489e-01, -4.02953759e-01, -1.03205455e-01, -1.27333134e+00,\n",
       "          1.40904925e+00, -1.21604020e+00, -6.45294392e-01,  4.60365643e-01,\n",
       "         -6.56214491e-01,  3.98940086e-01,  1.45682469e+00, -1.21604020e+00,\n",
       "          1.55994131e-01, -6.61290631e-01, -6.40175595e-01, -6.61290631e-01,\n",
       "          3.84314953e-01, -1.27333134e+00,  4.51151810e-01, -3.39966621e-01,\n",
       "         -2.95218654e-01,  1.26327612e-01,  9.78387845e-01, -4.86611702e-01,\n",
       "         -1.21604020e+00, -1.08237693e+00,  5.70044823e-02,  4.60365643e-01,\n",
       "         -1.15094246e+00, -1.00685621e+00, -6.45294392e-01,  3.84314953e-01,\n",
       "          4.60365643e-01,  4.51151810e-01, -7.87833186e-01,  1.53969112e-01,\n",
       "          2.16390110e+00,  5.66567905e-02,  1.01949572e+00, -1.27508287e+00,\n",
       "         -1.02159510e+00, -5.50596657e-01, -7.07924372e-01, -5.75678760e-01,\n",
       "          2.11300564e+00,  4.99268496e-01, -6.29369247e-01, -7.87833186e-01,\n",
       "          3.54150617e-01,  3.70846226e-01, -4.86611702e-01, -5.50596657e-01,\n",
       "          4.51151810e-01, -1.27333134e+00, -2.91828026e-01, -1.25408992e+00,\n",
       "          3.54150617e-01, -1.99227843e-01,  3.40439555e-01,  6.95830280e-01,\n",
       "         -1.25408992e+00, -7.19891884e-02,  3.70846226e-01, -4.07392233e-01,\n",
       "          2.81207767e-01, -2.18465518e-01, -3.39966621e-01,  1.03471972e-02,\n",
       "         -1.02701967e-01, -5.12650797e-01, -5.29268339e-01,  1.88339106e+00,\n",
       "          1.61282610e+00,  1.45136464e+00,  5.70044823e-02, -3.39966621e-01,\n",
       "         -1.20221945e+00,  4.51151810e-01, -4.02953759e-01, -1.31676004e+00,\n",
       "         -8.64422608e-02,  1.51739711e+00,  1.97041060e+00,  9.10819732e-01,\n",
       "          3.89384999e-01,  4.51151810e-01, -7.87833186e-01,  4.02216116e-01,\n",
       "         -4.26992778e-01,  5.70044823e-02,  1.83220309e+00,  4.73518947e-02,\n",
       "          6.88742716e-01, -6.61290631e-01, -6.60185436e-01, -1.28514395e+00,\n",
       "         -3.97317141e-01,  4.42449856e-01,  2.12397449e+00,  4.51151810e-01,\n",
       "         -6.60185436e-01,  2.07790532e+00,  1.55994131e-01,  3.40439555e-01,\n",
       "          3.98940086e-01, -7.41527765e-01,  3.70846226e-01, -3.85471344e-01,\n",
       "         -5.75678760e-01,  4.78793311e-01,  1.55994131e-01,  1.14423685e+00,\n",
       "         -1.15034898e+00, -8.64422608e-02, -7.03794923e-01, -1.26978756e+00,\n",
       "          9.02044652e-01,  2.05060508e+00,  1.56602568e+00, -1.10086728e+00,\n",
       "          2.06766773e+00, -2.95266215e-01,  1.98283265e-01,  1.03471972e-02,\n",
       "          1.59673846e+00,  1.88339106e+00,  1.05257102e+00,  1.40904925e+00,\n",
       "         -5.96531120e-01, -5.73631241e-01, -5.77568777e-01, -3.62515474e-01,\n",
       "          1.44131318e+00, -1.69547427e-01,  3.40439555e-01, -1.85626470e-01,\n",
       "         -7.25430033e-01,  1.95505421e+00,  1.45136464e+00,  2.96564157e-01,\n",
       "          1.82488121e-01, -1.10086728e+00, -2.18465518e-01,  4.42449856e-01,\n",
       "         -1.02159510e+00,  1.03471972e-02,  1.92970282e-03,  4.99268496e-01,\n",
       "         -2.95266215e-01, -1.26324221e+00, -3.39966621e-01,  1.04595596e+00,\n",
       "          8.34360859e-02]),\n",
       "  'Gradient Boost_full_cros': array([ 0.04876647, -1.17142643, -1.17348558,  0.60038803, -1.04997112,\n",
       "         -0.55709622,  0.0412113 , -1.66004429,  1.34582131, -1.42563997,\n",
       "         -0.74415907,  0.60406232, -0.80692857,  0.29899994,  1.57953686,\n",
       "         -1.41823152,  0.28988279, -0.75396197, -0.50602234, -0.87291219,\n",
       "          0.48078642, -1.72449222,  0.5391075 , -0.55371355, -0.50054867,\n",
       "          0.35143208,  0.96709296, -0.68838698, -1.24132196, -1.17412852,\n",
       "          0.10358267,  0.54508433, -1.23917435, -1.11928886, -0.8701945 ,\n",
       "          0.29971362,  0.60137763,  0.47896407, -1.04895026,  0.28723671,\n",
       "          2.37823493,  0.17109146,  1.21223526, -1.4782547 , -1.11250871,\n",
       "         -0.68521656, -0.92891529, -0.74302787,  2.25895117,  0.47887201,\n",
       "         -0.86477691, -1.04819231,  0.29180397,  0.11289124, -0.38392039,\n",
       "         -0.74738511,  0.47649432, -1.36184236, -0.31156304, -1.35801167,\n",
       "          0.17179478, -0.30355113,  0.59434685,  0.72390903, -1.60037287,\n",
       "          0.04995093,  0.35881344, -0.43996095,  0.11698478, -0.26008638,\n",
       "         -0.50366218,  0.22755226,  0.04768403, -0.68263758, -0.74679814,\n",
       "          1.88936903,  1.77234931,  1.3979598 , -0.0057314 , -0.56052807,\n",
       "         -0.99772419,  0.54350191, -0.61575444, -1.72529969, -0.18744402,\n",
       "          1.4020223 ,  2.0753352 ,  0.8555694 ,  0.41892383,  0.48380043,\n",
       "         -0.98346794,  0.48244291, -0.63013418,  0.29287894,  1.89266853,\n",
       "          0.22924628,  0.96498387, -0.86427958, -0.74609464, -1.47796149,\n",
       "         -0.43965361,  0.48263405,  2.25851569,  0.60067998, -0.80628231,\n",
       "          2.19878404,  0.35267107,  0.77430851,  0.5417921 , -0.9893198 ,\n",
       "          0.1154062 , -0.61702231, -0.68921188,  0.54135121,  0.2890906 ,\n",
       "          1.15779586, -1.23367589, -0.06747879, -0.92675316, -1.72370816,\n",
       "          0.85292797,  2.195293  ,  1.70272568, -1.23954144,  2.07761684,\n",
       "         -0.26095288,  0.11136795, -0.06699994,  1.70852411,  1.95368266,\n",
       "          1.1542264 ,  1.27852773, -0.69212991, -0.68992873, -0.62761718,\n",
       "         -0.38488435,  1.52649572, -0.13222727,  0.11659606, -0.01712793,\n",
       "         -0.44830135,  1.9504483 ,  1.34063571,  0.11900638,  0.28661081,\n",
       "         -1.23481294, -0.01541879,  0.53985033, -1.17389974, -0.00978235,\n",
       "          0.10681508,  0.53617923, -0.49724989, -1.60114135, -0.37754537,\n",
       "          0.97392222, -0.0623404 ]),\n",
       "  'Random Forest_full_long': array([ 0.33380946, -0.09273437,  1.58091313, -1.3981426 ,  0.89660181,\n",
       "         -0.46711097,  0.3117151 , -0.64509328,  1.8362257 ,  0.60692025,\n",
       "          1.00461867, -0.654913  ,  1.87980068,  0.01160009, -0.37382368,\n",
       "         -0.38487086, -1.00780897, -0.53032538, -0.81325589, -0.77643196,\n",
       "          0.23929471, -0.39407684, -0.63220491,  0.86346028, -0.62422639,\n",
       "         -1.27600991,  0.17730776,  0.52406641,  0.57009632, -0.3989867 ,\n",
       "         -0.77581823,  0.89476062,  2.11179142, -0.43949302, -0.62974998,\n",
       "          1.80247043, -0.21854946,  1.36794809, -0.05468298, -0.586175  ,\n",
       "          0.35099396,  0.55291182, -0.89242733,  1.74171095, -0.74513162,\n",
       "         -0.35172933, -1.11091597,  0.47619531, -0.05591044,  1.46553149,\n",
       "          0.60078293, -0.84394249,  1.41950158, -0.96484772, -1.47056299,\n",
       "         -0.1105326 , -0.56039825,  0.19265107,  0.01037263,  1.95958585,\n",
       "          0.54125091, -0.30569942, -1.3809581 , -0.49657011, -1.34720283,\n",
       "         -0.5327803 , -1.30424159,  1.94792494,  0.25156935, -0.74820028,\n",
       "         -1.02683467,  0.58052977,  0.6689072 , -0.08721078,  2.00745696,\n",
       "          1.65824338, -0.58494754, -0.66350525,  0.84566205,  0.12329934,\n",
       "          0.86530148, -1.33983805, -0.48613666, -0.15410758,  0.54370584,\n",
       "         -1.05690754, -1.3312458 , -0.49166025, -0.54812361, -0.42108106,\n",
       "         -0.71260382,  1.53181456,  0.56702766, -0.34129588,  1.24949779,\n",
       "          0.34915276, -0.24248501, -0.9605516 , -0.12096605, -0.67762109,\n",
       "          1.20101295, -0.06450269,  0.18528628,  0.60569279, -0.99062447,\n",
       "          1.50787901,  0.4626932 , -1.34720283, -0.60949682, -1.49818094,\n",
       "         -0.28421879]),\n",
       "  'Adaboost_full_long': array([ 0.26263312, -0.26130613,  1.52806398, -1.31397566,  0.97530393,\n",
       "         -0.40178259,  0.40167069, -0.57810881,  1.85197816,  0.74819023,\n",
       "          1.08072145, -0.61317921,  2.00833372, -0.0345175 , -0.00456152,\n",
       "         -0.28176387, -1.22998   , -0.53204175, -0.96371468, -0.65000314,\n",
       "          0.37561143, -0.5255032 , -0.54829896,  0.99567571, -0.53204175,\n",
       "         -1.25287693,  0.26263312,  0.50469001,  0.48130974, -0.37535801,\n",
       "         -0.66970717,  0.97530393,  2.15884422, -0.51275032, -0.54829896,\n",
       "          1.79060494,  0.21194953,  1.36303823, -0.22959664, -0.53204175,\n",
       "          0.41128133,  0.52563484, -0.81264215,  1.6743678 , -0.63363695,\n",
       "         -0.45899773, -1.21209711,  0.4455087 , -0.00456152,  1.35076359,\n",
       "          0.48130974, -0.87003747,  1.36020562, -1.22998   , -1.32920003,\n",
       "         -0.0345175 , -0.52572239,  0.36879219,  0.13746239,  2.02586892,\n",
       "          0.48130974, -0.28001035, -1.30733141, -0.40178259, -1.32510848,\n",
       "         -0.53204175, -1.25480825,  2.08724214,  0.52222522, -0.66534644,\n",
       "         -1.18688533,  0.65110896,  0.73703146,  0.05510688,  2.05655553,\n",
       "          1.62694304, -0.5255032 , -0.61829365,  0.96206657,  0.18255623,\n",
       "          0.97530393, -1.25480825, -0.35891876, -0.12602934,  0.50469001,\n",
       "         -1.19047099, -1.3159025 , -0.5255032 , -0.66534644, -0.30073377,\n",
       "         -0.53204175,  1.52372446,  0.46523581, -0.45899773,  1.14209466,\n",
       "          0.40167069, -0.30073377, -0.81264215, -0.12901276, -0.61999846,\n",
       "          1.18469489, -0.00590743,  0.36879219,  0.5276405 , -1.16367833,\n",
       "          1.4121368 ,  0.40386259, -1.31458736, -0.59783591, -1.3159025 ,\n",
       "         -0.44951731]),\n",
       "  'Gradient Boost_full_long': array([ 3.07625644e-01, -6.30537659e-02,  1.59720041e+00, -1.59325734e+00,\n",
       "          8.59387481e-01, -4.89549321e-01,  6.11359121e-01, -7.37971754e-01,\n",
       "          1.90148417e+00,  9.77068134e-01,  1.22551546e+00, -8.55300390e-01,\n",
       "          1.96280324e+00,  1.82242285e-01,  5.88829090e-02, -4.27915524e-01,\n",
       "         -1.22694013e+00, -6.13161495e-01, -9.79841589e-01, -8.60436014e-01,\n",
       "          1.26838728e-01, -2.47832132e-01, -7.34871161e-01,  9.20545913e-01,\n",
       "         -6.74385336e-01, -1.34948059e+00,  1.24640284e-01,  4.91336314e-01,\n",
       "          5.51547824e-01, -4.30601034e-01, -9.15398053e-01,  9.82623366e-01,\n",
       "          2.39253670e+00, -3.72533281e-01, -6.75272027e-01,  1.77992084e+00,\n",
       "          3.02832739e-01,  1.28819161e+00,  2.00602529e-03, -6.75805009e-01,\n",
       "          3.08219481e-01,  5.52666592e-01, -1.03991318e+00,  1.71776335e+00,\n",
       "         -7.99653165e-01, -3.68032749e-01, -1.22417134e+00,  4.30055232e-01,\n",
       "          1.39416012e-03,  1.35016964e+00,  6.13375530e-01, -1.10310006e+00,\n",
       "          1.34863136e+00, -1.16459051e+00, -1.71390955e+00, -6.25235335e-02,\n",
       "         -6.71740599e-01,  1.24676755e-01,  2.42620502e-01,  2.08640381e+00,\n",
       "          4.92790918e-01, -3.03614046e-01, -1.41129020e+00, -5.53427705e-01,\n",
       "         -1.47090250e+00, -6.74387233e-01, -1.35126606e+00,  2.08446369e+00,\n",
       "          7.96490990e-01, -9.18055684e-01, -1.16312935e+00,  4.94103053e-01,\n",
       "          7.35779882e-01, -5.84875774e-02,  2.20948831e+00,  1.71598743e+00,\n",
       "         -7.32568940e-01, -7.96617419e-01,  8.59663601e-01,  3.06523545e-01,\n",
       "          9.82386755e-01, -1.35008721e+00, -6.08922153e-01, -1.82418554e-01,\n",
       "          4.91750892e-01, -1.22613168e+00, -1.47154224e+00, -4.90831329e-01,\n",
       "         -4.33167011e-01, -4.29604954e-01, -7.32073349e-01,  1.53533919e+00,\n",
       "          5.52547885e-01, -3.67130807e-01,  1.16747804e+00,  3.08141446e-01,\n",
       "         -6.34086362e-02, -1.10221922e+00, -1.20840739e-01, -8.56019202e-01,\n",
       "          1.16442677e+00,  2.42805296e-01,  1.86169027e-01,  6.16157289e-01,\n",
       "         -1.16430933e+00,  1.41386926e+00,  3.68778774e-01, -1.40709728e+00,\n",
       "         -7.34700086e-01, -1.65513178e+00, -2.47084726e-01]),\n",
       "  'Random Forest_imp_cros': array([ 0.09447407, -1.0038149 , -1.02285682,  0.60000641, -0.97064509,\n",
       "         -0.46511276, -0.19975435, -1.52408937,  1.40038143, -1.39018165,\n",
       "         -0.70467243,  0.59202109, -0.7286284 ,  0.29349288,  1.56930171,\n",
       "         -1.35271206,  0.00233574, -0.63034751, -0.61007707, -0.81216716,\n",
       "          0.47654104, -1.57445833,  0.5434949 , -0.47371233, -0.43501423,\n",
       "          0.11535876,  0.97224529, -0.61314835, -1.28268693, -1.1143809 ,\n",
       "          0.05024767,  0.54718043, -1.20037668, -1.00074362, -0.67764519,\n",
       "          0.29103586,  0.59939216,  0.47469827, -0.81585269,  0.19275496,\n",
       "          2.2566537 ,  0.11781578,  1.09878194, -1.35148355, -0.83980866,\n",
       "         -0.61437686, -0.80909588, -0.61069133,  2.2124273 ,  0.48329785,\n",
       "         -0.80663886, -0.99337255,  0.28857883,  0.14238601, -0.50135384,\n",
       "         -0.69852987,  0.48206934, -1.36376866, -0.25872288, -1.31524247,\n",
       "          0.20504008, -0.20466839,  0.38071717,  0.82543821, -1.53821725,\n",
       "          0.06253278,  0.30946352, -0.42088636,  0.13992898, -0.25749437,\n",
       "         -0.41904359, -0.07383196, -0.26916523, -0.59472068, -0.7175718 ,\n",
       "          1.90038546,  1.74866434,  1.45136464,  0.00786404, -0.5087249 ,\n",
       "         -1.17212092,  0.55393724, -0.48354042, -1.62237026, -0.0676894 ,\n",
       "          1.4587357 ,  2.03429318,  0.8905493 ,  0.44521401,  0.48391211,\n",
       "         -0.90430549,  0.49251169, -0.62481921,  0.15897091,  1.89792844,\n",
       "          0.10737344,  0.61044876, -0.76671224, -0.6567605 , -1.42396571,\n",
       "         -0.38218825,  0.47776955,  2.21549857,  0.5932496 , -0.7231001 ,\n",
       "          2.15653004,  0.05639023,  0.25786606,  0.54226639, -0.89632017,\n",
       "          0.11474451, -0.51363895, -0.58304983,  0.54840894, -0.06584663,\n",
       "          1.17433537, -1.19484838, -0.05417578, -0.81646695, -1.64264069,\n",
       "          0.90283441,  2.18048601,  1.62458471, -1.17887773,  1.98330997,\n",
       "         -0.37911698,  0.10307365, -0.03943364,  1.72532262,  1.96733932,\n",
       "          1.18109218,  1.35738353, -0.67088837, -0.56523642, -0.64140411,\n",
       "         -0.34533292,  1.50603338, -0.05233301,  0.18415539,  0.00663553,\n",
       "         -0.63034751,  1.91021355,  1.39915291,  0.1411575 , -0.41658657,\n",
       "         -1.16474986,  0.00356425,  0.48636913, -1.05418385,  0.0041785 ,\n",
       "          0.04410512,  0.5490232 , -0.44299956, -1.49214808, -0.36621761,\n",
       "          0.95013209, -0.00994938]),\n",
       "  'Adaboost_imp_cros': array([ 0.19448933, -0.92755945, -0.92755945,  0.37050233, -0.70240938,\n",
       "         -0.48126285, -0.21190296, -1.37728229,  1.48119991, -1.20982452,\n",
       "         -0.57228419,  0.45091556, -0.57718306,  0.31047183,  1.52507531,\n",
       "         -1.15351775,  0.0365293 , -0.60977621, -0.57718306, -0.60345379,\n",
       "          0.53842729, -1.40659903,  0.36822731, -0.38990795, -0.4718821 ,\n",
       "          0.12478082,  0.97907035, -0.57902924, -1.09879209, -0.94423211,\n",
       "          0.10506095,  0.38723998, -1.00439765, -0.73807258, -0.57718306,\n",
       "          0.18512065,  0.40186511,  0.46036564, -0.62765423,  0.18108411,\n",
       "          2.13165269,  0.07816217,  1.02343325, -1.22339166, -0.9224482 ,\n",
       "         -0.60345379, -0.57228419, -0.4718821 ,  2.0642552 ,  0.44398549,\n",
       "         -0.57718306, -0.73181856,  0.2020633 ,  0.2020633 , -0.48850496,\n",
       "         -0.57228419,  0.36822731, -1.22218275, -0.31277737, -1.20982452,\n",
       "          0.25970882, -0.31277737,  0.2351386 ,  0.582193  , -1.35003708,\n",
       "          0.19448933,  0.37050233, -0.4718821 ,  0.28632656, -0.08563931,\n",
       "         -0.4718821 , -0.05582457, -0.24705203, -0.48376793, -0.54449348,\n",
       "          1.88339106,  1.78306265,  1.4145093 ,  0.01969075, -0.46140404,\n",
       "         -1.09879209,  0.54226639, -0.45138234, -1.43486875,  0.04155502,\n",
       "          1.3868678 ,  2.02876488,  0.90204465,  0.45091556,  0.46036564,\n",
       "         -0.68324839,  0.38723998, -0.48850496,  0.19418823,  1.88339106,\n",
       "         -0.06931851,  0.61137014, -0.57902924, -0.49124299, -1.2134808 ,\n",
       "         -0.38990795,  0.37078671,  2.06035517,  0.46036564, -0.57902924,\n",
       "          1.9704106 ,  0.07816217,  0.37078671,  0.35389468, -0.68324839,\n",
       "          0.25970882, -0.37229191, -0.57718306,  0.43989046, -0.05337538,\n",
       "          1.18382221, -0.98268985,  0.01969075, -0.60345379, -1.37728229,\n",
       "          0.98862544,  2.02876488,  1.55578809, -0.94021582,  2.00624217,\n",
       "         -0.49124299,  0.18512065,  0.04552057,  1.63915134,  1.93457902,\n",
       "          1.03750994,  1.4145093 , -0.48850496, -0.38990795, -0.49124299,\n",
       "         -0.37911698,  1.48040217, -0.00637552,  0.28632656,  0.04155502,\n",
       "         -0.62481921,  1.91410384,  1.47593486,  0.29246912, -0.05582457,\n",
       "         -0.94297209,  0.00618879,  0.37050233, -0.9224482 ,  0.09122729,\n",
       "          0.0892529 ,  0.38723998, -0.37911698, -1.15351775, -0.24524076,\n",
       "          0.97907035,  0.12478082]),\n",
       "  'Gradient Boost_imp_cros': array([ 0.02723643, -1.16427995, -1.14166295,  0.58240937, -1.04664648,\n",
       "         -0.54500568,  0.00634914, -1.62173467,  1.33555157, -1.45223526,\n",
       "         -0.75002727,  0.61795512, -0.79953339,  0.28883131,  1.56473138,\n",
       "         -1.42208413,  0.27614592, -0.77294361, -0.50747615, -0.86946902,\n",
       "          0.46791389, -1.7228306 ,  0.5303958 , -0.55651658, -0.51803584,\n",
       "          0.31916415,  0.96458387, -0.67652636, -1.23410189, -1.17814287,\n",
       "          0.09905395,  0.5439731 , -1.19601572, -1.10366041, -0.84717355,\n",
       "          0.29745492,  0.60473374,  0.46709689, -1.02486211,  0.25402861,\n",
       "          2.36857807,  0.14556465,  1.19445874, -1.45998219, -1.08035832,\n",
       "         -0.70410762, -0.8827868 , -0.74451339,  2.23273802,  0.47755577,\n",
       "         -0.85315857, -1.04726768,  0.31296624,  0.13103813, -0.41100886,\n",
       "         -0.75998361,  0.47321088, -1.36998793, -0.27787656, -1.34832343,\n",
       "          0.17912877, -0.29896125,  0.56063057,  0.71629262, -1.59463697,\n",
       "          0.05078382,  0.33928895, -0.44393066,  0.13120045, -0.27032293,\n",
       "         -0.54438037,  0.19164856,  0.01741314, -0.65533238, -0.75811795,\n",
       "          1.87092553,  1.77860522,  1.42031609, -0.03867211, -0.54139588,\n",
       "         -1.03324499,  0.53822829, -0.59617682, -1.72301096, -0.16734596,\n",
       "          1.41494681,  2.07217191,  0.86099419,  0.45161596,  0.48359255,\n",
       "         -0.95329912,  0.49067603, -0.64250315,  0.25243781,  1.8784448 ,\n",
       "          0.20907924,  0.95883541, -0.84644573, -0.72741876, -1.47585496,\n",
       "         -0.43604882,  0.48830542,  2.25893069,  0.60395382, -0.80416163,\n",
       "          2.1707994 ,  0.32685852,  0.74791355,  0.55022202, -0.9849523 ,\n",
       "          0.13133457, -0.5802854 , -0.68903152,  0.54022745,  0.256636  ,\n",
       "          1.18025195, -1.20998098, -0.07342972, -0.90390974, -1.70252229,\n",
       "          0.86684324,  2.203364  ,  1.69807388, -1.21188011,  2.05379826,\n",
       "         -0.30079567,  0.10076121, -0.00358552,  1.7186892 ,  1.96186249,\n",
       "          1.13882421,  1.27651043, -0.70531807, -0.66092777, -0.64551433,\n",
       "         -0.40874622,  1.52203996, -0.11658302,  0.13806145, -0.01581059,\n",
       "         -0.4708703 ,  1.94731215,  1.34642284,  0.14264598,  0.25377261,\n",
       "         -1.23354369,  0.00312522,  0.51989154, -1.16328219,  0.01716012,\n",
       "          0.09758329,  0.53925833, -0.49493051, -1.58967954, -0.40152164,\n",
       "          0.97431632, -0.01804451]),\n",
       "  'Random Forest_imp_long': array([ 0.32521721, -0.0589791 ,  1.59502897, -1.47301792,  0.91869617,\n",
       "         -0.43949302,  0.32951333, -0.64938941,  1.87673202,  0.6689072 ,\n",
       "          1.08379011, -0.7389943 ,  1.851569  ,  0.08708914, -0.45729125,\n",
       "         -0.40144163, -1.09189027, -0.6052007 , -0.82246187, -0.7905478 ,\n",
       "          0.15214475, -0.46342857, -0.66596018,  0.87941731, -0.62790878,\n",
       "         -1.31835742,  0.16135073,  0.49644847,  0.54738824, -0.38241593,\n",
       "         -0.72733339,  0.93465321,  2.18421181, -0.46649724, -0.60826936,\n",
       "          1.80983522, -0.1946139 ,  1.36794809, -0.02154144, -0.59047112,\n",
       "          0.32767213,  0.55352556, -0.91145303,  1.68954372, -0.71935487,\n",
       "         -0.32779378, -1.0961864 ,  0.41236717, -0.00619814,  1.41090933,\n",
       "          0.58850829, -0.90101958,  1.43238996, -1.06979591, -1.55218936,\n",
       "         -0.05591044, -0.55732959,  0.22517887,  0.00914516,  2.02034533,\n",
       "          0.48662875, -0.28299133, -1.38525423, -0.45422259, -1.36684226,\n",
       "         -0.586175  , -1.34536164,  1.98106648,  0.20553944, -0.78625167,\n",
       "         -1.09557266,  0.55720795,  0.70082127, -0.07248121,  2.08233228,\n",
       "          1.60914481, -0.67823482, -0.73776683,  0.8677564 ,  0.13005039,\n",
       "          0.91746871, -1.33492819, -0.46342857, -0.06818509,  0.52836254,\n",
       "         -1.10232372, -1.32449475, -0.57758275, -0.58126514, -0.43703809,\n",
       "         -0.66227778,  1.51708499,  0.51179177, -0.3149054 ,  1.21696998,\n",
       "          0.34485663, -0.21118467, -0.96853011, -0.07861853, -0.75372387,\n",
       "          1.19426189, -0.06388896,  0.2257926 ,  0.61796743, -1.09986879,\n",
       "          1.45693924,  0.3804531 , -1.32817714, -0.64693448, -1.54482458,\n",
       "         -0.32349765]),\n",
       "  'Adaboost_imp_long': array([ 0.19550312,  0.02300653,  1.55789818, -1.27770296,  0.84224268,\n",
       "         -0.43928844,  0.44411386, -0.58362915,  1.77423875,  0.67224863,\n",
       "          1.05266513, -0.58362915,  1.93994643,  0.13864264, -0.17655264,\n",
       "         -0.43928844, -0.99062447, -0.59844964, -0.70629719, -0.7198517 ,\n",
       "          0.30741897, -0.58362915, -0.60963845,  0.90069336, -0.58143445,\n",
       "         -1.23537661,  0.27437186,  0.40970766,  0.4301654 , -0.42053552,\n",
       "         -0.71137635,  0.96615812,  2.16395865, -0.54596093, -0.58999378,\n",
       "          1.71900286,  0.12329934,  1.41895604, -0.13810509, -0.58862993,\n",
       "          0.38106683,  0.52733965, -0.89331823,  1.59625644, -0.62942506,\n",
       "         -0.20684622, -1.00801355,  0.40970766,  0.06874537,  1.33030585,\n",
       "          0.47108087, -0.77274957,  1.26484109, -0.95910096, -1.34746586,\n",
       "          0.02685572, -0.55030909,  0.28111617,  0.12652951,  2.06269285,\n",
       "          0.4301654 , -0.29515438, -1.26288874, -0.50407128, -1.2951038 ,\n",
       "         -0.58362915, -1.16846066,  1.97983901,  0.4551693 , -0.62942506,\n",
       "         -0.99062447,  0.5467745 ,  0.67224863, -0.03497895,  2.10769987,\n",
       "          1.58748883, -0.62942506, -0.60963845,  0.87205253,  0.12329934,\n",
       "          0.87512119, -1.24736908, -0.60167174,  0.01171168,  0.52733965,\n",
       "         -0.95910096, -1.29095295, -0.64693448, -0.62942506, -0.42053552,\n",
       "         -0.58143445,  1.52806398,  0.51529598, -0.43928844,  1.16664395,\n",
       "          0.21011998, -0.40056487, -0.90930496, -0.0608203 , -0.60963845,\n",
       "          1.16664395,  0.03291333,  0.37390662,  0.52733965, -0.99062447,\n",
       "          1.53488322,  0.36495636, -1.22471944, -0.71291068, -1.34493675,\n",
       "         -0.35891876]),\n",
       "  'Gradient Boost_imp_long': array([ 2.84637407e-01, -5.62531200e-02,  1.60619445e+00, -1.57115360e+00,\n",
       "          8.77814581e-01, -4.85664476e-01,  5.83329540e-01, -7.27841518e-01,\n",
       "          1.89547073e+00,  9.61334141e-01,  1.20324848e+00, -8.34906282e-01,\n",
       "          1.94900860e+00,  1.79856947e-01,  3.46581490e-02, -4.10096351e-01,\n",
       "         -1.19574934e+00, -6.26044132e-01, -9.68400314e-01, -8.55076835e-01,\n",
       "          1.18666368e-01, -2.45344352e-01, -7.24026654e-01,  9.18286816e-01,\n",
       "         -6.66500595e-01, -1.37009246e+00,  1.47576476e-01,  4.92979900e-01,\n",
       "          5.27730521e-01, -4.39361057e-01, -9.05797838e-01,  9.70889807e-01,\n",
       "          2.38777433e+00, -4.03136799e-01, -6.82363876e-01,  1.79974430e+00,\n",
       "          2.76235121e-01,  1.30651133e+00, -2.46636438e-02, -6.91709826e-01,\n",
       "          3.25867366e-01,  5.55504879e-01, -1.00433798e+00,  1.70277509e+00,\n",
       "         -8.07830051e-01, -3.59671538e-01, -1.20703512e+00,  4.50954799e-01,\n",
       "          2.31550494e-03,  1.35944955e+00,  6.07603366e-01, -1.08873285e+00,\n",
       "          1.33636023e+00, -1.14581306e+00, -1.70697400e+00, -5.24396465e-02,\n",
       "         -6.75955591e-01,  1.39931110e-01,  2.16551509e-01,  2.05906146e+00,\n",
       "          5.04812299e-01, -2.89608203e-01, -1.40931760e+00, -5.41422863e-01,\n",
       "         -1.45514796e+00, -6.73475569e-01, -1.34667332e+00,  2.06988539e+00,\n",
       "          7.55900977e-01, -8.93947171e-01, -1.15453568e+00,  4.91133029e-01,\n",
       "          7.20931655e-01, -6.26837044e-02,  2.19862010e+00,  1.70088023e+00,\n",
       "         -7.23595927e-01, -8.15716412e-01,  8.88795220e-01,  2.89670065e-01,\n",
       "          9.98819179e-01, -1.34785937e+00, -5.84822921e-01, -1.60160160e-01,\n",
       "          4.94273398e-01, -1.21544124e+00, -1.46065528e+00, -5.20200847e-01,\n",
       "         -4.68002941e-01, -4.22702124e-01, -7.28693060e-01,  1.53996102e+00,\n",
       "          5.47006433e-01, -3.47997015e-01,  1.15623791e+00,  2.98284102e-01,\n",
       "         -9.82998760e-02, -1.10324314e+00, -1.03532526e-01, -8.27297449e-01,\n",
       "          1.15336390e+00,  2.11132910e-01,  1.98873327e-01,  6.21245147e-01,\n",
       "         -1.16001592e+00,  1.41510001e+00,  3.75915209e-01, -1.40060071e+00,\n",
       "         -7.43000599e-01, -1.65664749e+00, -2.60894397e-01])},\n",
       " {'Random Forest_full_cros': array([-0.26793672, -0.34041887,  0.50295403,  1.84510246, -0.05233301,\n",
       "          1.18293495, -0.33550483, -0.25933714,  0.68661645, -0.4589702 ,\n",
       "         -0.25565161, -1.31954226, -1.1143809 ,  0.55086596, -0.078746  ,\n",
       "         -0.85639356,  0.50233977, -0.55110854,  1.7283939 , -0.31154886,\n",
       "         -0.45159913, -0.60946282,  0.90406292, -0.09348813, -0.34410441,\n",
       "          0.10491642, -0.44115679,  1.33834161, -0.3373476 , -0.52285278,\n",
       "          0.20442582, -1.33367014, -1.01364299,  0.66941729,  1.35554077,\n",
       "         -0.64263262,  0.2572518 , -1.17212092, -0.33120504,  0.14484303,\n",
       "         -0.61191984, -0.50503937, -0.30663482,  2.01893679,  0.83096651,\n",
       "          0.55270873,  1.94461186, -1.1973054 ,  0.04471937, -1.10271004,\n",
       "         -1.27654437, -0.80848162, -0.01302065]),\n",
       "  'Adaboost_full_cros': array([-0.25319458, -0.29521865,  0.42414031,  1.56193064, -0.19763237,\n",
       "          1.14500467, -0.39731714, -0.10320546,  0.5545515 , -0.55059666,\n",
       "         -0.39731714, -1.26324221, -1.08271882,  0.4992685 , -0.17928953,\n",
       "         -0.72543003,  0.40080147, -0.59653112,  1.53385039, -0.2743322 ,\n",
       "         -0.6401756 , -0.5126508 ,  0.8630443 , -0.19763237, -0.59653112,\n",
       "          0.39309003, -0.55059666,  1.34079863, -0.18562647, -0.29526621,\n",
       "          0.38431495, -1.25408992, -0.97801616,  0.51155361,  1.29472947,\n",
       "         -0.68499118,  0.40080147, -1.15034898, -0.33996662,  0.37084623,\n",
       "         -0.6401756 , -0.59653112, -0.17928953,  2.01647977,  0.70460536,\n",
       "          0.48084083,  1.77077754, -1.08237693, -0.25319458, -1.10013602,\n",
       "         -1.20221945, -0.77353371, -0.22154707]),\n",
       "  'Gradient Boost_full_cros': array([-0.08646015, -0.31159003,  0.58187613,  1.89934241, -0.03011368,\n",
       "          1.10884322, -0.69234986, -0.35961346,  0.62702157, -0.77387274,\n",
       "         -0.38050759, -1.05976599, -1.19977256,  0.61668554, -0.05864725,\n",
       "         -0.93542535,  0.65633374, -0.82527975,  1.67036465, -0.32812618,\n",
       "         -0.48149907, -0.65099837,  0.88771131,  0.08786346, -0.59037981,\n",
       "          0.13288473, -0.46306079,  1.33944122, -0.38200388, -0.50649696,\n",
       "          0.24334674, -1.16062047, -0.74475318,  0.62655537,  1.27475879,\n",
       "         -0.69763601,  0.25932533, -1.11412557, -0.462703  ,  0.26356546,\n",
       "         -0.65087374, -0.41900398, -0.35927818,  2.08763929,  0.80495512,\n",
       "          0.61710429,  2.0479314 , -0.97431695,  0.30759034, -0.76722812,\n",
       "         -1.27833954, -1.03386588,  0.02640092]),\n",
       "  'Random Forest_full_long': array([-0.35541172, -0.5002525 , -0.35848038, -1.1937698 , -1.26987259,\n",
       "         -0.08168719,  1.77485248, -0.92188647,  0.74562371, -0.16576849,\n",
       "          0.43814392,  1.67174549, -0.48245427,  0.69345648,  0.50995058,\n",
       "          0.22947499, -0.47079336, -1.26680393,  0.66154241, -0.13569562,\n",
       "          0.39947879, -0.10439528,  1.80062923, -0.18295299,  0.56825513,\n",
       "          0.76771807,  0.69529768, -0.69419185, -0.45974618, -0.34559201,\n",
       "         -0.77274957, -0.07002628, -0.4333557 ,  0.55966288, -1.16983425,\n",
       "         -0.28299133, -1.18885995]),\n",
       "  'Adaboost_full_long': array([-0.40178259, -0.45899773, -0.35891876, -1.22998   , -1.25480825,\n",
       "         -0.27903617,  1.85197816, -1.12345364,  0.79499505,  0.00999494,\n",
       "          0.50176748,  1.56556983, -0.37535801,  0.77112769,  0.41211445,\n",
       "          0.26138906, -0.59856654, -1.15486452,  0.73703146, -0.22959664,\n",
       "          0.40386259, -0.26247514,  1.82129155, -0.26130613,  0.66385571,\n",
       "          0.98252431,  0.81374798, -0.66534644, -0.36939117, -0.5255032 ,\n",
       "         -0.74644676,  0.10576413, -0.57810881,  0.52563484, -1.22998   ,\n",
       "         -0.26539768, -1.25287693]),\n",
       "  'Gradient Boost_full_long': array([-0.42278461, -0.50951305, -0.38571044, -1.3552843 , -1.49243779,\n",
       "         -0.01260984,  1.82245877, -0.91904688,  0.80784544, -0.05280325,\n",
       "          0.4602105 ,  1.69294436, -0.56654386,  0.54946841,  0.38876674,\n",
       "          0.31124323, -0.55202999, -1.33101334,  0.62620541, -0.04329056,\n",
       "          0.34412807, -0.07642608,  1.97279468, -0.06997266,  0.58331457,\n",
       "          0.93531532,  0.8491662 , -0.83638783, -0.5536058 , -0.61819763,\n",
       "         -0.91039609,  0.09956586, -0.49620268,  0.71614268, -1.06879319,\n",
       "         -0.02653219, -1.36886687]),\n",
       "  'Random Forest_imp_cros': array([-0.26609395, -0.21633925,  0.5324383 ,  2.02446509,  0.0041785 ,\n",
       "          1.15775047, -0.52469555, -0.27837906,  0.72900008, -0.56585067,\n",
       "         -0.32567674, -1.38711037, -1.17089241,  0.58956407, -0.03574811,\n",
       "         -0.92089039,  0.50909659, -0.82199525,  1.64301238, -0.33366206,\n",
       "         -0.63649006, -0.69914413,  0.94644656, -0.01424916, -0.59410643,\n",
       "          0.08833152, -0.46081297,  1.3205282 , -0.26547969, -0.57015046,\n",
       "          0.22039647, -1.41659464, -1.11499515,  0.74988477,  1.31008586,\n",
       "         -0.85209377,  0.21548242, -1.13465133, -0.31707716,  0.2130254 ,\n",
       "         -0.71265775, -0.35823229, -0.22616734,  2.19768516,  0.90774845,\n",
       "          0.5324383 ,  2.12274598, -1.10762409, -0.03697662, -1.1475507 ,\n",
       "         -1.40246676, -0.97801616, -0.00319256]),\n",
       "  'Adaboost_imp_cros': array([-0.24524076, -0.103072  ,  0.43989046,  1.8168467 , -0.20618041,\n",
       "          1.15652196, -0.4718821 , -0.24524076,  0.582193  , -0.57718306,\n",
       "         -0.29601181, -1.18971496, -0.94297209,  0.43989046,  0.01969075,\n",
       "         -0.62140668,  0.4361677 , -0.60977621,  1.66021153, -0.37911698,\n",
       "         -0.48850496, -0.47125531,  0.6212421 ,  0.00833654, -0.4718821 ,\n",
       "          0.28632656, -0.57902924,  1.24586823, -0.16412752, -0.46140404,\n",
       "          0.31047183, -1.22218275, -0.62140668,  0.56683661,  1.22562571,\n",
       "         -0.49124299,  0.25970882, -1.00439765, -0.4718821 ,  0.31047183,\n",
       "         -0.60345379, -0.46140404, -0.20618041,  2.04719255,  0.95549286,\n",
       "          0.4361677 ,  1.95505421, -0.59572289, -0.08563931, -0.93962519,\n",
       "         -1.17963069, -0.93917353,  0.04155502]),\n",
       "  'Gradient Boost_imp_cros': array([-0.32388576, -0.20964891,  0.82466886,  2.13700472,  0.0097338 ,\n",
       "          1.16308579, -0.77106329, -0.142148  ,  0.74540011, -0.44056388,\n",
       "         -0.35950465, -1.43011557, -1.03508657,  0.77196226, -0.03266151,\n",
       "         -0.88271754,  0.6285053 , -1.02604683,  1.68278169, -0.42313743,\n",
       "         -0.78289964, -0.6139275 ,  0.77136224, -0.0947413 , -0.59942919,\n",
       "          0.1653938 , -0.5532648 ,  1.26200237, -0.38959411, -0.63166586,\n",
       "          0.24063477, -1.18171739, -0.94952294,  0.76794067,  1.25161564,\n",
       "         -0.89180013,  0.42738325, -1.01923805, -0.3007545 ,  0.18171338,\n",
       "         -0.75723335, -0.59111458, -0.39605439,  2.3954889 ,  0.79268396,\n",
       "          0.58087529,  2.25324064, -0.94297445,  0.14385026, -1.0532854 ,\n",
       "         -1.16435357, -1.08112912,  0.04673626]),\n",
       "  'Random Forest_imp_long': array([-0.38793952, -0.45729125, -0.4505402 , -1.32081235, -1.26557646,\n",
       "          0.04719655,  1.95037987, -0.9912382 ,  0.76587687, -0.08598332,\n",
       "          0.31478376,  1.8877792 , -0.39407684,  0.67688571,  0.43323406,\n",
       "          0.22517887, -0.61808907, -1.3159025 ,  0.72414309, -0.1467428 ,\n",
       "          0.3595862 , -0.02583757,  1.91416968, -0.1811118 ,  0.63515193,\n",
       "          0.83031874,  0.75789835, -0.78747914, -0.61808907, -0.49841131,\n",
       "         -0.81141469,  0.01221382, -0.61931653,  0.54186465, -1.33370073,\n",
       "         -0.14367414, -1.28214723]),\n",
       "  'Adaboost_imp_long': array([-0.58143445, -0.57226374, -0.55030909, -1.22471944, -1.23537661,\n",
       "          0.12329934,  2.10088063, -0.70907486,  0.84224268,  0.02624402,\n",
       "          0.36265487,  1.96449571, -0.60963845,  0.52733965,  0.40970766,\n",
       "          0.4219823 , -0.59844964, -1.22471944,  0.72534133,  0.03291333,\n",
       "          0.36265487, -0.29515438,  1.71900286, -0.2190268 ,  0.52733965,\n",
       "          0.90069336,  0.76333427, -0.64693448, -0.54596093, -0.37864587,\n",
       "         -0.89958754,  0.12652951, -0.58143445,  0.45822172, -1.07068862,\n",
       "         -0.35891876, -1.14508039]),\n",
       "  'Gradient Boost_imp_long': array([-0.41435595, -0.42347533, -0.41611159, -1.37552353, -1.14567651,\n",
       "          0.08984721,  2.15139969, -0.97010532,  0.70178246, -0.02276904,\n",
       "          0.44067192,  2.01464465, -0.32385654,  0.63901027,  0.39025779,\n",
       "          0.30308437, -0.7759722 , -1.34934437,  0.69962121,  0.05305862,\n",
       "          0.48868976,  0.03406509,  2.13520259, -0.08409065,  0.74298093,\n",
       "          0.84511543,  0.83086574, -0.84397536, -0.67042194, -0.58654384,\n",
       "         -0.90446371,  0.0137545 , -0.69145559,  0.60969834, -1.24591135,\n",
       "         -0.03212413, -1.07655312])}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Saved Models/Epic Base Trained Models New n_fea 150.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained models\n",
    "top = data_scaled[2][0].shape[1] # significant features\n",
    "joblib.dump(trained_models_base, \n",
    "            \"E:/Machine Learning/Saved Models/Epic Base Trained Models New \"+\"n_fea \"+str(top)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading object ... done\n"
     ]
    }
   ],
   "source": [
    "# Load if needed\n",
    "import os\n",
    "import joblib\n",
    "def load_saved(path):\n",
    "    print(\"Loading object ... done\")\n",
    "    saved_scores = joblib.load(path)\n",
    "    return saved_scores \n",
    "    \n",
    "\n",
    "path_bm = 'E:/Machine Learning/Saved Models/Epic Base Trained Models New n_fea 150.pkl'\n",
    "if 'trained_models_base' not in locals():\n",
    "    trained_models_base = load_saved(path = path_bm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False),\n",
       " AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                   n_estimators=50, random_state=42),\n",
       " GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False),\n",
       " AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                   n_estimators=50, random_state=42),\n",
       " GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False),\n",
       " AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                   n_estimators=50, random_state=42),\n",
       " GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False),\n",
       " AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                   n_estimators=50, random_state=42),\n",
       " GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=42, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the parameters if there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model back\n",
    "name_id = ' '.join((\"n_iter\", str(n_iter), \"n_fea\", str(top))) # make id from iterations and num of top features\n",
    "# if 'rand_s_parms' not in locals():\n",
    "#     rand_s_parms = joblib.load(\"E:/Machine Learning/Saved Models/Hyper_Parameters_Epic_nIter_\"+name_id+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Now search for the hyper-parameters to see if the base model improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_iter 100 n_fea 150'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100,\n",
       "        1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = np.arange(100, 2000, 100)\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators = np.arange(100, 2000, 100)\n",
    "\n",
    "random_state = [42]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 5, 8, 10, 12] \n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 6, 8, 10, 12]\n",
    "\n",
    "max_leaf_nodes = [2, 3, 4, 5, 6, 7, 8, 10]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid_rf = {'n_estimators': n_estimators,\n",
    "                  'max_features': max_features,\n",
    "                  'max_depth': max_depth,\n",
    "                  'min_samples_split': min_samples_split,\n",
    "                  'min_samples_leaf': min_samples_leaf,\n",
    "                  'max_leaf_nodes': max_leaf_nodes,\n",
    "                  'bootstrap': bootstrap, \n",
    "                  'random_state': random_state}\n",
    "\n",
    "\n",
    "learning_rate = [0.1, 0.2, 0.3, 0.5, 0.8, 1, 1.5]\n",
    "loss_ab = ['linear', 'square', 'exponential']\n",
    "random_grid_ab = {'n_estimators': n_estimators,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'loss': loss_ab}\n",
    "\n",
    "\n",
    "loss_gb = ['ls', 'lad', 'huber', 'quantile']\n",
    "random_grid_gb = {'n_estimators': n_estimators,\n",
    "                  'max_features': max_features,\n",
    "                  'max_depth': max_depth,\n",
    "                  'min_samples_split': min_samples_split,\n",
    "                  'min_samples_leaf': min_samples_leaf,\n",
    "                  'max_leaf_nodes': max_leaf_nodes,\n",
    "                  'learning_rate': learning_rate, \n",
    "                  'random_state': random_state,\n",
    "                  'loss': loss_gb}\n",
    "\n",
    "rf_g_search = RandomForestRegressor(random_state=42)\n",
    "ab_g_search = AdaBoostRegressor(random_state=42)\n",
    "gb_g_search = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "\n",
    "def SearchParameters(model_name, grid_parm, n_iter, cv, scoring, train_f, train_l):\n",
    "    grid_search = RandomizedSearchCV(model_name, grid_parm, n_iter=n_iter, \n",
    "                                     cv=cv, scoring=scoring)\n",
    "    %time grid_search.fit(train_f, train_l) # train data and train features for each case\n",
    "    return(grid_search)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching parameter space 0\n",
      "Wall time: 3h 5min 43s\n",
      "Wall time: 6h 59min 44s\n",
      "Wall time: 2h 22min 7s\n",
      "Searching parameter space 1\n",
      "Wall time: 3h 13min 39s\n",
      "Wall time: 11h 8min 12s\n",
      "Wall time: 2h 14min 17s\n",
      "Searching parameter space 2\n",
      "Wall time: 14min 24s\n",
      "Wall time: 24min 50s\n",
      "Wall time: 8min 53s\n",
      "Searching parameter space 3\n",
      "Wall time: 14min 4s\n",
      "Wall time: 21min 3s\n",
      "Wall time: 9min 28s\n"
     ]
    }
   ],
   "source": [
    "# Search for hyperparameters\n",
    "rand_s_parms = {}\n",
    "g_search_models = [rf_g_search, ab_g_search, gb_g_search]\n",
    "g_search_parms = [random_grid_rf, random_grid_ab, random_grid_gb]\n",
    "n_iter=100\n",
    "for i in range(len(data_scaled)):\n",
    "    print(\"Searching parameter space\", i)\n",
    "    scaled_trn_labels = data_scaled[i][1].ravel()\n",
    "    for j in range(len(g_search_models)):\n",
    "        parms = SearchParameters(model_name= g_search_models[j], \n",
    "                                 grid_parm= g_search_parms[j],\n",
    "                                 n_iter=n_iter, cv=5, scoring='neg_mean_squared_error',\n",
    "                                 train_f=data_scaled[i][0], train_l=scaled_trn_labels)\n",
    "        key = model_names[j]+ '_' +df_types[i] \n",
    "        rand_s_parms[key] = parms\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Saved Models/Hyper_Parameters_Epic_nIter_newn_iter 100 n_fea 150.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rand_s_parms, \"E:/Machine Learning/Saved Models/Hyper_Parameters_Epic_nIter_new\"+name_id+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading object ... done\n"
     ]
    }
   ],
   "source": [
    "# Load if needed\n",
    "# Load if needed\n",
    "path_parms = 'E:/Machine Learning/Saved Models/Hyper_Parameters_Epic_nIter_newn_iter 100 n_fea 150.pkl'\n",
    "if 'rand_s_parms' not in locals():\n",
    "    rand_s_parms = load_saved(path = path_parms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest_full_cros\n",
      "Parameters : {'random_state': 42, 'n_estimators': 1900, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_leaf_nodes': 8, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': True}\n",
      "Estimaters : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=20, max_features='auto', max_leaf_nodes=8,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=6,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1900, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Adaboost_full_cros\n",
      "Parameters : {'n_estimators': 1600, 'loss': 'square', 'learning_rate': 0.5}\n",
      "Estimaters : AdaBoostRegressor(base_estimator=None, learning_rate=0.5, loss='square',\n",
      "                  n_estimators=1600, random_state=42)\n",
      "Gradient Boost_full_cros\n",
      "Parameters : {'random_state': 42, 'n_estimators': 400, 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_leaf_nodes': 8, 'max_features': 'auto', 'max_depth': None, 'loss': 'huber', 'learning_rate': 0.1}\n",
      "Estimaters : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='huber',\n",
      "                          max_depth=None, max_features='auto', max_leaf_nodes=8,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=6, min_samples_split=8,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=400,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Random Forest_full_long\n",
      "Parameters : {'random_state': 42, 'n_estimators': 1400, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_leaf_nodes': 7, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': True}\n",
      "Estimaters : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=90, max_features='auto', max_leaf_nodes=7,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=4,\n",
      "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1400, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Adaboost_full_long\n",
      "Parameters : {'n_estimators': 1000, 'loss': 'square', 'learning_rate': 0.1}\n",
      "Estimaters : AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=1000, random_state=42)\n",
      "Gradient Boost_full_long\n",
      "Parameters : {'random_state': 42, 'n_estimators': 1500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_leaf_nodes': 6, 'max_features': 'auto', 'max_depth': 40, 'loss': 'huber', 'learning_rate': 0.2}\n",
      "Estimaters : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.2, loss='huber',\n",
      "                          max_depth=40, max_features='auto', max_leaf_nodes=6,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=2, min_samples_split=5,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Random Forest_imp_cros\n",
      "Parameters : {'random_state': 42, 'n_estimators': 1800, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_leaf_nodes': 10, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': True}\n",
      "Estimaters : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=40, max_features='auto', max_leaf_nodes=10,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=2,\n",
      "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1800, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Adaboost_imp_cros\n",
      "Parameters : {'n_estimators': 1400, 'loss': 'linear', 'learning_rate': 0.5}\n",
      "Estimaters : AdaBoostRegressor(base_estimator=None, learning_rate=0.5, loss='linear',\n",
      "                  n_estimators=1400, random_state=42)\n",
      "Gradient Boost_imp_cros\n",
      "Parameters : {'random_state': 42, 'n_estimators': 1000, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_leaf_nodes': 7, 'max_features': 'auto', 'max_depth': 100, 'loss': 'huber', 'learning_rate': 0.3}\n",
      "Estimaters : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.3, loss='huber',\n",
      "                          max_depth=100, max_features='auto', max_leaf_nodes=7,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=6, min_samples_split=4,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Random Forest_imp_long\n",
      "Parameters : {'random_state': 42, 'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_leaf_nodes': 10, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': True}\n",
      "Estimaters : RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=50, max_features='auto', max_leaf_nodes=10,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=4,\n",
      "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=600, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Adaboost_imp_long\n",
      "Parameters : {'n_estimators': 600, 'loss': 'square', 'learning_rate': 1}\n",
      "Estimaters : AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=600, random_state=42)\n",
      "Gradient Boost_imp_long\n",
      "Parameters : {'random_state': 42, 'n_estimators': 1000, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_leaf_nodes': 3, 'max_features': 'auto', 'max_depth': 100, 'loss': 'lad', 'learning_rate': 0.1}\n",
      "Estimaters : GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='lad',\n",
      "                          max_depth=100, max_features='auto', max_leaf_nodes=3,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=4, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Best Estimators using RandomSearch\n",
    "for key in rand_s_parms:\n",
    "    print(key)\n",
    "    print(\"Parameters :\", rand_s_parms[key].best_params_)\n",
    "    print(\"Estimaters :\", rand_s_parms[key].best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Random Search. To determine if random search yielded a better model, we compare the base model with the best random search model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Random Forest_full_cros --------------------------\n",
      "full_cros :\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=20, max_features='auto', max_leaf_nodes=8,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=6,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1900, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.16086321572574488\n",
      "Mean Squared Error:  0.05415792902941793\n",
      "Root Mean Squared Error:  0.2327185618497543\n",
      "R Squared :  0.945842070970582 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.17792551585431415\n",
      "Mean Squared Error:  0.07271932022786129\n",
      "Root Mean Squared Error:  0.26966520025368734\n",
      "R Squared :  0.9272806797721387 \n",
      "\n",
      "1\n",
      "Adaboost_full_cros --------------------------\n",
      "full_cros :\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=0.5, loss='square',\n",
      "                  n_estimators=1600, random_state=42)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.12481072356334447\n",
      "Mean Squared Error:  0.022290663658922037\n",
      "Root Mean Squared Error:  0.1493005815759672\n",
      "R Squared :  0.9777093363410779 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.19452164711391873\n",
      "Mean Squared Error:  0.07778956236155057\n",
      "Root Mean Squared Error:  0.27890780261862624\n",
      "R Squared :  0.9222104376384495 \n",
      "\n",
      "2\n",
      "Gradient Boost_full_cros --------------------------\n",
      "full_cros :\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='huber',\n",
      "                          max_depth=None, max_features='auto', max_leaf_nodes=8,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=6, min_samples_split=8,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=400,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.008057874514445347\n",
      "Mean Squared Error:  0.0013334685891082125\n",
      "Root Mean Squared Error:  0.03651668918601757\n",
      "R Squared :  0.9986665314108918 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.18140361307320663\n",
      "Mean Squared Error:  0.07416759205547523\n",
      "Root Mean Squared Error:  0.27233727628709814\n",
      "R Squared :  0.9258324079445248 \n",
      "\n",
      "3\n",
      "Random Forest_full_long --------------------------\n",
      "full_long :\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=90, max_features='auto', max_leaf_nodes=7,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=4,\n",
      "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1400, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.16373913328192521\n",
      "Mean Squared Error:  0.05377120672846512\n",
      "Root Mean Squared Error:  0.23188619348392675\n",
      "R Squared :  0.9462287932715349 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.26054177056496786\n",
      "Mean Squared Error:  0.12996915995105554\n",
      "Root Mean Squared Error:  0.36051235755665234\n",
      "R Squared :  0.8700308400489444 \n",
      "\n",
      "4\n",
      "Adaboost_full_long --------------------------\n",
      "full_long :\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='square',\n",
      "                  n_estimators=1000, random_state=42)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.10093178700094699\n",
      "Mean Squared Error:  0.017668615685939037\n",
      "Root Mean Squared Error:  0.13292334515027462\n",
      "R Squared :  0.982331384314061 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.2517860160942283\n",
      "Mean Squared Error:  0.12410745320825661\n",
      "Root Mean Squared Error:  0.3522888774972276\n",
      "R Squared :  0.8758925467917433 \n",
      "\n",
      "5\n",
      "Gradient Boost_full_long --------------------------\n",
      "full_long :\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.2, loss='huber',\n",
      "                          max_depth=40, max_features='auto', max_leaf_nodes=6,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=2, min_samples_split=5,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.0033358497980720816\n",
      "Mean Squared Error:  0.0003201883420875177\n",
      "Root Mean Squared Error:  0.017893807367005986\n",
      "R Squared :  0.9996798116579125 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.2281860361507624\n",
      "Mean Squared Error:  0.09305592435672201\n",
      "Root Mean Squared Error:  0.3050506914542598\n",
      "R Squared :  0.906944075643278 \n",
      "\n",
      "6\n",
      "Random Forest_imp_cros --------------------------\n",
      "imp_cros :\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=40, max_features='auto', max_leaf_nodes=10,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=2,\n",
      "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=1800, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.14306068542449238\n",
      "Mean Squared Error:  0.040855272970759686\n",
      "Root Mean Squared Error:  0.20212687345021613\n",
      "R Squared :  0.9591447270292404 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.1472701722588224\n",
      "Mean Squared Error:  0.057547453770261735\n",
      "Root Mean Squared Error:  0.23989050371005047\n",
      "R Squared :  0.9424525462297383 \n",
      "\n",
      "7\n",
      "Adaboost_imp_cros --------------------------\n",
      "imp_cros :\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=0.5, loss='linear',\n",
      "                  n_estimators=1400, random_state=42)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.15314104495171088\n",
      "Mean Squared Error:  0.03183019726102193\n",
      "Root Mean Squared Error:  0.1784101938259749\n",
      "R Squared :  0.968169802738978 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.2110936047552505\n",
      "Mean Squared Error:  0.07760032197303943\n",
      "Root Mean Squared Error:  0.2785683434510092\n",
      "R Squared :  0.9223996780269605 \n",
      "\n",
      "8\n",
      "Gradient Boost_imp_cros --------------------------\n",
      "imp_cros :\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.3, loss='huber',\n",
      "                          max_depth=100, max_features='auto', max_leaf_nodes=7,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=6, min_samples_split=4,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.007137152928075537\n",
      "Mean Squared Error:  0.0017804487614445732\n",
      "Root Mean Squared Error:  0.042195364217465565\n",
      "R Squared :  0.9982195512385554 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.16722746979119588\n",
      "Mean Squared Error:  0.059375817667013914\n",
      "Root Mean Squared Error:  0.2436715364317587\n",
      "R Squared :  0.9406241823329861 \n",
      "\n",
      "9\n",
      "Random Forest_imp_long --------------------------\n",
      "imp_long :\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=50, max_features='auto', max_leaf_nodes=10,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=4,\n",
      "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=600, n_jobs=None, oob_score=False,\n",
      "                      random_state=42, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.14369386334893636\n",
      "Mean Squared Error:  0.04671886756858707\n",
      "Root Mean Squared Error:  0.2161454777888889\n",
      "R Squared :  0.953281132431413 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.22450718119681215\n",
      "Mean Squared Error:  0.10876602965801488\n",
      "Root Mean Squared Error:  0.3297969521660485\n",
      "R Squared :  0.891233970341985 \n",
      "\n",
      "10\n",
      "Adaboost_imp_long --------------------------\n",
      "imp_long :\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='square',\n",
      "                  n_estimators=600, random_state=42)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.11647134247255689\n",
      "Mean Squared Error:  0.02096649431510356\n",
      "Root Mean Squared Error:  0.14479811571668866\n",
      "R Squared :  0.9790335056848964 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.23263676351496312\n",
      "Mean Squared Error:  0.10876908756187534\n",
      "Root Mean Squared Error:  0.32980158817367045\n",
      "R Squared :  0.8912309124381246 \n",
      "\n",
      "11\n",
      "Gradient Boost_imp_long --------------------------\n",
      "imp_long :\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='lad',\n",
      "                          max_depth=100, max_features='auto', max_leaf_nodes=3,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=4, min_samples_split=12,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best model on  Train data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.08871273977604673\n",
      "Mean Squared Error:  0.06769973290608175\n",
      "Root Mean Squared Error:  0.26019172336198887\n",
      "R Squared :  0.9323002670939182 \n",
      "\n",
      "Best model on  Test data ................: \n",
      "\n",
      "Scores\n",
      "Mean Abs Error:  0.19046871234296478\n",
      "Mean Squared Error:  0.11555930288176121\n",
      "Root Mean Squared Error:  0.33994014602832834\n",
      "R Squared :  0.8844406971182388 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # # the best model we created using best hyperparameters\n",
    "# # We have the parameters for full and important features\n",
    "# # First three for full data (RF,AB,GB) and last three for important features\n",
    "def score(features, labels):\n",
    "    print('Scores')\n",
    "    mabe = metrics.mean_absolute_error(features, labels)\n",
    "    mse = metrics.mean_squared_error(features, labels)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(features, labels))\n",
    "    r2 = metrics.r2_score(features, labels)\n",
    "    print(\"Mean Abs Error: \", mabe )\n",
    "    print(\"Mean Squared Error: \",mse )\n",
    "    print(\"Root Mean Squared Error: \", rmse )\n",
    "    print('R Squared : ', r2 , \"\\n\")\n",
    "    return([mabe, mse, rmse, r2])\n",
    "\n",
    "best_m_score = [{},{}]\n",
    "for index, key in enumerate(rand_s_parms):\n",
    "    print(index)\n",
    "    print(key, \"--------------------------\")\n",
    "    i = index//3 # we have three models\n",
    "    print(df_types[i], \":\")\n",
    "    best_random = rand_s_parms[key].best_estimator_\n",
    "    print(best_random)\n",
    "\n",
    "    for j in range(2): # train and test\n",
    "        if j == 0:\n",
    "            msg = \"Train\"\n",
    "            indx = 0\n",
    "        else:\n",
    "            msg = \"Test\"\n",
    "            indx = 2\n",
    "    \n",
    "        # now trying the best model on the training data\n",
    "        print(\"Best model on \", msg,  \"data ................: \\n\")\n",
    "        pred = best_random.predict(data_scaled[i][indx])\n",
    "        best_score = score(data_scaled[i][indx+1].ravel(), pred)\n",
    "        best_m_score[j][key] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Lets evaluate base and the tuned models to determine if random search yielded a better model, we compare the base model with the best random search model. We will perfrom ten-fold cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  5.1. Cross-validation using base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n"
     ]
    }
   ],
   "source": [
    "# n_jobs = 100, could be a problem to run that number of threads. Use n_jobs = -1  as a solution\n",
    "# input: training data and training labels\n",
    "# output: Score for each fold\n",
    "# Scikit-Learn cross-validation features expect a utility function (greater is better) rather \n",
    "# than a cost function (lower is better), so the scoring function is actually the \n",
    "# opposite of the MSE (i.e., a negative value), which is why the preceding code computes -scores \n",
    "# before calculating the square root.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Function to perform cross validation    \n",
    "def perform_crossv(model, df1, df2, cv_fold, model_name, \n",
    "                   df_types, store_s, store_a):\n",
    "    print(\"Model ..........: \", model_name)\n",
    "    scores = cross_val_score(model, df1, df2, scoring=\"neg_mean_squared_error\", cv = cv_fold)\n",
    "    r2 = cross_val_score(model, df1, df2, scoring=\"r2\", cv = cv_fold)\n",
    "    key = model_name + \"_\"+ df_types +  \"_\" + 'mse'\n",
    "    key1 = model_name + '_' + df_types +   \"_\" + 'r2'\n",
    "#     tree_rmse_scores = np.sqrt(-scores)\n",
    "#     print(\"RMSE Score :\", tree_rmse_scores)\n",
    "    store_s[key] = [scores]\n",
    "    store_a[key1] = [r2]\n",
    "    \n",
    "\n",
    "cv_scores = [{},{}]\n",
    "cv_r2 = [{},{}]\n",
    "\n",
    "# call cross validation function\n",
    "for i in range(len(data_scaled)):\n",
    "    df_type = df_types[i]\n",
    "    rfm = RandomForestRegressor(random_state = 42)\n",
    "    ada_reg = AdaBoostRegressor(random_state=42)\n",
    "    gbrt = GradientBoostingRegressor(random_state=42)\n",
    "    models = [rfm, ada_reg, gbrt]\n",
    "    \n",
    "    for m in range(len(models)):\n",
    "        \n",
    "        for j in range(2):\n",
    "            if j == 0:\n",
    "                msg = \"Train\"\n",
    "                indx = 0\n",
    "            else:\n",
    "                msg = \"Test\"\n",
    "                indx = 2\n",
    "            # cross validation training\n",
    "            print(\"Performing cross validation on \", msg, \"data\" )\n",
    "            perform_crossv(model=models[m], df1=data_scaled[i][indx], \n",
    "                           df2=data_scaled[i][indx+1].ravel(), cv_fold=10, \n",
    "                           model_name=model_names[m], df_types=df_type, \n",
    "                           store_s=cv_scores[j], store_a=cv_r2[j])\n",
    "        \n",
    "        if m == 2:\n",
    "            m = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Output Data/BaseModel Scores Epic New n_fea 150.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save scores\n",
    "base_id = ' '.join(('n_fea', str(top)))\n",
    "joblib.dump([cv_scores, cv_r2], \"E:/Machine Learning/Output Data/BaseModel Scores Epic New \"+base_id+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading object ... done\n"
     ]
    }
   ],
   "source": [
    "# load the base model results\n",
    "  \n",
    "# call for base scores \n",
    "path_base = \"E:/Machine Learning/Output Data/BaseModel Scores Epic New n_fea 150.pkl\"\n",
    "if 'cv_scores' not in locals():\n",
    "    cv_scores, cv_r2 = load_saved(path= path_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Random Forest_full_cros_mse': [array([-0.11131708, -0.13729954, -0.14415538, -0.07908314, -0.13590623,\n",
       "          -0.09625949, -0.28923703, -0.09319565, -0.05138408, -0.21808427])],\n",
       "  'Adaboost_full_cros_mse': [array([-0.09905924, -0.14731475, -0.23154867, -0.10477705, -0.111415  ,\n",
       "          -0.10271536, -0.29269233, -0.16101142, -0.07255728, -0.20547586])],\n",
       "  'Gradient Boost_full_cros_mse': [array([-0.14346104, -0.15701661, -0.20535438, -0.06578425, -0.10683774,\n",
       "          -0.0700115 , -0.29936777, -0.12068702, -0.01726851, -0.24261307])],\n",
       "  'Random Forest_full_long_mse': [array([-0.25721257, -0.16421848, -0.07992322, -0.26077213, -0.11227248,\n",
       "          -0.13222697, -0.30451873, -0.09891032, -0.07160586, -0.11140927])],\n",
       "  'Adaboost_full_long_mse': [array([-0.20632998, -0.18516019, -0.14828948, -0.24704667, -0.08208457,\n",
       "          -0.12727051, -0.34826006, -0.10420478, -0.06834157, -0.14535937])],\n",
       "  'Gradient Boost_full_long_mse': [array([-0.20337134, -0.17386341, -0.07589559, -0.24347779, -0.06773662,\n",
       "          -0.13072588, -0.37440589, -0.07728752, -0.10001243, -0.12339696])],\n",
       "  'Random Forest_imp_cros_mse': [array([-0.07761819, -0.08507006, -0.12765795, -0.05581338, -0.1102745 ,\n",
       "          -0.07800717, -0.25314691, -0.11077278, -0.05285488, -0.21539038])],\n",
       "  'Adaboost_imp_cros_mse': [array([-0.09924569, -0.08796228, -0.15258286, -0.05755408, -0.11697784,\n",
       "          -0.09567819, -0.25033351, -0.12471591, -0.07228788, -0.17640103])],\n",
       "  'Gradient Boost_imp_cros_mse': [array([-0.08347362, -0.10205299, -0.12230703, -0.06919504, -0.15438171,\n",
       "          -0.08491695, -0.28232389, -0.1455858 , -0.04221631, -0.22323115])],\n",
       "  'Random Forest_imp_long_mse': [array([-0.17011019, -0.15153325, -0.05506028, -0.24710449, -0.04926912,\n",
       "          -0.11346607, -0.26496765, -0.09102277, -0.04410022, -0.10033268])],\n",
       "  'Adaboost_imp_long_mse': [array([-0.16646679, -0.14870549, -0.06233536, -0.26643955, -0.0719382 ,\n",
       "          -0.18364024, -0.26408572, -0.08239235, -0.04983124, -0.09724924])],\n",
       "  'Gradient Boost_imp_long_mse': [array([-0.18180242, -0.15764834, -0.06747157, -0.255177  , -0.07042474,\n",
       "          -0.15972195, -0.36344128, -0.15428908, -0.06327538, -0.12047328])]},\n",
       " {'Random Forest_full_cros_mse': [array([-0.37491083, -0.1404409 , -0.0662508 , -0.14276152, -0.02927635,\n",
       "          -0.0801503 , -0.07771806, -0.02768177, -1.15327645, -0.11054057])],\n",
       "  'Adaboost_full_cros_mse': [array([-0.30933064, -0.17562281, -0.03530188, -0.17671515, -0.0637861 ,\n",
       "          -0.12739675, -0.0551693 , -0.06037322, -0.90731236, -0.09540553])],\n",
       "  'Gradient Boost_full_cros_mse': [array([-0.36637496, -0.18463964, -0.0157027 , -0.16963867, -0.04174201,\n",
       "          -0.04752944, -0.06676747, -0.04686542, -0.96985164, -0.11534858])],\n",
       "  'Random Forest_full_long_mse': [array([-0.43574925, -0.96003067, -0.60004098, -0.01247963, -0.72469999,\n",
       "          -1.07774536, -0.48892631, -0.13493295, -0.0704036 , -0.44006854])],\n",
       "  'Adaboost_full_long_mse': [array([-0.56647091, -0.87709799, -0.67293958, -0.03769941, -0.88463478,\n",
       "          -1.28889419, -0.70072667, -0.16806263, -0.34952714, -0.35990073])],\n",
       "  'Gradient Boost_full_long_mse': [array([-0.4712098 , -0.50599707, -0.20886584, -0.03400716, -0.82284926,\n",
       "          -0.88521227, -0.0198363 , -0.1010125 , -0.25682449, -0.12266853])],\n",
       "  'Random Forest_imp_cros_mse': [array([-0.25435074, -0.10742459, -0.04643384, -0.09744639, -0.02555486,\n",
       "          -0.06083358, -0.03977692, -0.01968956, -0.63410871, -0.03248834])],\n",
       "  'Adaboost_imp_cros_mse': [array([-0.27106462, -0.11220085, -0.0780753 , -0.19049187, -0.04716163,\n",
       "          -0.0561764 , -0.06217267, -0.05184633, -0.56660664, -0.00930523])],\n",
       "  'Gradient Boost_imp_cros_mse': [array([-0.25627566, -0.08447999, -0.06663991, -0.13076053, -0.04562529,\n",
       "          -0.03111709, -0.03064325, -0.00563202, -0.39857895, -0.02189802])],\n",
       "  'Random Forest_imp_long_mse': [array([-0.368013  , -0.31466125, -0.27036001, -0.05401037, -0.81536744,\n",
       "          -0.72214766, -0.2228911 , -0.05967648, -0.03623429, -0.24455118])],\n",
       "  'Adaboost_imp_long_mse': [array([-0.52122084, -0.579917  , -0.56839078, -0.02695869, -0.85300014,\n",
       "          -1.02536922, -0.27558   , -0.08831312, -0.16395554, -0.10836667])],\n",
       "  'Gradient Boost_imp_long_mse': [array([-0.202276  , -0.22750294, -0.33287383, -0.10198344, -0.8197143 ,\n",
       "          -0.68061909, -0.12203035, -0.07682585, -0.09219688, -0.27964057])]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Cross validation on training data using best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Random Forest', 'Adaboost', 'Gradient Boost']"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Random Forest\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Adaboost\n",
      "Performing cross validation on  Train data\n",
      "Model ..........:  Gradient Boost\n",
      "Performing cross validation on  Test data\n",
      "Model ..........:  Gradient Boost\n"
     ]
    }
   ],
   "source": [
    "# storage for best score and r2 values\n",
    "cv_scores_best = [{},{}]\n",
    "cv_r2_best = [{}, {}]\n",
    "\n",
    "# call cross validation function\n",
    "keys = list(rand_s_parms.keys())\n",
    "k = 0 # counter to get keys\n",
    "for i in range(len(data_scaled)):\n",
    "    df_type = df_types[i]\n",
    "    for m in range(len(model_names)):\n",
    "        best_random = rand_s_parms[keys[k]].best_estimator_\n",
    "\n",
    "        for j in range(2):\n",
    "            if j == 0:\n",
    "                msg = \"Train\"\n",
    "                indx = 0\n",
    "            else:\n",
    "                msg = \"Test\"\n",
    "                indx = 2\n",
    "            print(\"Performing cross validation on \", msg, \"data\" )\n",
    "            perform_crossv(model=best_random, df1=data_scaled[i][indx], \n",
    "                           df2=data_scaled[i][indx+1].ravel(), cv_fold=10, \n",
    "                           model_name=model_names[m], df_types=df_type, \n",
    "                           store_s=cv_scores_best[j], store_a=cv_r2_best[j])\n",
    "        \n",
    "        k=k+1\n",
    "        if m == 2:\n",
    "            m = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Machine Learning/Output Data/Hypertuned Model Scores Epic New n_iter 100 n_fea 150.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save scores\n",
    "joblib.dump([cv_scores_best, cv_r2_best], \"E:/Machine Learning/Output Data/Hypertuned Model Scores Epic New \"+name_id+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading object ... done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# call for tuned scores \n",
    "path_tuned = \"E:/Machine Learning/Output Data/Hypertuned Model Scores Epic New n_iter 100 n_fea 150.pkl\"\n",
    "if 'cv_scores_best' not in locals():\n",
    "    cv_scores_best, cv_r2_best = load_saved(path= path_tuned)\n",
    "\n",
    "    \n",
    "# if 'cv_scores_best' not in locals():\n",
    "#     print(\"Loading scores ... done\")\n",
    "#     saved_scores_best = joblib.load(\"E:/Machine Learning/Output Data/Hypertuned Model Scores Epic New n_iter 100 n_fea 150.pkl\")\n",
    "#     cv_scores_best, cv_r2_best = saved_scores_best\n",
    "# else:\n",
    "#     print(\"Already loaded ...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Final scores on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1 Base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Mean Absolute Error', 'Mean Square Error',\n",
    "        \"Root Mean Sq Error\", \"R Squared\"]\n",
    "\n",
    "def create_dataframe(data, score_cols):\n",
    "    score = pd.DataFrame(data, index=[score_cols]).T # transpose the data\n",
    "    score.sort_index(inplace = True)\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Root Mean Sq Error</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adaboost_full_cros</th>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost_full_long</th>\n",
       "      <td>0.2728</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.3768</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost_imp_cros</th>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.9166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost_imp_long</th>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>0.8796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_full_cros</th>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>0.9248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_full_long</th>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.8796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_imp_cros</th>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.9529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_imp_long</th>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.9049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_full_cros</th>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.2674</td>\n",
       "      <td>0.9285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_full_long</th>\n",
       "      <td>0.2638</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.3532</td>\n",
       "      <td>0.8752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_imp_cros</th>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_imp_long</th>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.8930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Mean Absolute Error Mean Square Error  \\\n",
       "Adaboost_full_cros                    0.2128            0.0871   \n",
       "Adaboost_full_long                    0.2728            0.1420   \n",
       "Adaboost_imp_cros                     0.2161            0.0834   \n",
       "Adaboost_imp_long                     0.2452            0.1204   \n",
       "Gradient Boost_full_cros              0.1830            0.0752   \n",
       "Gradient Boost_full_long              0.2639            0.1204   \n",
       "Gradient Boost_imp_cros               0.1353            0.0471   \n",
       "Gradient Boost_imp_long               0.2059            0.0951   \n",
       "Random Forest_full_cros               0.1779            0.0715   \n",
       "Random Forest_full_long               0.2638            0.1248   \n",
       "Random Forest_imp_cros                0.1403            0.0490   \n",
       "Random Forest_imp_long                0.2205            0.1070   \n",
       "\n",
       "                         Root Mean Sq Error R Squared  \n",
       "Adaboost_full_cros                   0.2952    0.9129  \n",
       "Adaboost_full_long                   0.3768    0.8580  \n",
       "Adaboost_imp_cros                    0.2888    0.9166  \n",
       "Adaboost_imp_long                    0.3470    0.8796  \n",
       "Gradient Boost_full_cros             0.2742    0.9248  \n",
       "Gradient Boost_full_long             0.3469    0.8796  \n",
       "Gradient Boost_imp_cros              0.2171    0.9529  \n",
       "Gradient Boost_imp_long              0.3084    0.9049  \n",
       "Random Forest_full_cros              0.2674    0.9285  \n",
       "Random Forest_full_long              0.3532    0.8752  \n",
       "Random Forest_imp_cros               0.2214    0.9510  \n",
       "Random Forest_imp_long               0.3271    0.8930  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call function and save data\n",
    "base_scores = create_dataframe(data = base_m_score[1], score_cols = cols)\n",
    "base_scores.to_csv(\"E:/Machine Learning/Output Data/Base Model Test Score \" +\"n_fea \"+ str(top)+ \".csv\")\n",
    "base_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Absolute Error   0.211465\n",
       "Mean Square Error     0.093585\n",
       "Root Mean Sq Error    0.301963\n",
       "R Squared             0.906415\n",
       "dtype: float64"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_scores.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2 Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Root Mean Sq Error</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adaboost_full_cros</th>\n",
       "      <td>0.194522</td>\n",
       "      <td>0.077790</td>\n",
       "      <td>0.278908</td>\n",
       "      <td>0.922210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost_full_long</th>\n",
       "      <td>0.251786</td>\n",
       "      <td>0.124107</td>\n",
       "      <td>0.352289</td>\n",
       "      <td>0.875893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost_imp_cros</th>\n",
       "      <td>0.211094</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.278568</td>\n",
       "      <td>0.922400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost_imp_long</th>\n",
       "      <td>0.232637</td>\n",
       "      <td>0.108769</td>\n",
       "      <td>0.329802</td>\n",
       "      <td>0.891231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_full_cros</th>\n",
       "      <td>0.181404</td>\n",
       "      <td>0.074168</td>\n",
       "      <td>0.272337</td>\n",
       "      <td>0.925832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_full_long</th>\n",
       "      <td>0.228186</td>\n",
       "      <td>0.093056</td>\n",
       "      <td>0.305051</td>\n",
       "      <td>0.906944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_imp_cros</th>\n",
       "      <td>0.167227</td>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.243672</td>\n",
       "      <td>0.940624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost_imp_long</th>\n",
       "      <td>0.190469</td>\n",
       "      <td>0.115559</td>\n",
       "      <td>0.339940</td>\n",
       "      <td>0.884441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_full_cros</th>\n",
       "      <td>0.177926</td>\n",
       "      <td>0.072719</td>\n",
       "      <td>0.269665</td>\n",
       "      <td>0.927281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_full_long</th>\n",
       "      <td>0.260542</td>\n",
       "      <td>0.129969</td>\n",
       "      <td>0.360512</td>\n",
       "      <td>0.870031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_imp_cros</th>\n",
       "      <td>0.147270</td>\n",
       "      <td>0.057547</td>\n",
       "      <td>0.239891</td>\n",
       "      <td>0.942453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_imp_long</th>\n",
       "      <td>0.224507</td>\n",
       "      <td>0.108766</td>\n",
       "      <td>0.329797</td>\n",
       "      <td>0.891234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Mean Absolute Error Mean Square Error  \\\n",
       "Adaboost_full_cros                  0.194522          0.077790   \n",
       "Adaboost_full_long                  0.251786          0.124107   \n",
       "Adaboost_imp_cros                   0.211094          0.077600   \n",
       "Adaboost_imp_long                   0.232637          0.108769   \n",
       "Gradient Boost_full_cros            0.181404          0.074168   \n",
       "Gradient Boost_full_long            0.228186          0.093056   \n",
       "Gradient Boost_imp_cros             0.167227          0.059376   \n",
       "Gradient Boost_imp_long             0.190469          0.115559   \n",
       "Random Forest_full_cros             0.177926          0.072719   \n",
       "Random Forest_full_long             0.260542          0.129969   \n",
       "Random Forest_imp_cros              0.147270          0.057547   \n",
       "Random Forest_imp_long              0.224507          0.108766   \n",
       "\n",
       "                         Root Mean Sq Error R Squared  \n",
       "Adaboost_full_cros                 0.278908  0.922210  \n",
       "Adaboost_full_long                 0.352289  0.875893  \n",
       "Adaboost_imp_cros                  0.278568  0.922400  \n",
       "Adaboost_imp_long                  0.329802  0.891231  \n",
       "Gradient Boost_full_cros           0.272337  0.925832  \n",
       "Gradient Boost_full_long           0.305051  0.906944  \n",
       "Gradient Boost_imp_cros            0.243672  0.940624  \n",
       "Gradient Boost_imp_long            0.339940  0.884441  \n",
       "Random Forest_full_cros            0.269665  0.927281  \n",
       "Random Forest_full_long            0.360512  0.870031  \n",
       "Random Forest_imp_cros             0.239891  0.942453  \n",
       "Random Forest_imp_long             0.329797  0.891234  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score on test data using hyperparameters\n",
    "hyperTuned_scores = create_dataframe(data=best_m_score[1], score_cols=cols)\n",
    "hyperTuned_scores.to_csv(\"E:/Machine Learning/Output Data/HyperTuned Test Score \" + name_id+\".csv\")\n",
    "hyperTuned_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean Absolute Error   0.205631\n",
       "Mean Square Error     0.091619\n",
       "Root Mean Sq Error    0.300036\n",
       "R Squared             0.908381\n",
       "dtype: float64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperTuned_scores.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Bagging and voting approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    " \n",
    "lnr_reg = LinearRegression()\n",
    "rnd_reg = RandomForestRegressor(random_state = 42) \n",
    "ab_reg = AdaBoostRegressor(random_state=42)\n",
    "gb_reg = GradientBoostingRegressor(random_state=42)\n",
    "svr_reg = SVR()\n",
    "bag_reg = BaggingRegressor(DecisionTreeRegressor(random_state=42),  n_estimators=500,\n",
    "                           bootstrap=True, n_jobs=-1, oob_score=True, \n",
    "                           bootstrap_features=True)\n",
    "\n",
    "# ('lr', log_reg),\n",
    "voting_reg = VotingRegressor([('lnr', lnr_reg),\n",
    "                              ('rf', rnd_reg), \n",
    "                              ('ab', ab_reg),\n",
    "                              ('gb', gb_reg),\n",
    "                              ('svr', svr_reg),\n",
    "                             ('bag_reg', bag_reg)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "=====================\n",
      "0\n",
      "=====================\n",
      "0\n",
      "=====================\n",
      "0\n",
      "=====================\n",
      "0\n",
      "=====================\n",
      "0\n",
      "=====================\n",
      "0\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "bag_score = {}\n",
    "models_all = [lnr_reg, rnd_reg, ab_reg, gb_reg, svr_reg, voting_reg, bag_reg]\n",
    "voting_models = [models_all]\n",
    "for m in range(len(voting_models)):\n",
    "    for clf in voting_models[m]:\n",
    "        print(m)\n",
    "        print('=====================')\n",
    "        for i in range(len(data_scaled)):\n",
    "            clf.fit(data_scaled[i][0], data_scaled[i][1].ravel())\n",
    "            y_pred = clf.predict(data_scaled[i][2])\n",
    "            clf_nm = clf.__class__.__name__ + \"_\" + df_types[i] + \"_\" + str(m)\n",
    "\n",
    "            abe = metrics.mean_absolute_error(data_scaled[i][3].ravel(), y_pred)\n",
    "            mse = metrics.mean_squared_error(data_scaled[i][3].ravel(), y_pred)\n",
    "            rmse = np.sqrt(metrics.mean_squared_error(data_scaled[i][3].ravel(), y_pred))\n",
    "            r2 = metrics.r2_score(data_scaled[i][3], y_pred)\n",
    "            bag_score[clf_nm] = [abe, mse, rmse, r2 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Root Mean Sq Error</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor_full_cros_0</th>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor_full_long_0</th>\n",
       "      <td>0.2728</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.3768</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor_imp_cros_0</th>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.9166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor_imp_long_0</th>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>0.8796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_full_cros_0</th>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.9076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_full_long_0</th>\n",
       "      <td>0.3041</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.8418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_imp_cros_0</th>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_imp_long_0</th>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor_full_cros_0</th>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>0.9248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor_full_long_0</th>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.8796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor_imp_cros_0</th>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.9529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor_imp_long_0</th>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.9049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_full_cros_0</th>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.6760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_full_long_0</th>\n",
       "      <td>0.6536</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_imp_cros_0</th>\n",
       "      <td>0.7971</td>\n",
       "      <td>1.1396</td>\n",
       "      <td>1.0675</td>\n",
       "      <td>-0.1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_imp_long_0</th>\n",
       "      <td>0.5958</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor_full_cros_0</th>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.2674</td>\n",
       "      <td>0.9285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor_full_long_0</th>\n",
       "      <td>0.2638</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.3532</td>\n",
       "      <td>0.8752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor_imp_cros_0</th>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor_imp_long_0</th>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.8930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_full_cros_0</th>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.8618</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_full_long_0</th>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_imp_cros_0</th>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_imp_long_0</th>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_full_cros_0</th>\n",
       "      <td>0.3013</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_full_long_0</th>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_imp_cros_0</th>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_imp_long_0</th>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.8666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Mean Absolute Error Mean Square Error  \\\n",
       "AdaBoostRegressor_full_cros_0                      0.2128            0.0871   \n",
       "AdaBoostRegressor_full_long_0                      0.2728            0.1420   \n",
       "AdaBoostRegressor_imp_cros_0                       0.2161            0.0834   \n",
       "AdaBoostRegressor_imp_long_0                       0.2452            0.1204   \n",
       "BaggingRegressor_full_cros_0                       0.2189            0.0924   \n",
       "BaggingRegressor_full_long_0                       0.3041            0.1582   \n",
       "BaggingRegressor_imp_cros_0                        0.1658            0.0599   \n",
       "BaggingRegressor_imp_long_0                        0.2490            0.1219   \n",
       "GradientBoostingRegressor_full_cros_0              0.1830            0.0752   \n",
       "GradientBoostingRegressor_full_long_0              0.2639            0.1204   \n",
       "GradientBoostingRegressor_imp_cros_0               0.1353            0.0471   \n",
       "GradientBoostingRegressor_imp_long_0               0.2059            0.0951   \n",
       "LinearRegression_full_cros_0                       0.4640            0.3240   \n",
       "LinearRegression_full_long_0                       0.6536            0.6888   \n",
       "LinearRegression_imp_cros_0                        0.7971            1.1396   \n",
       "LinearRegression_imp_long_0                        0.5958            0.5455   \n",
       "RandomForestRegressor_full_cros_0                  0.1779            0.0715   \n",
       "RandomForestRegressor_full_long_0                  0.2638            0.1248   \n",
       "RandomForestRegressor_imp_cros_0                   0.1403            0.0490   \n",
       "RandomForestRegressor_imp_long_0                   0.2205            0.1070   \n",
       "SVR_full_cros_0                                    0.7070            0.7426   \n",
       "SVR_full_long_0                                    0.7715            0.9185   \n",
       "SVR_imp_cros_0                                     0.3464            0.2290   \n",
       "SVR_imp_long_0                                     0.4662            0.3534   \n",
       "VotingRegressor_full_cros_0                        0.3013            0.1425   \n",
       "VotingRegressor_full_long_0                        0.3861            0.2398   \n",
       "VotingRegressor_imp_cros_0                         0.2145            0.0943   \n",
       "VotingRegressor_imp_long_0                         0.2737            0.1334   \n",
       "\n",
       "                                      Root Mean Sq Error R Squared  \n",
       "AdaBoostRegressor_full_cros_0                     0.2952    0.9129  \n",
       "AdaBoostRegressor_full_long_0                     0.3768    0.8580  \n",
       "AdaBoostRegressor_imp_cros_0                      0.2888    0.9166  \n",
       "AdaBoostRegressor_imp_long_0                      0.3470    0.8796  \n",
       "BaggingRegressor_full_cros_0                      0.3040    0.9076  \n",
       "BaggingRegressor_full_long_0                      0.3978    0.8418  \n",
       "BaggingRegressor_imp_cros_0                       0.2448    0.9401  \n",
       "BaggingRegressor_imp_long_0                       0.3492    0.8781  \n",
       "GradientBoostingRegressor_full_cros_0             0.2742    0.9248  \n",
       "GradientBoostingRegressor_full_long_0             0.3469    0.8796  \n",
       "GradientBoostingRegressor_imp_cros_0              0.2171    0.9529  \n",
       "GradientBoostingRegressor_imp_long_0              0.3084    0.9049  \n",
       "LinearRegression_full_cros_0                      0.5692    0.6760  \n",
       "LinearRegression_full_long_0                      0.8300    0.3112  \n",
       "LinearRegression_imp_cros_0                       1.0675   -0.1396  \n",
       "LinearRegression_imp_long_0                       0.7386    0.4545  \n",
       "RandomForestRegressor_full_cros_0                 0.2674    0.9285  \n",
       "RandomForestRegressor_full_long_0                 0.3532    0.8752  \n",
       "RandomForestRegressor_imp_cros_0                  0.2214    0.9510  \n",
       "RandomForestRegressor_imp_long_0                  0.3271    0.8930  \n",
       "SVR_full_cros_0                                   0.8618    0.2574  \n",
       "SVR_full_long_0                                   0.9584    0.0815  \n",
       "SVR_imp_cros_0                                    0.4786    0.7710  \n",
       "SVR_imp_long_0                                    0.5945    0.6466  \n",
       "VotingRegressor_full_cros_0                       0.3775    0.8575  \n",
       "VotingRegressor_full_long_0                       0.4897    0.7602  \n",
       "VotingRegressor_imp_cros_0                        0.3071    0.9057  \n",
       "VotingRegressor_imp_long_0                        0.3652    0.8666  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag_score_tst = dict(filter(lambda item: '_1'  in item[0], bag_score.items()))\n",
    "ensemble_score = create_dataframe(data=bag_score, score_cols=cols )\n",
    "ensemble_score.to_csv(\"E:/Machine Learning/Output Data/Bagging & voting scores new \" + str(top) +\".csv\")\n",
    "ensemble_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Root Mean Sq Error</th>\n",
       "      <th>R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_full_cros_0</th>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.9076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_full_long_0</th>\n",
       "      <td>0.3041</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.8418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_imp_cros_0</th>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor_imp_long_0</th>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>0.8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_full_cros_0</th>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.6760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_full_long_0</th>\n",
       "      <td>0.6536</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_imp_cros_0</th>\n",
       "      <td>0.7971</td>\n",
       "      <td>1.1396</td>\n",
       "      <td>1.0675</td>\n",
       "      <td>-0.1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression_imp_long_0</th>\n",
       "      <td>0.5958</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_full_cros_0</th>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.8618</td>\n",
       "      <td>0.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_full_long_0</th>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_imp_cros_0</th>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_imp_long_0</th>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.6466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_full_cros_0</th>\n",
       "      <td>0.3013</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_full_long_0</th>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_imp_cros_0</th>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor_imp_long_0</th>\n",
       "      <td>0.2737</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.3652</td>\n",
       "      <td>0.8666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Mean Absolute Error Mean Square Error  \\\n",
       "BaggingRegressor_full_cros_0              0.2189            0.0924   \n",
       "BaggingRegressor_full_long_0              0.3041            0.1582   \n",
       "BaggingRegressor_imp_cros_0               0.1658            0.0599   \n",
       "BaggingRegressor_imp_long_0               0.2490            0.1219   \n",
       "LinearRegression_full_cros_0              0.4640            0.3240   \n",
       "LinearRegression_full_long_0              0.6536            0.6888   \n",
       "LinearRegression_imp_cros_0               0.7971            1.1396   \n",
       "LinearRegression_imp_long_0               0.5958            0.5455   \n",
       "SVR_full_cros_0                           0.7070            0.7426   \n",
       "SVR_full_long_0                           0.7715            0.9185   \n",
       "SVR_imp_cros_0                            0.3464            0.2290   \n",
       "SVR_imp_long_0                            0.4662            0.3534   \n",
       "VotingRegressor_full_cros_0               0.3013            0.1425   \n",
       "VotingRegressor_full_long_0               0.3861            0.2398   \n",
       "VotingRegressor_imp_cros_0                0.2145            0.0943   \n",
       "VotingRegressor_imp_long_0                0.2737            0.1334   \n",
       "\n",
       "                             Root Mean Sq Error R Squared  \n",
       "BaggingRegressor_full_cros_0             0.3040    0.9076  \n",
       "BaggingRegressor_full_long_0             0.3978    0.8418  \n",
       "BaggingRegressor_imp_cros_0              0.2448    0.9401  \n",
       "BaggingRegressor_imp_long_0              0.3492    0.8781  \n",
       "LinearRegression_full_cros_0             0.5692    0.6760  \n",
       "LinearRegression_full_long_0             0.8300    0.3112  \n",
       "LinearRegression_imp_cros_0              1.0675   -0.1396  \n",
       "LinearRegression_imp_long_0              0.7386    0.4545  \n",
       "SVR_full_cros_0                          0.8618    0.2574  \n",
       "SVR_full_long_0                          0.9584    0.0815  \n",
       "SVR_imp_cros_0                           0.4786    0.7710  \n",
       "SVR_imp_long_0                           0.5945    0.6466  \n",
       "VotingRegressor_full_cros_0              0.3775    0.8575  \n",
       "VotingRegressor_full_long_0              0.4897    0.7602  \n",
       "VotingRegressor_imp_cros_0               0.3071    0.9057  \n",
       "VotingRegressor_imp_long_0               0.3652    0.8666  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the scores of bagging, linear reg,svr and voting\n",
    "sel_models = ['Bagging', 'Linear', 'SVR', 'Voting']\n",
    "sel_models = ensemble_score.loc[ensemble_score.index.str.contains('|'.join(sel_models)),:]\n",
    "sel_models.to_csv(\"E:/Machine Learning/Output Data/Bagging, LR,SVR & voting scores\" + str(top)+\".csv\")\n",
    "sel_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
